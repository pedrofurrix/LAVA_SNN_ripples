{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show current directory\n",
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)\n",
    "import json\n",
    "# Define general variables\n",
    "parent = r\"C:\\__NeuroSpark_Liset_Dataset__\\neurospark_mat\\CNN_TRAINING_SESSIONS\" # Modify this to your data path folder\n",
    "\n",
    "### HOME PC\n",
    "# parent=r\"E:\\neurospark_mat\\CNN_TRAINING_SESSIONS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path (To acess sntt_utils)\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(curr_dir, os.pardir))\n",
    "liset_path = os.path.abspath(os.path.join(curr_dir, '../liset_tk'))\n",
    "\n",
    "\n",
    "# Add the grandparent directory to the system path\n",
    "# grandparent_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append(liset_path)\n",
    "from liset_tk import liset_tk\n",
    "\n",
    "from liset_aux import ripples_std, middle\n",
    "from signal_aid import most_active_channel, bandpass_filter\n",
    "\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca993c4a",
   "metadata": {},
   "source": [
    "\n",
    "# Check if Cuda is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67faa46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Check CUDA Installation\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Get the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs: {num_gpus}\")\n",
    "\n",
    "# Get information about each GPU\n",
    "for i in range(num_gpus):\n",
    "    device_props = torch.cuda.get_device_properties(i)\n",
    "    print(f\"\\nGPU {i}:\")\n",
    "    print(f\"  Name: {device_props.name}\")\n",
    "    print(f\"  Total memory: {device_props.total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"  Multiprocessor count: {device_props.multi_processor_count}\")\n",
    "    print(f\"  Major compute capability: {device_props.major}\")\n",
    "    print(f\"  Minor compute capability: {device_props.minor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8186829e",
   "metadata": {},
   "source": [
    "## Define the Device that will be used to train the SNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71086d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to be used\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")     # torch.device(\"cpu\") #\n",
    "\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953fa9e",
   "metadata": {},
   "source": [
    "## Set some important Parameters\n",
    "`RIPPLE_DETECTION_OFFSET` - based on the time for 4.5 periods of the ripple\n",
    "\n",
    "`RIPPLE_CONFIDENCE_WINDOW`-\n",
    "\n",
    "`WINDOW_SIZE` -\n",
    "\n",
    "`INTERSECT_WINDOW_LEN` - \n",
    "\n",
    "`PRED_CAUSALITY_WINDOW` - \n",
    "\n",
    "`PRED_GT_TOLERANCE` - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=1  # Time step in milliseconds (1 ms)\n",
    "\n",
    "\n",
    "RIPPLE_DETECTION_OFFSET = [18, 45, 31, 20] # it's calculated as 4.5 periods of the ripple wavelet - for 100 Hz and 250 Hz as the limit frequencies\n",
    "# The Windows for HFO detection are based on the MAX DETECTION OFFSET\n",
    "\n",
    "#TODO - Why are these values? Can I tune them in a better way?\n",
    "RIPPLE_CONFIDENCE_WINDOW = int(round(RIPPLE_DETECTION_OFFSET[1] * 1.8)) \n",
    "\n",
    "# in timesteps (ms) - Max time from the Insertion Timing to the GT annotation\n",
    "MAX_DETECTION_OFFSET = RIPPLE_DETECTION_OFFSET[1]   # in timesteps (ms)\n",
    "\n",
    "MEAN_DETECTION_OFFSET = RIPPLE_DETECTION_OFFSET[2]   # in timesteps (ms)\n",
    "\n",
    "WINDOW_SIZE = int(RIPPLE_DETECTION_OFFSET[1]*4)   # in timesteps (ms) - The size of the window to slice the input data\n",
    "\n",
    "# unit: timesteps (ms) - The number of steps that 2 consecutive windows must overlap to not lose any relevant CBs\n",
    "# INTERSECT_WINDOW_LEN = int(MAX_DETECTION_OFFSET)\n",
    "std, mean = ripples_std(parent) # 61 ms # in seconds\n",
    "INTERSECT_WINDOW_LEN=int((std+mean)*1000) # in timesteps (ms) - The size of the intersection window to slice the input data\n",
    "\n",
    "# unit: timesteps (ms) - The number of steps that the window must shift to get the next window\n",
    "WINDOW_SHIFT = int(WINDOW_SIZE - INTERSECT_WINDOW_LEN)\n",
    "\n",
    "# unit: timesteps (ms) - The time window after the GT annotation where the network should predict the burst (GT_time, GT_time + PRED_CAUSALITY_WINDOW)\n",
    "# This is needed to give the network some extra time steps to increase the membrane potential and spike\n",
    "PRED_CAUSALITY_WINDOW = int(5)     # Giving PRED_CAUSALITY_WINDOW ms for the network to update its inner state and spike   \n",
    "\n",
    "# unit: timesteps (ms) - The time window around the GT annotation where the network should predict the burst (GT_time - PRED_GT_TOLERANCE, GT_time + PRED_GT_TOLERANCE)\n",
    "PRED_GT_TOLERANCE = int(RIPPLE_DETECTION_OFFSET[3])  # in timesteps (ms)\n",
    "print(f\"WINDOW_SIZE: {WINDOW_SIZE}\")\n",
    "print(f\"INTERSECT_WINDOW_LEN: {INTERSECT_WINDOW_LEN} (MEAN+STD)\")\n",
    "print(f\"WINDOW_SHIFT: {WINDOW_SHIFT}\")\n",
    "print(f\"MEAN DETECTION OFFSET: {MEAN_DETECTION_OFFSET}\")\n",
    "print(f\"PRED_GT_TOLERANCE: {PRED_GT_TOLERANCE}\")\n",
    "print(f\"PRED_CAUSALITY_WINDOW: {PRED_CAUSALITY_WINDOW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6002d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for the Refractory LIF Process\n",
    "confidence_window=int(RIPPLE_DETECTION_OFFSET[1])\n",
    "# We know that 2 relevant events do not occur within the confidence window of a ripple event, so we set the refractory period accordingly\n",
    "refrac_period = np.floor(confidence_window / dt)   # Number of time-steps for the refractory period\n",
    "print(\"Refractory Period: \", refrac_period, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382cc13",
   "metadata": {},
   "source": [
    "# Read the concatenated data and GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent = r\"C:\\__NeuroSpark_Liset_Dataset__\\neurospark_mat\\CNN_TRAINING_SESSIONS\" # Modify this to your data path folder\n",
    "freq=1000 # Frequency of the data\n",
    "bandpass=[100,250]\n",
    "downsampled_fs = 1000 # Downsampled frequency\n",
    "WINDOW_SHIFT=int(119*downsampled_fs/1000)\n",
    "WINDOW_SIZE=int(180*downsampled_fs/1000)\n",
    "time_max=60\n",
    "window_size=0.05\n",
    "sample_ratio=0.75\n",
    "scaling_factor=1\n",
    "refractory=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb24ffa",
   "metadata": {},
   "source": [
    "# Generate the SNN's Input Data and Labels (GT)\n",
    "We need to transform the input data into a format that we can feed into the SNN. To allow learning through BPTT, we will split the spike trains into time windows of WINDOW_SIZE ms. Since a relevant HFO can occur in-between 2 time windows, we will introduce an overlap of INTERSECT_WINDOW_LEN ms between the time windows -- equal to the maximum duration of an HFO.\n",
    "\n",
    "We are opting for this windowing strategy because it is a simple way to implement learning in the SNN. Another option would be to feed the data in real-time to the SNN without windows, but this would disable the possibility of having batch_size > 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df78a96",
   "metadata": {},
   "source": [
    "# Split the Input into Time Windows and Calculate the Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "load=True\n",
    "\n",
    "\n",
    "from extract_Nripples.utils_encoding import *\n",
    "# Only run this block if first time\n",
    "if 'windowed_input_data' not in locals():\n",
    "    if load:\n",
    "        windowed_path=os.path.join(curr_dir,os.pardir,\"extract_Nripples\",\"train_pedro\",\"windowed_data\")\n",
    "        windowed_input_data = np.load(os.path.join(windowed_path,\"windowed_input_data.npy\"))\n",
    "        windowed_gt = np.load(os.path.join(windowed_path,\"windowed_gt.npy\"))\n",
    "        filtered_windows=np.load(os.path.join(windowed_path,\"filtered_windows.npy\"))\n",
    "    else:\n",
    "        # Split the Input Data and Ground Truth into Windows\n",
    "        windowed_input_data = []    # Input Data Windows\n",
    "        windowed_gt = []        # Ground Truth Windows (spike time if HFO, -1 if no HFO)\n",
    "        filtered_windows=[] \n",
    "        total_windows_count = 0\n",
    "        skipped_hfo_count = 0   # Counts the nÂº of skipped HFOs due to no input activations\n",
    "        total_hfos=0\n",
    "        # curr_ripple_times = ripples_concat[curr_ripple_id]    # Get the GT times for the current sEEG source\n",
    "\n",
    "        # LOAD THE DATA\n",
    "        # Iterate over the datasets\n",
    "        for dataset in os.listdir(parent):\n",
    "            dataset_path = os.path.join(parent, dataset)\n",
    "            liset= liset_tk(dataset_path, shank=3, downsample=downsampled_fs, verbose=False)\n",
    "\n",
    "            ripples=np.array(liset.ripples_GT)\n",
    "            spikified=np.zeros((liset.data.shape[0], liset.data.shape[1], 2))\n",
    "            filtered=np.zeros((liset.data.shape[0], liset.data.shape[1]))\n",
    "            thresholds = np.zeros((liset.data.shape[1]))\n",
    "\n",
    "            print(\"data shape: \", liset.data.shape)\n",
    "            print(\"ripples shape: \", ripples.shape)\n",
    "            # print(\"Head of data_concat: \", data[:10][:])\n",
    "            # print(\"Head of ripples_concat: \", ripples[:10])\n",
    "            ripples = ripples[np.argsort(ripples[:, 0])]\n",
    "            # print(ripples[:10][:])\n",
    "\n",
    "            for channel in range(liset.data.shape[1]):\n",
    "                channel_signal = liset.data[:time_max*downsampled_fs, channel]\n",
    "                filtered_signal=bandpass_filter(channel_signal, bandpass=bandpass, fs=liset.fs)\n",
    "                thresholds[channel]=round(calculate_threshold(filtered_signal,downsampled_fs,window_size,sample_ratio,scaling_factor),4)\n",
    "\n",
    "                if thresholds[channel] > 0.1:\n",
    "                    channel_signal = liset.data[:, channel]\n",
    "                    curr_ripple_id = 0     # Keep track of the current GT event index since it is monotonically increasing the timestep\n",
    "                    filtered_liset=bandpass_filter(channel_signal, bandpass=bandpass, fs=liset.fs)\n",
    "                    spikified[:, channel, :]=up_down_channel(filtered_liset,thresholds[channel],liset.fs,refractory)\n",
    "                    \n",
    "                    for i in range(0, liset.data.shape[0], WINDOW_SHIFT*liset.fs):\n",
    "                        left, right = i, i+WINDOW_SIZE*liset.fs\n",
    "                        # Get the current input window\n",
    "                        curr_window = spikified[left:right, channel, :]\n",
    "                        filtered_window = filtered_liset[left:right]\n",
    "                        \n",
    "                        # Increment the total windows count\n",
    "                        total_windows_count += 1\n",
    "                        # Check if the current window is smaller than the expected size\n",
    "                        if curr_window.shape[0] < WINDOW_SIZE:\n",
    "                            # If the current window is smaller than the expected size, break the loop\n",
    "                            print(f\"[WARNING] Current window [{left}, {right}] is smaller than the expected size. Breaking the loop...\")\n",
    "                            break\n",
    "\n",
    "                        # OPTIMIZATION STEP: Skip windows with no activations - The gradient will be zero \n",
    "                        if np.sum(curr_window) == 0:\n",
    "                            # print(f\"Window [{left}:{right}] has no Input activations. Skipping...\")\n",
    "                            cur_gt_time=[-1, -1]    # Default value for Spike Time (no HFO)\n",
    "                            if curr_ripple_id < ripples.shape[0]:\n",
    "                                cur_gt_time = ripples[curr_ripple_id]  \n",
    "                            if (cur_gt_time[1] >= left) and (cur_gt_time[0] <= right):\n",
    "                                if cur_gt_time[1] <= right:\n",
    "                                    print(f\"[WARNING] Window [{left}:{right}] has a GT event at {cur_gt_time} and NO Input activations. Skipping...\")\n",
    "                                    # Update the curr_gt_idx to the next GT event\n",
    "                                    skipped_hfo_count += 1\n",
    "                                curr_ripple_id += 1\n",
    "                            continue   \n",
    "                        \n",
    "                        '''\n",
    "                        Check if there is a GT event in the current window\n",
    "                        '''\n",
    "\n",
    "                        curr_gt = -1    # Default value for Spike Time (no HFO)\n",
    "                        \n",
    "                        # Check if the current GT event is within the current window\n",
    "                        while curr_ripple_id<ripples.shape[0]-1 and ripples[curr_ripple_id][1] < left:\n",
    "                            # Ripple ends before the window starts â skip it\n",
    "                            curr_ripple_id += 1\n",
    "                        \n",
    "                        if curr_ripple_id >= ripples.shape[0]:\n",
    "                            curr_ripple_id=ripples.shape[0]-1\n",
    "                    \n",
    "                        cur_gt_time = ripples[curr_ripple_id]      \n",
    "                        if (cur_gt_time[1] >= left) and (cur_gt_time[0] <= right):\n",
    "                            '''\n",
    "                                Check if the current window overlaps with the current GT event\n",
    "                                The Network may spike in the interval [GT_time[0], GT_time[0] + MEAN_HFO_DURATION + PRED_GT_TOLERANCE]\n",
    "                                However, we are using an upper limit for the HFO Duration of WINDOW_SIZE.\n",
    "                                This way, the Ground Truth Timestamps will be clamped uppwards by WINDOW_SIZE - MAX_HFO_DURATION + MEAN_HFO_DURATION\n",
    "                            '''\n",
    "                            if cur_gt_time[1] <= right and cur_gt_time[0]>=left: # If the GT event is completely within the current window\n",
    "                                '''The Network should predict the HFO -> Calculate the spike time\n",
    "                                Let's assume the network should spike at the end of the relevant event. We have no way of knowing\n",
    "                                the exact end time, so we use the mean duration of the event to calculate the spike time.\n",
    "                                '''\n",
    "                                avg_spike_time = cur_gt_time[0] +  MEAN_DETECTION_OFFSET # The network should spike at the end of the relevant event\n",
    "                                \n",
    "                                # Subtract the left offset to get the spike time in the current window\n",
    "                                relative_spike_time = avg_spike_time - left\n",
    "                                if relative_spike_time > WINDOW_SIZE:\n",
    "                                    # If the spike time is greater than the window size, we want to skip the window\n",
    "                                    print(f\"[WARNING] Spike time {relative_spike_time} is greater than the window size {WINDOW_SIZE}. Adjusting...\")\n",
    "                                    relative_spike_time= cur_gt_time[1]-left\n",
    "\n",
    "                                curr_gt = relative_spike_time   # Update the curr_gt value\n",
    "\n",
    "                                # Update the curr_gt_idx to the next GT event\n",
    "                                curr_ripple_id += 1\n",
    "                                \n",
    "                            elif cur_gt_time[1] > right or cur_gt_time[0] < left:\n",
    "                                continue\n",
    "                                # If the GT event is not completely within the current window, we want to skip the window\n",
    "                        \n",
    "                        # Append the current window    \n",
    "                        windowed_input_data.append(curr_window)            \n",
    "                        # Append the current GT Spike Time to the windowed GT\n",
    "                        windowed_gt.append(curr_gt)\n",
    "                        filtered_windows.append(filtered_window)\n",
    "                    total_hfos+=ripples.shape[0]\n",
    "                else:\n",
    "                    print(f\"[WARNING] Channel {channel} has a very low threshold. Skipping...\")\n",
    "        # Convert to numpy array\n",
    "        filtered_windows=np.array(filtered_windows, dtype=np.float32)\n",
    "        windowed_input_data = np.array(windowed_input_data)\n",
    "        windowed_gt = np.array(windowed_gt, dtype=np.float32)\n",
    "        removed_windows = total_windows_count - windowed_input_data.shape[0]\n",
    "        print(f\"Removed {removed_windows}/{total_windows_count} ({round((removed_windows / total_windows_count)*100, 2)}%) windows with no input activations\")\n",
    "        print(f\"Skipped {skipped_hfo_count} HFOs due to no input activations\")\n",
    "        print(f\"Total HFOs (theoretical): {total_hfos}\")\n",
    "else:\n",
    "    print(\"Code Block already run. Skipping...\")\n",
    "\n",
    "print(\"Windowed Input Data Shape: \", windowed_input_data.shape)\n",
    "print(\"Windowed GT Shape: \", windowed_gt.shape)\n",
    "print(\"Filtered Windows Shape: \", filtered_windows.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Save the windowed \n",
    "# input data and ground truth to a file\n",
    "save=False\n",
    "if save:\n",
    "    windowed_save=os.path.join(curr_dir,\"windowed_data\")\n",
    "    os.makedirs(windowed_save, exist_ok=True)\n",
    "    np.save(os.path.join(windowed_save, \"windowed_input_data.npy\"), windowed_input_data, allow_pickle=True)\n",
    "    np.save(os.path.join(windowed_save,\"windowed_gt.npy\"), windowed_gt, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f2fdf",
   "metadata": {},
   "source": [
    "The code block above outputs:\n",
    "\n",
    "1. A list of time windows of shape =  `(num_windows, window_size, input_neurons) -- windowed_input_data`\n",
    "2. A list of labels of shape = `(num_windows, ) -- windowed_gt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1eed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mask for windows with an HFO (spike time >= 0) in the GT\n",
    "\n",
    "# TODO: Some ripples are detect outside the window - this is not compatible...\n",
    "# I have changed it to be 180 - might still be too close to the window size\n",
    "# Mesquita had clamped it differently.\n",
    "\n",
    "# See GT Class Distribution\n",
    "# Set print options to see more elements\n",
    "np.set_printoptions(linewidth=100, threshold=50, edgeitems=20)\n",
    "print(f\"Ground Truth Class Distribution: {np.unique(windowed_gt, return_counts=True)}\")\n",
    "\n",
    "\n",
    "\n",
    "GT_HFO_MASK = windowed_gt >= 0\n",
    "# print(windowed_gt[0:1000])\n",
    "# Define the number of windows with an HFO\n",
    "num_hfo_windows = np.sum(GT_HFO_MASK)\n",
    "print(f\"Number of windows with an HFO: {num_hfo_windows}\")\n",
    "print(f\"Percentage of windows with an HFO: {num_hfo_windows / windowed_gt.shape[0] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d72f4",
   "metadata": {},
   "source": [
    "**Note**: It's a good sign that the GT time is distributed along the time window.\n",
    "\n",
    "For example, if the GT annotation could only occur on the first 25% timesteps of the window, it could converge the network toward not spiking or spiking initially to minimize the loss.\n",
    "\n",
    "\n",
    "**QUESTION** : \n",
    " - How to deal with edge cases? \n",
    " - How to deal with the fact that there are a lot of them at the limit (175-180 ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63ff40",
   "metadata": {},
   "source": [
    "## Interpreting the Ground Truth Timestamp values\n",
    "- Lower limit: `MEAN_HFO_DURATION`\n",
    "- Upper limit: `RIPPLE[1]` (actually WINDOW_SIZE)\n",
    "\n",
    "Such that we only consider the ripples that are completely within the window.\n",
    "\n",
    "The Marker annotation is a timestamp that indicates the approximated end of the HFO event. It is bounded upwards and downwards by the variables mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4061f",
   "metadata": {},
   "source": [
    "# Class Balancing\n",
    "We can see that Class 0 (No HFO) is much more frequent than Class 1 (HFO). This is expected since HFOs are rare events. However, we need to be careful with **class imbalance**, as it can lead to model overfitting and poor generalization.\n",
    "\n",
    "- 6.51% of Windows -> HFO\n",
    "- 93.49% of Windows -> No HFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f66138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snnTorch.utils.training import undersample_majority, oversample_minority\n",
    "intermediate_input, intermediate_gt = windowed_input_data, windowed_gt  # Default: No Balancing\n",
    "balance=True\n",
    "if balance:\n",
    "    intermediate_input, intermediate_gt = undersample_majority(windowed_input_data, windowed_gt, GT_HFO_MASK)  \n",
    "\n",
    "# Print the number of samples in each class\n",
    "print(f\"Intermediate GT Class Distribution: {np.unique(intermediate_gt, return_counts=True)}\")\n",
    "print(f\"Intermediate Window Input Data Shape: {intermediate_input.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e28814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices to sort the input data by the nÂº of UP/DN spikes (descending order)\n",
    "intermediate_sorted_indices = np.argsort(\n",
    "    -(np.sum(intermediate_input[:, :, 0], axis=1) + np.sum(intermediate_input[:, :, 1], axis=1)), \n",
    ")\n",
    "\n",
    "# Sort the input data and GT data by the sorted indices\n",
    "intermediate_sorted_input = intermediate_input[intermediate_sorted_indices]\n",
    "intermediate_sorted_gt = intermediate_gt[intermediate_sorted_indices]\n",
    "\n",
    "print(f\"intermediate_sorted_indices: {intermediate_sorted_indices}\")\n",
    "print(f\"intermediate_sorted_input: {intermediate_sorted_input.shape} | intermediate_sorted_gt: {intermediate_sorted_gt.shape}\")\n",
    "print(f\"intermediate_sorted_gt preview: {intermediate_sorted_gt[:10]}\")\n",
    "print(f\"GT first window: {intermediate_sorted_gt[0]} | GT last window: {intermediate_sorted_gt[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da77add",
   "metadata": {},
   "source": [
    "## Split sorted GT Samples into Time bins to select number of non-HFO Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33bdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GT time bins to stratify the GT events\n",
    "num_bins = 12\n",
    "# Define bins explicitly to handle the -1 GT\n",
    "bin_edges = np.linspace(intermediate_sorted_gt[intermediate_sorted_gt >= 0].min(), intermediate_sorted_gt.max(), num_bins)\n",
    "# Add the -1 bin edge\n",
    "bin_edges = np.insert(bin_edges, 0, -1.1)   # Add edge below -1\n",
    "bin_edges = np.unique(bin_edges)   # Remove duplicates\n",
    "print(bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import cut\n",
    "intermediate_binned_gt = cut(intermediate_sorted_gt, bins=bin_edges, labels=False, include_lowest=True)\n",
    "\n",
    "# Print the number of samples in each bin\n",
    "unique_bins, unique_counts = np.unique(intermediate_binned_gt, return_counts=True)\n",
    "print(f\"Binned GT Class Distribution: {np.unique(intermediate_binned_gt, return_counts=True)}\")\n",
    "print(f\"There are {len(unique_bins)} bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89df22",
   "metadata": {},
   "source": [
    "`intermediate_binned_gt` is a numpy array of shape (num_bins) containing the index of the GT time bin for each window\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07588405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the max. number of elements in a bin excluding the -1 bin\n",
    "# unique_bins idx 0 is the -1 bin\n",
    "# Only select MAJORITY_FACTOR * max_bin_size samples with gt=-1\n",
    "MAJORITY_FACTOR = 3 # 2 # 1 \n",
    "max_bin_size = int(np.sum(unique_counts[unique_bins > 0]) / MAJORITY_FACTOR) #all ripples\n",
    "print(f\"Max bin size: {max_bin_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define Mask for Definitive Windows used\n",
    "    We will use max_bin_size windows with GT=-1\n",
    "'''\n",
    "\n",
    "# Get the indices of the sample windows with gt=-1\n",
    "ALL_GT_MINUS_1_MASK = intermediate_binned_gt == 0\n",
    "print(f\"Selecting {max_bin_size} samples with GT=-1\")\n",
    "\"\"\" \n",
    "Since intermediate_sorted_input contains the sorted input data, we can select the first max_bin_size samples with gt=-1.\n",
    "This way, the selected GT=-1 samples will contain the most UP/DN spikes, forcing the network to differentiate the HFO events\n",
    "from the non-HFO events with more UP/DN spikes.\n",
    "\"\"\"\n",
    "GT_MINUS_1_INDICES = np.where(ALL_GT_MINUS_1_MASK)[0][:max_bin_size]\n",
    "print(f\"GT_MINUS_1_INDICES: {GT_MINUS_1_INDICES}\")\n",
    "\n",
    "# Define Mask for the selected indices with GT=-1\n",
    "GT_MINUS_1_MASK = np.zeros(ALL_GT_MINUS_1_MASK.shape, dtype=bool)   # Create a mask of the same shape as the input data\n",
    "for selected_idx in GT_MINUS_1_INDICES:\n",
    "    GT_MINUS_1_MASK[selected_idx] = True   # Set the selected indices to True\n",
    "\n",
    "# Define Mask for the definitive windows\n",
    "BALANCED_WINDOWS_MASK = GT_MINUS_1_MASK | (~ALL_GT_MINUS_1_MASK)   # Get the indices some samples with gt=-1 + gt!=-1\n",
    "\n",
    "# Define the Balanced input and gt data\n",
    "balanced_input = intermediate_sorted_input[BALANCED_WINDOWS_MASK]\n",
    "balanced_gt = intermediate_sorted_gt[BALANCED_WINDOWS_MASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae037f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of samples in each class\n",
    "print(f\"Balanced GT Class Distribution: {np.unique(balanced_gt, return_counts=True)}\")\n",
    "print(f\"Balanced Window Input Data Shape: {balanced_input.shape}\")\n",
    "hfo_percent = np.sum(balanced_gt >= 0) / balanced_gt.shape[0] * 100\n",
    "print(f\"Percentage of windows with an HFO: {hfo_percent:.2f}%\")\n",
    "print(f\"Baseline Accuracy (No Spiking): {100 - hfo_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_gt = cut(balanced_gt, bins=bin_edges, labels=False, include_lowest=True)\n",
    "\n",
    "# Print the number of samples in each bin\n",
    "unique_bins, unique_counts = np.unique(binned_gt, return_counts=True)\n",
    "print(f\"Binned GT Class Distribution: {np.unique(binned_gt, return_counts=True)}\")\n",
    "print(f\"There are {len(unique_bins)} bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47cb9e",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets\n",
    "Since we split the input into windows, we can use it without worrying about sample order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Split the data into training and testing\n",
    "train_proportion = 0.85      # Portion of the data to be used for training\n",
    "\n",
    "train_data, test_data, train_gt, test_gt = train_test_split(\n",
    "    balanced_input, balanced_gt,\n",
    "    train_size=train_proportion, \n",
    "    stratify=binned_gt,    # Maintain the class balance based on the labels (balanced_gt)\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Training Data Shape: \", train_data.shape)\n",
    "print(\"Training Ground Truth Shape: \", train_gt.shape)\n",
    "print(\"Testing Data Shape: \", test_data.shape)\n",
    "print(\"Testing Ground Truth Shape: \", test_gt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of input activations in the training and testing data\n",
    "print(\"Number of Input Activations in Training Data: \", np.sum(train_data))\n",
    "print(\"Number of Input Activations in Testing Data: \", np.sum(test_data))\n",
    "\n",
    "# Print the Number Annotations in the training and testing data\n",
    "print(\"Number of HFO Samples in Training Data: \", np.sum(train_gt >= 0))\n",
    "print(\"Number of HFO Samples in Testing Data: \", np.sum(test_gt >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12130a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "train_data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "train_gt_tensor = torch.tensor(train_gt, dtype=torch.float32)\n",
    "\n",
    "test_data_tensor = torch.tensor(test_data, dtype=torch.float32)\n",
    "test_gt_tensor = torch.tensor(test_gt, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3617bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tensor Dataset\n",
    "train_dataset = TensorDataset(train_data_tensor, train_gt_tensor)\n",
    "test_dataset = TensorDataset(test_data_tensor, test_gt_tensor)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 2  # 2\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,   # Do we want to force training one by one, i.e., batch_size=1?\n",
    "    shuffle=True,   # TODO: We are shuffling because each window resets the state of the network so it should not matter. Might not be the case for RNNs!!\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show how many batches are in the training and testing data\n",
    "print(\"Number of Training Batches: \", len(train_loader))\n",
    "print(\"Number of Testing Batches: \", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e769f",
   "metadata": {},
   "source": [
    "## Define the Network\n",
    "### Define the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e52010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import functional as SF\n",
    "from snnTorch.utils.loss import mse_temporal_loss_penalty, first_spike_acc\n",
    "\n",
    "'''\n",
    "Define the loss function\n",
    "Let's use the mse_temporal_loss - Mean Squared Error Loss Temporal Loss.\n",
    "\n",
    "Forward function:\n",
    "Parameters:\n",
    "    - output: Predictions of the network - First spike time of each output neuron.\n",
    "        shape: torch.Tensor shape=(batch_size, num_classes) \n",
    "    - target:  Ground truth of the network - First spike time of each output neuron.\n",
    "        shape: torch.Tensor shape=(batch_size, num_timesteps)\n",
    "Returns:\n",
    "    - loss: The loss value \n",
    "        shape: torch.Tensor shape=()\n",
    "\n",
    "The loss function calculates the MSE loss of the first spike time of each output neuron.\n",
    "If the output neuron spikes within the tolerance window, the loss is 0.\n",
    "If the output neuron does not spike -> Considers it to spike at the last timestep and calculates the loss accordingly.\n",
    "Note: The spike time is divided by the number of timesteps to normalize it between 0 and 1 -> Loss gets pretty low values\n",
    "'''\n",
    "PENALTY_FACTOR = 1     # 1.5  # 1    # Penalty factor for the loss function (Extreme cases)\n",
    "\n",
    "\n",
    "loss_fn = mse_temporal_loss_penalty(\n",
    "    # target_is_time=True -> Target is the spike time (time step) of each output neuron. If false, the target is the gt class and the spike time of each class is fixed\n",
    "    target_is_time=True,\n",
    "    tolerance=PRED_GT_TOLERANCE,       # Tolerance for the mse loss (in timesteps). If the output neuron spikes within this tolerance, the loss is 0\n",
    "    reduction='mean',        # Average the loss across the batch\n",
    "    penalty_factor=PENALTY_FACTOR,\n",
    "    normalize=False, # True      # Whether to normalize the loss by the number of timesteps \n",
    ")\n",
    "\n",
    "\"\"\" loss_fn = SF.mse_temporal_loss(\n",
    "    target_is_time=True,\n",
    "    tolerance=PRED_GT_TOLERANCE,       # Tolerance for the mse loss (in timesteps). If the output neuron spikes within this tolerance, the loss is 0\n",
    "    reduction='mean'  # 'mean',          # Average the loss across the batch OR Sum the loss across the batch\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2092281",
   "metadata": {},
   "source": [
    "##  Define the Parameters of the Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c32a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "import torch.nn as nn\n",
    "from snntorch import surrogate\n",
    "\n",
    "# Global Parameters\n",
    "v_thr = 1.0\n",
    "\n",
    "# Define the surrogate gradient function to propagate spikes through the network\n",
    "spike_grad = surrogate.fast_sigmoid()   # surrogate.atan()  # TODO: Try other surrogate from paper   \n",
    "\n",
    "# Parameters for LIF neurons\n",
    "# TODO: Make parameters learnable or at least distribute them in a better way\n",
    "\n",
    "# Define the distribution for the parameters (alpha and beta)\n",
    "alpha_mean, alpha_std = 0.5, 0.2    \n",
    "beta_mean, beta_std = 0.5, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Dense Layers\n",
    "inputDataDim = 2 # UP DN   # max_channel_idx - min_channel_idx + 1    # Number of input channels\n",
    "\n",
    "input_to_hidden = (inputDataDim, 24) # 24 # 16 # TODO: Increase the size of this layer # (inputDataDim, 100) # (inputDataDim, 500)  # Number of neurons in the first Fully-Connected Layer\n",
    "\n",
    "hiddenL2Dim = (input_to_hidden[1], input_to_hidden[1])  # Number of neurons in the Recurrent Fully-Connected Layer (L2)\n",
    "\n",
    "hiddenL3Dim = (input_to_hidden[1], 16)  # 16 # Number of neurons in the Fully-Connected Layer (L3)\n",
    "\n",
    "hiddenL4Dim = (hiddenL3Dim[1], input_to_hidden[1])  # Number of neurons in the Recurrent Fully-Connected Layer (L4)\n",
    "\n",
    "hidden_to_out = (hiddenL3Dim[1], 1)  # Number of neurons in the Output Fully-Connected Layer\n",
    "# In this case, we only need 1 output neuron -> Fires when HFO is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random distribution for the current and membrane decays\n",
    "alpha_lif1 = torch.normal(mean=torch.full(size=(input_to_hidden[1],), fill_value=alpha_mean), std=torch.full(size=(input_to_hidden[1],), fill_value=alpha_std))\n",
    "beta_lif1 = torch.normal(mean=torch.full(size=(input_to_hidden[1],), fill_value=beta_mean), std=torch.full(size=(input_to_hidden[1],), fill_value=beta_std))\n",
    "alpha_lif2 = torch.normal(mean=torch.full(size=(hiddenL3Dim[1],), fill_value=alpha_mean), std=torch.full(size=(hiddenL3Dim[1],), fill_value=alpha_std))\n",
    "beta_lif2 = torch.normal(mean=torch.full(size=(hiddenL3Dim[1],), fill_value=beta_mean), std=torch.full(size=(hiddenL3Dim[1],), fill_value=beta_std))\n",
    "\n",
    "# Clip the value to be positive\n",
    "TIME_CONSTANT_MIN = 1e-2\n",
    "TIME_CONSTANT_MAX = 0.99\n",
    "alpha_lif1 = torch.clamp(alpha_lif1, min=0.05, max=0.95)\n",
    "beta_lif1 = torch.clamp(beta_lif1, min=0.05, max=0.95)\n",
    "alpha_lif2 = torch.clamp(alpha_lif2, min=0.05, max=0.95)\n",
    "beta_lif2 = torch.clamp(beta_lif2, min=0.05, max=0.95)\n",
    "\n",
    "# TODO: Check these values?\n",
    "alpha_lif_out = 0.5\n",
    "beta_lif_out = 0.5\n",
    "\n",
    "# Print the parameters\n",
    "print(f\"LIF1 Alpha: {alpha_lif1} |\\nBeta: {beta_lif1} |\\n Shape: {alpha_lif1.shape}\")\n",
    "print(f\"\\nLIF2 Alpha: {alpha_lif2} |\\nBeta: {beta_lif2} |\\n Shape: {alpha_lif2.shape}\")\n",
    "print(f\"\\nLIF OUT Alpha: {alpha_lif_out} | Beta: {beta_lif_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d359a",
   "metadata": {},
   "source": [
    "## Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        \n",
    "        # Create a Linear Layer to serve input to LIF1\n",
    "        self.fc_in = nn.Linear(input_to_hidden[0], input_to_hidden[1],\n",
    "                bias=False,\n",
    "                dtype=torch.float32     # Set the data type of the weights to float32\n",
    "        )\n",
    "\n",
    "        # TODO: Should the LIF neurons be able to get a negative membrane potential? I think so?\n",
    "        self.lif1 = snn.Synaptic(\n",
    "            alpha=alpha_lif1, beta=beta_lif1, threshold=v_thr,\n",
    "            reset_mechanism=\"zero\", reset_delay=False,\n",
    "            # TODO: How to add Refractory Period?\n",
    "            # init_hidden=True,   # enables the methods in snntorch.backprop to automatically clear the hidden states and detach them from the comp. graph\n",
    "            spike_grad=spike_grad,\n",
    "            learn_alpha=True,   # Learn the alpha parameter\n",
    "            learn_beta=True,    # Learn the beta parameter\n",
    "            learn_threshold=False,   # Learn the threshold parameter\n",
    "        )      \n",
    "\n",
    "        \"\"\" self.fc2 = nn.Linear(\n",
    "            hiddenL2Dim[0], hiddenL2Dim[1],\n",
    "            bias=False,\n",
    "            dtype=torch.float32     # Set the data type of the weights to float32\n",
    "        ) \"\"\"\n",
    "\n",
    "        self.fc3 = nn.Linear(\n",
    "            hiddenL3Dim[0], hiddenL3Dim[1],\n",
    "            bias=False,\n",
    "            dtype=torch.float32     # Set the data type of the weights to float32\n",
    "        )\n",
    "\n",
    "        self.lif2 = snn.Synaptic(\n",
    "            alpha=alpha_lif2, beta=beta_lif2, threshold=v_thr,\n",
    "            reset_mechanism=\"zero\", reset_delay=False,\n",
    "            # TODO: How to add Refractory Period?\n",
    "            # init_hidden=True,   # enables the methods in snntorch.backprop to automatically clear the hidden states and detach them from the comp. graph\n",
    "            spike_grad=spike_grad,\n",
    "            learn_alpha=True,   # Learn the alpha parameter\n",
    "            learn_beta=True,    # Learn the beta parameter\n",
    "            learn_threshold=False,   # Learn the threshold parameter\n",
    "            # inhibition=True,   # If true, surpresses all spiking other than the neuron with the highest potential\n",
    "        ) \n",
    "\n",
    "        \"\"\" self.fc4 = nn.Linear(\n",
    "            hiddenL4Dim[0], hiddenL4Dim[1],\n",
    "            bias=False,\n",
    "            dtype=torch.float32     # Set the data type of the weights to float32\n",
    "        ) \"\"\"\n",
    "\n",
    "        self.fc_out = nn.Linear(\n",
    "            hidden_to_out[0], hidden_to_out[1],\n",
    "            bias=False,\n",
    "            dtype=torch.float32     # Set the data type of the weights to float32\n",
    "        )\n",
    "\n",
    "        self.lif_out = snn.Synaptic(\n",
    "            alpha=alpha_lif_out, beta=beta_lif_out, threshold=v_thr,\n",
    "            reset_mechanism=\"zero\", reset_delay=False,\n",
    "            # init_hidden=True,   # enables the methods in snntorch.backprop to automatically clear the hidden states and detach them from the comp. graph\n",
    "            spike_grad=spike_grad,\n",
    "            learn_alpha=True,   # Learn the alpha parameter\n",
    "            learn_beta=True,    # Learn the beta parameter\n",
    "            learn_threshold=False,   # Learn the threshold parameter\n",
    "            # inhibition=True,   # If true, surpresses all spiking other than the neuron with the highest potential\n",
    "        )\n",
    "        \n",
    "    \"\"\"\n",
    "    Function called during the forward pass of the network\n",
    "    \"\"\"\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        '''\n",
    "        Forward Pass of the Network\n",
    "\n",
    "        Parameters:\n",
    "        - x: input tensor. Shape: (batch_size, num_steps, num_features)\n",
    "\n",
    "        Returns:\n",
    "        - spk_rec: tuple of tensors containing the spikes of the neurons\n",
    "        - mem_rec: tuple of tensors containing the membrane potentials of the neurons\n",
    "        - cur_rec: tuple of tensors containing the currents of the neurons\n",
    "        '''\n",
    "        '''\n",
    "        print(f\"Input Shape: {x.shape}\")\n",
    "        Get the batch size and input data dimension\n",
    "        '''\n",
    "        cur_batch_size, cur_num_steps, cur_num_channels = x.shape\n",
    "\n",
    "        # Reset the hidden states of the neurons (membrane potentials, currents, and spikes)\n",
    "        syn1, mem1 = self.lif1.reset_mem()\n",
    "        syn2, mem2 = self.lif2.reset_mem()\n",
    "        syn_out, mem_out = self.lif_out.reset_mem()\n",
    "\n",
    "        # Define small residual for spk1\n",
    "        #TODO : Check if this is necessary...\n",
    "        spk1_factor = 0.01\n",
    "        spk1 = torch.rand(size=(cur_batch_size, input_to_hidden[1]), dtype=torch.float32, device=device) * spk1_factor\n",
    "        spk2 = torch.zeros(size=(cur_batch_size, hiddenL3Dim[1]), dtype=torch.float32, device=device) * spk1_factor\n",
    "        spk_out = torch.zeros(size=(cur_batch_size, hidden_to_out[1]), dtype=torch.float32, device=device)\n",
    "        # preview_np_array(spk1, \"spk1\", edge_items=5)\n",
    "        \n",
    "        # Record the neuron's spikes, membrane potentials and currents for each Neuron Layer\n",
    "        # Shape of each Rec: (num_lif_layers=2, num_steps, batch_size, num_neurons)\n",
    "        cur_rec: tuple[torch.Tensor[float], torch.Tensor[float], torch.Tensor[float]] = ([], [], [])\n",
    "        mem_rec: tuple[torch.Tensor[float], torch.Tensor[float], torch.Tensor[float]] = ([], [], [])\n",
    "        spk_rec: tuple[torch.Tensor[float], torch.Tensor[float], torch.Tensor[float]] = ([], [], [])\n",
    "\n",
    "        # TODO: Here, having + PRED_CAUSALITY WINDOW MIGHT NOT BE NECESSARY?\n",
    "        # NOTE: I think it is, to assure the LIF neurons have time after the actual event time\n",
    "        # to update their inner state and be able to spike.\n",
    "        \n",
    "        for step in range(WINDOW_SIZE + PRED_CAUSALITY_WINDOW):         #  \n",
    "            # Define the default input for step > WINDOW_SIZE\n",
    "            # No actiation after the window size (only to include network updates for the PRED_CAUSALITY_WINDOW)\n",
    "            curr_input = torch.zeros(size=(cur_batch_size, cur_num_channels), dtype=torch.float32, device=device)\n",
    "\n",
    "            if step < WINDOW_SIZE:\n",
    "                # Get the current input from x\n",
    "\n",
    "                # curr_input Shape: (batch_size, num_channels)\n",
    "                curr_input = x[:, step, :]     # Get the current input for all the batch elements\n",
    "            \n",
    "                if len(curr_input.shape) == 1:\n",
    "                    # If the input is 1D, it means we have only one feature (one channel)\n",
    "                    # Unsqueeze the input to add the num_features dimension\n",
    "                    curr_input = curr_input.unsqueeze(1)\n",
    "\n",
    "            \n",
    "            ############# State Update #############\n",
    "            # Calculate Input Current for LIF1 from the Input Layer (FC1) Input -> LIF1\n",
    "            cur_fc_in = self.fc_in(curr_input) \n",
    "        \n",
    "            # Calculate Input Current from Recurrent Layer (FC2) LIF1 -> LIF1\n",
    "            # cur_fc2 = self.fc2(spk1)   # Connect LIF1 to itself using FC Layer 2 (Recurrent Layer)\n",
    "\n",
    "            # Calculate Input Current From Recurrent Layer (FC4) LIF2 -> LIF1\n",
    "            # cur_fc4 = self.fc4(spk2)    # Connect LIF2 to LIF1 using FC Layer 4 (Recurrent Layer)\n",
    "\n",
    "            # Join the input currents for LIF1 (FC1 + FC2)\n",
    "            cur1 = cur_fc_in # + cur_fc4  # + cur_fc2  # TODO: Not feeding Recurent Layer to LIF1 for now\n",
    "\n",
    "            # Feed the joined input current to LIF1\n",
    "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)  # Feed input to LIF1\n",
    "\n",
    "            # Calculate Input Current for LIF2 from LIF1 (FC3) LIF1 -> LIF2\n",
    "            cur2 = self.fc3(spk1)   # Connect LIF1 to LIF2 using FC Layer 3\n",
    "            # Feed the input current to LIF2 and get the spikes, synaptic currents and membrane potentials\n",
    "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)  # Feed input to LIF2\n",
    "\n",
    "            # Calculate Input Current for LIF_OUT from LIF2 (FC4) LIF2 -> LIF_OUT\n",
    "            cur_out = self.fc_out(spk2)\n",
    "            # Feed the input current to LIF_OUT and get the spikes, synaptic currents and membrane potentials\n",
    "            spk_out, syn_out, mem_out = self.lif_out(cur_out, syn_out, mem_out)  # Feed input to LIF_OUT\n",
    "\n",
    "            # Record the currents, membrane potentials and spikes\n",
    "            cur_rec[0].append(cur1), cur_rec[1].append(cur2), cur_rec[2].append(cur_out)\n",
    "            mem_rec[0].append(mem1), mem_rec[1].append(mem2), mem_rec[2].append(mem_out)\n",
    "            spk_rec[0].append(spk1), spk_rec[1].append(spk2), spk_rec[2].append(spk_out)\n",
    "\n",
    "        # Return the recorded currents, membrane potentials and spikes\n",
    "        # Convert the lists to tensors and stack them along the first dimension\n",
    "        cur_rec = tuple([torch.stack(cur, dim=0) for cur in cur_rec])\n",
    "        mem_rec = tuple([torch.stack(mem, dim=0) for mem in mem_rec])\n",
    "        spk_rec = tuple([torch.stack(spk, dim=0) for spk in spk_rec])\n",
    "\n",
    "        # TODO: Check if the dimensions are correct\n",
    "        return (\n",
    "            spk_rec, mem_rec, cur_rec, \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd798b2",
   "metadata": {},
   "source": [
    "The code in the `forward()` function will only be called once the input argument x is explicitly passed to the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_layers = [\"fc2\", \"fc4\"]  # List w/ name of recurrent layers\n",
    "positive_bias = [   # List w/ name of layers that should have positive bias in the weights\n",
    "    # \"fc_in\",\n",
    "    \"fc3\",\n",
    "    \"fc_out\"\n",
    "]  \n",
    "POSITIVE_INC = 0.4\n",
    "\n",
    "def weight_init(net: Net):\n",
    "    '''\n",
    "    Initialize the weights of the network (Linear Layers)\n",
    "\n",
    "    Parameters:\n",
    "        net: The network to initialize\n",
    "    '''\n",
    "    linear_layer_idx = 0\n",
    "\n",
    "    # Iterate over the Linear Layers in the network\n",
    "    for name, layer in net.named_children():\n",
    "        # print(f\"Layer: {name} - {layer}\")\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            # print(f\"Layer: {layer.in_features } -> {layer.out_features}\")\n",
    "            if name in recurrent_layers:\n",
    "                # Second linear layer (Recurrent Layer) -> Initialize the weights using orthogonal initialization\n",
    "                # Orthogonal initialization is used to promote stable gradient propagation and prevent vanishing/exploding gradients\n",
    "                nn.init.orthogonal_(layer.weight)\n",
    "            elif name in positive_bias:\n",
    "                nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    # Create a mask for incrementable weights\n",
    "                    INTERVAL_WEIGHTS_MASK = (layer.weight.data >= 0) & (layer.weight.data < (1 - POSITIVE_INC))\n",
    "                    # Offset the weights to be positive\n",
    "                    layer.weight.data[INTERVAL_WEIGHTS_MASK] += POSITIVE_INC\n",
    "            else:\n",
    "                # If it's not the first linear layer, initialize the weights between -1 and 1\n",
    "                # nn.init.uniform_(layer.weight, a=-1, b=1)\n",
    "                nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "            # Increment the linear layer index\n",
    "            linear_layer_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network onto CUDA if available\n",
    "net = Net().to(device)\n",
    "\n",
    "# Initialize the weights of the network\n",
    "weight_init(net)\n",
    "\n",
    "# print the network\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9820956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Initial network to a file to preserve the initial weights\n",
    "SAVE_NETWORK = False\n",
    "if SAVE_NETWORK:\n",
    "    torch.save(net.state_dict(), \"./out/hfo/initial_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Initial network from a file\n",
    "LOAD_NETWORK = False\n",
    "# TODO: Initial weights don't have to be loaded? Could just be random\n",
    "if LOAD_NETWORK:\n",
    "    net.load_state_dict(torch.load(\"./out/hfo/initial_weights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbafeb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the network architecture\n",
    "untrained_params = []\n",
    "untrained_total_params = 0\n",
    "# Iterate through the layers of the network\n",
    "for idx, (name, param) in enumerate(net.named_parameters()):\n",
    "    # Add the parameter to the list of untrained parameters\n",
    "    untrained_params.append(param.clone())\n",
    "\n",
    "    # print(\"param: \", param)\n",
    "    if param.shape == torch.Size([]):\n",
    "        print(f\"Scalar Param ({name}) | Shape={param.shape} | Value={param} \\n\")\n",
    "    elif len(param.shape) == 1:\n",
    "        print(f\"Vector Param ({name}) | Shape={param.shape} | Value={param} \\n\")\n",
    "    else:\n",
    "        print(f\"Tensor Param ({name}) | Shape={param.shape}. Total={param.numel()} Preview: {param}\\n\")\n",
    "\n",
    "    # Add the number of parameters in the layer to the total\n",
    "    untrained_total_params += param.numel()\n",
    "\n",
    "# Print the total number of parameters in the network\n",
    "print(f\"Total Parameters: {untrained_total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726abeee",
   "metadata": {},
   "source": [
    "## Define the Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755eb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define the Learning Rate.\n",
    "Using a LR based on the window size, since our loss function is also dependent on the window size.\n",
    "Another alternative is to normalize the loss function by the window size.\n",
    "'''\n",
    "learning_rate = 1e-4   # (1 / (WINDOW_SIZE**2)) # 5e-1   #1e-2    # 1e-1   # (1 / (WINDOW_SIZE**2)) * 10 # * 1e-1    # * 10    # 1e-3 # 1e-1\n",
    "\n",
    "# Define Learning Rate for Alpha and Beta Parameters\n",
    "time_constant_params = {\n",
    "    \"params\": [net.lif1.alpha, net.lif1.beta, net.lif2.alpha, net.lif2.beta, net.lif_out.alpha, net.lif_out.beta],\n",
    "    \"lr\": learning_rate # * 0.1,   # Make these parameters learn slower than the weights\n",
    "}   # * 10\n",
    "increased_lr_params = {\n",
    "    \"params\": [net.fc_in.weight],\n",
    "    \"lr\": learning_rate * 5,   # Make these parameters learn faster than the default\n",
    "}\n",
    "other_params = {\n",
    "    \"params\": [param for name, param in net.named_parameters() if name not in [\"lif1.alpha\", \"lif1.beta\", \"lif2.alpha\", \"lif2.beta\", \"lif_out.alpha\", \"lif_out.beta\", \"fc_in.weight\"]],\n",
    "    \"lr\": learning_rate,   # Default learning rate\n",
    "}\n",
    "\n",
    "param_groups = [\n",
    "    time_constant_params,\n",
    "    increased_lr_params, \n",
    "    other_params\n",
    "]\n",
    "\n",
    "print(f\"Number of time constant params: {len(time_constant_params['params'])}\")\n",
    "print(f\"Number of increased LR params: {len(increased_lr_params['params'])}\")\n",
    "print(f\"Number of other params: {len(other_params['params'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# The Adam Optimizer is an adaptive learning rate optimization algorithm\n",
    "# that is based on the adaptive estimation of first-order and second-order moments.\n",
    "# The learning rate is defined for each parameter and is updated during training.\n",
    "# NOTE: Should I define the learning rate for each layer parameters separately?\n",
    "'''\n",
    "\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     param_groups, lr=learning_rate,\n",
    "#     betas=(0.9, 0.999),  # TODO: What are these betas? How much past gradients influence the current gradient? How much past squared gradients influence the current gradient?\n",
    "#     weight_decay=0   # Pushes the weights towards 0 (L2 Regularization)\n",
    "# )  \n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    param_groups, lr=learning_rate,\n",
    "    weight_decay=0,\n",
    "    momentum=0,      # 0.6, # Note: setting to 0 to simplify the optimizer\n",
    "    dampening=0\n",
    ")\n",
    "\n",
    "# Define a scheduler for the learning rate\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer,\n",
    "    gamma=0.8   # Decrease the learning rate by 10% every epoch\n",
    ")\n",
    "\n",
    "print(f\"learning_rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the learning rate for each parameter group\n",
    "for group_idx, param_group in enumerate(optimizer.param_groups):\n",
    "    print(f\"Param Group {group_idx} | Learning Rate: {param_group['lr']}\")\n",
    "    # Show parameters shape inside this group\n",
    "    for param in param_group['params']:\n",
    "        print(f\"Param Shape: {param.shape}\")\n",
    "\n",
    "    print(\"====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_step(\n",
    "        data: torch.Tensor, gt: torch.Tensor, \n",
    "        is_train: bool = True,\n",
    "        verbose=False, print_params=False,\n",
    "        print_first_spike_times=False\n",
    "    ) -> tuple[float, float]:\n",
    "    '''\n",
    "    Perform a training step for the network\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data: torch.Tensor\n",
    "        The input data for the network. Shape: (num_batches, num_steps).\n",
    "    gt: torch.Tensor\n",
    "        The ground truth for the network. Shape: (batch_size,).\n",
    "        Since we are using a first-time-to-spike loss function, the ground truth is the time step of the first spike of the neuron. (or -1 if spiking on the last timestep)\n",
    "    verbose: bool\n",
    "        Whether to print debug information\n",
    "    print_params: bool\n",
    "        Whether to print the parameters of the network before the forward pass\n",
    "    print_first_spike_times: bool\n",
    "        Whether to print the first spike times\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple (loss, accuracy).\n",
    "    - loss: float\n",
    "        The loss value for the current batch.\n",
    "    - accuracy: float\n",
    "        The accuracy value for the current batch.\n",
    "    '''\n",
    "    if is_train:\n",
    "        net.train() # Set the network to training mode\n",
    "    else:\n",
    "        net.eval()  # Set the network to evaluation mode\n",
    "\n",
    "    if print_params:\n",
    "        # Show the Network State before the forward pass\n",
    "        print(\"Network Parameters before Forward Pass\")\n",
    "        for idx, param in enumerate(net.parameters()):\n",
    "            print(f\"Layer {idx} Parameters Shape={param.shape} | Preview: {param}\\n\")\n",
    "\n",
    "        print(\"=====================================\\n\")\n",
    "\n",
    "    if verbose:\n",
    "        # View the shape of the data\n",
    "        # print(f\"Data Shape: {data.shape} | Value={data[:10]}\")\n",
    "        print(f\"Data Shape: {data.shape}\")\n",
    "        print(f\"Number of Input Activations: {torch.sum(data)}\")\n",
    "        print(f\"Targets Shape: {gt.shape} |  Value={gt.tolist()}\")\n",
    "        # print(f\"Targets Shape: {gt.shape}\")\n",
    "        print(\"=====================================\\n\")\n",
    "\n",
    "    # Feed a single batch of data through the network\n",
    "    spikes, mem, cur = net(data)\n",
    "    if verbose:\n",
    "        # Print the shapes of the recorded spikes, membrane potentials and currents lists\n",
    "        print(f\"Number of Spike/Voltage/Current Recorded lists: \", len(spikes), len(mem), len(cur))\n",
    "        print(\"=====================================\\n\")\n",
    "\n",
    "    if verbose:\n",
    "        # Show the Network State after the forward pass\n",
    "        lif1_spikes, lif2_spikes, lif_out_spikes = spikes\n",
    "        lif1_mem, lif2_mem, lif_out_mem = mem\n",
    "        lif1_cur, lif2_cur, lif_out_cur = cur\n",
    "\n",
    "        # Print the shapes of the recorded spikes, membrane potentials and currents\n",
    "        print(f\"Lif1 Spikes Shape: {lif1_spikes.shape} | Membrane Potentials Shape: {lif1_mem.shape} | Currents Shape: {lif1_cur.shape}\")\n",
    "        print(f\"Lif2 Spikes Shape: {lif2_spikes.shape} | Membrane Potentials Shape: {lif2_mem.shape} | Currents Shape: {lif2_cur.shape}\")\n",
    "        print(f\"Lif_Out Spikes Shape: {lif_out_spikes.shape} | Membrane Potentials Shape: {lif_out_mem.shape} | Currents Shape: {lif_out_cur.shape}\")\n",
    "\n",
    "        print(f\"Number of spikes in LIF1: {torch.sum(lif1_spikes)}\")\n",
    "        print(f\"Number of spikes in LIF2: {torch.sum(lif2_spikes)}\")\n",
    "        print(f\"Number of spikes in LIF_OUT: {torch.sum(lif_out_spikes)}\")\n",
    "        print(\"=====================================\\n\")\n",
    "    \n",
    "    # ------ Loss and Accuracy Calculation ------\n",
    "    out_spikes = spikes[-1]    # out_spikes shape = (num_steps, batch_size, num_neurons)\n",
    "\n",
    "    # Add num_features dimension to the ground truth tensor\n",
    "    gt = gt.unsqueeze(1)   # gt shape = (batch_size, 1)\n",
    "\n",
    "    # Calculate the loss for the current Batch\n",
    "    loss_val = loss_fn(out_spikes, gt.clone())   # Copy the ground truth to avoid modifying it in place\n",
    "\n",
    "    # Scale the loss value to account for class imbalance\n",
    "    \"\"\"\n",
    "    # This is a possible solution to the class imbalance problem. Does not seem to work well.\n",
    "    scaled_loss = loss_val.clone()  # Create a copy of the loss value\n",
    "    if gt.item() == 1:\n",
    "        # Class 1 has 1/4 of the input windows of class 0\n",
    "        # Scale the loss value by 4\n",
    "        scaled_loss *= 4\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the Accuracy\n",
    "    # There is no time tolerance for the accuracy calculation? -> The first spike time must be exactly the same?\n",
    "    # acc = SF.accuracy_temporal(out_spikes, gt)\n",
    "    acc = first_spike_acc(out_spikes, gt, tolerance=PRED_GT_TOLERANCE, verbose=False)\n",
    "\n",
    "    if verbose or print_first_spike_times:\n",
    "        # Find the first spike of each output neuron\n",
    "        first_spikes = torch.argmax(out_spikes, dim=0)\n",
    "\n",
    "        # If max spike value is 0 -> set the first spike to -1\n",
    "        first_spikes[first_spikes == 0] = -1\n",
    "\n",
    "        # Show the Output Spikes and Loss Value\n",
    "        print(f\"Output Spikes shape: {out_spikes.shape}. | First spike of each Output Neuron: {first_spikes}\\n\")\n",
    "    if verbose:\n",
    "        print(f\"Loss val shape: {loss_val.shape} | Value: {loss_val.item()}\")\n",
    "        print(f\"Accuracy Shape: {acc.shape} | Value: {acc.item()}\")\n",
    "        print(\"=====================================\\n\")\n",
    "\n",
    "    # ------ Backward Pass (Gradient calculation and weight updates) ------\n",
    "    if not is_train:\n",
    "        # If we are not training, return the loss value and evaluation metrics (no backpropagation)\n",
    "        return loss_val.item(), acc.item()\n",
    "    \n",
    "    # Save the previous weights\n",
    "    prev_weights = None\n",
    "    if verbose:\n",
    "        prev_weights = [param.clone() for (_name, param) in net.named_parameters()]\n",
    "    \n",
    "    # Gradient Calculation + Backpropagation (weight update)\n",
    "    optimizer.zero_grad()   # Zero the gradients\n",
    "    # Backpropagate the loss (Traverses the computational graph backward and applies the chain rule to \n",
    "    # update the .grad attribute of each parameter Tensor)\n",
    "    loss_val.backward()\n",
    "    \n",
    "    if verbose:\n",
    "        # Print the gradients of the network\n",
    "        print(\"Network Gradients\")\n",
    "        '''\n",
    "        The gradients are stored in the .grad attribute of each parameter Tensor.\n",
    "        NOTE: The .grad attibute stores the gradient of the loss function with respect to that specific parameter.\n",
    "        As such, it does not take the learning rate into account. The LR is only used during the optimizer.step() call.\n",
    "        Gradients are calculated when calling loss.backwrad(). Pytorch's autograd engine calculates the partial derivate for each parameter\n",
    "        and applies the chain rule to calculate the gradients.\n",
    "        '''\n",
    "        for idx, (name, param) in enumerate(net.named_parameters()):\n",
    "            if param.grad is None:\n",
    "                print(f\"Layer {name}(idx) Gradient: None\")\n",
    "                continue\n",
    "            print(f\"Layer {name}(idx) Gradient Shape={param.grad.shape} | Preview: {param.grad}\\n\")\n",
    "\n",
    "    # Uses the gradients calculated by .backward() to update the parameters\n",
    "    optimizer.step()        # Update the parameters\n",
    "\n",
    "    # Perform manual updates to restricted parameters\n",
    "    with torch.no_grad():\n",
    "        # Clamp the alpha parameter to be between TIME_CONSTANT_MIN and TIME_CONSTANT_MAX\n",
    "        net.lif1.alpha.data.clamp_(min=TIME_CONSTANT_MIN, max=TIME_CONSTANT_MAX)\n",
    "        net.lif1.beta.data.clamp_(min=TIME_CONSTANT_MIN, max=TIME_CONSTANT_MAX)\n",
    "        net.lif2.alpha.data.clamp_(min=TIME_CONSTANT_MIN, max=TIME_CONSTANT_MAX)\n",
    "        net.lif2.beta.data.clamp_(min=TIME_CONSTANT_MIN, max=TIME_CONSTANT_MAX)\n",
    "        net.lif_out.alpha.data.clamp_(min=TIME_CONSTANT_MIN, max=TIME_CONSTANT_MAX)\n",
    "        net.lif_out.beta.data.clamp_(min=TIME_CONSTANT_MIN, max=TIME_CONSTANT_MAX)\n",
    "\n",
    "        # Clamp the weights of the Linear Layers to be between -1 and 1\n",
    "        # TODO: Check if this is a good idea\n",
    "        # TODO: I don't think it is necessary...\n",
    "        # net.fc_in.weight.data.clamp_(min=-1, max=1)\n",
    "        # net.fc3.weight.data.clamp_(min=-1, max=1)\n",
    "        # net.fc_out.weight.data.clamp_(min=-1, max=1)\n",
    "        # # net.fc2.weight.data.clamp_(min=-1, max=1)\n",
    "        # # net.fc4.weight.data.clamp_(min=-1, max=1)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"=====================================\")\n",
    "        # print the changes in the weights\n",
    "        for idx, (prev, new) in enumerate(zip(prev_weights, net.named_parameters())):\n",
    "            param_name, new = new\n",
    "            \n",
    "            print(f\"Layer {param_name}({idx}) Shape: {new.shape} | Parameter Change: {torch.sum(torch.abs(new - prev)).item()}\")\n",
    "            print(f\"Prev Param: {prev} |\\nNew Param: {new}\\n\")\n",
    "            # print(f\"Prev weights: {prev} |\\nNew Weights: {new}\")\n",
    "        print(\"=====================================\\n\")\n",
    "\n",
    "    # Return the loss value and accuracy\n",
    "    return loss_val.item(), acc.item()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform training on the First Batch\n",
    "data, targets = next(iter(train_loader))\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Perform a training step\n",
    "forward_step(data, targets, is_train=True, verbose=True, print_params=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "889ffea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snnTorch.utils import training as tr_utils\n",
    "\n",
    "num_epochs = 2            # Number of epochs to train the network\n",
    "loss_hist = []              # History of the loss (train)\n",
    "test_loss_hist = []         # History of the test loss\n",
    "acc_hist = []               # History of the accuracy (train)\n",
    "test_acc_hist = []          # History of the test accuracy\n",
    "f1_hist = []                # History of the F1 Score (train)\n",
    "test_f1_hist = []           # History of the test F1 Score\n",
    "\n",
    "global_counter = 0          # Global Counter for the iterations\n",
    "\n",
    "max_iter = False # 8000 # 4000\n",
    "verbose_training = False    # For debugging purposes\n",
    "\n",
    "# Outer Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0                    # Counter for the iterations \n",
    "    train_batch = iter(train_loader)    # Iterator for the training data\n",
    "\n",
    "    # Print the Learning Rate for the current epoch\n",
    "    print(f\"Learning Rate for epoch {epoch}: {scheduler.get_last_lr()}\\n\")\n",
    "\n",
    "    # Minibatch training loop - Go through all the batches using the iterator\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)          # Send the data to the device (GPU or CPU)\n",
    "        targets = targets.to(device)    # Send the targets to the device (GPU or CPU)\n",
    "\n",
    "        # Perform a training step\n",
    "        loss_val, acc_val = forward_step(data, targets, is_train=True, verbose=False)\n",
    "\n",
    "        # Store the Loss History\n",
    "        loss_hist.append(loss_val)\n",
    "        # Append the accuracy to the accuracy history\n",
    "        acc_hist.append(acc_val)\n",
    "        \n",
    "        # Print if target has at least 1 spike\n",
    "        # It is not like this anymore...\n",
    "        # if verbose_training and torch.sum(targets) > 0:\n",
    "        #     print(f\"Epoch: {epoch} | Iteration: {iter_counter} has a Ripple!\")\n",
    "\n",
    "        '''\n",
    "        Test Set Evaluation\n",
    "            Evaluate the network on a single Time Window from the Test Set to track the training's progress\n",
    "        Only Evaluate on the Test Set every 50 iterations\n",
    "        '''\n",
    "        if global_counter % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                net.eval()  # Set the network to evaluation mode\n",
    "                curr_test_data, curr_test_gt = next(iter(test_loader))  # Get the next test data\n",
    "\n",
    "                curr_test_data = curr_test_data.to(device)    # Send the test data to the device\n",
    "                curr_test_gt = curr_test_gt.to(device)        # Send the test ground truth to the device\n",
    "\n",
    "                # Perform a Test Step\n",
    "                test_loss_val, test_acc_val = forward_step(curr_test_data, curr_test_gt, is_train=False, verbose=False, print_first_spike_times=True)\n",
    "\n",
    "                # Store the Test Loss History\n",
    "                test_loss_hist.append(test_loss_val)\n",
    "                # Append the accuracy to the accuracy history\n",
    "                test_acc_hist.append(test_acc_val)\n",
    "\n",
    "                # Print Train/Test Loss/Accuracy\n",
    "                tr_utils.train_printer(\n",
    "                    epoch, iter_counter,\n",
    "                    loss_val, test_loss_val, \n",
    "                    acc_val, test_acc_val,\n",
    "                )\n",
    "\n",
    "        iter_counter += 1       # Increment the iteration counter\n",
    "        global_counter += 1     # Increment the global counter\n",
    "\n",
    "        if max_iter and iter_counter > max_iter:\n",
    "            break   # Stop the training loop\n",
    "\n",
    "    # Update the Learning Rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1a0c3",
   "metadata": {},
   "source": [
    "## Results\n",
    "Plot Loss and Accuracy Curves during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5412071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABmsAAAHWCAYAAACYKb1QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACsCElEQVR4nOzdd3gU1f7H8U8CJAGkCgRQBGwggqCoiAqiIlFRxHbBiohy9YKKeC1YAEFFUVAUhJ/SLCCIV1EBgdB7C4TeAgkJJQkhpJO6+/sDWROySbbPlvfrefLAzp45893Z2dmd851zTpDZbDYLAAAAAAAAAAAAhgg2OgAAAAAAAAAAAIBARrIGAAAAAAAAAADAQCRrAAAAAAAAAAAADESyBgAAAAAAAAAAwEAkawAAAAAAAAAAAAxEsgYAAAAAAAAAAMBAJGsAAAAAAAAAAAAMRLIGAAAAAAAAAADAQCRrAAAAAAAAAAAADESyBgDgEs8884yaNWtmdBgAAAAA4DJc5wAAPIVkDQD4uaCgIJv+VqxYYXSopcTFxalv37667LLLFBYWpoYNG6pz584aNmyYQ/UtWLBAw4cPt7l8ly5d1Lp1a4e2BQAAAMB9uM75h73XOcXdeOONCgoK0sSJEx1aHwDgOkFms9lsdBAAAPf58ccfSzz+/vvvFRkZqR9++KHE8rvuukvh4eEOb6egoEAmk0mhoaEO11FcTEyMbrjhBlWtWlXPPvusmjVrphMnTmjr1q3666+/lJuba3edAwcO1IQJE2TrV1+XLl2UkpKiXbt22b0tAAAAAO7Ddc4/7L3OOefgwYO68sor1axZM1100UVas2aN3dsGALhOZaMDAAC415NPPlni8YYNGxQZGVlq+flycnJUrVo1m7dTpUoVh+Iry+eff66srCxFR0eradOmJZ5LTk526bYAAAAA+Bauc5z3448/qkGDBhozZoweeeQRxcXFeeWQbyaTSfn5+QoLCzM6FABwK4ZBAwBYhvuKiopS586dVa1aNb399tuSpN9//13du3dX48aNFRoaqssuu0wjR45UUVFRiTrOH8s5Li5OQUFB+uyzz/TNN9/osssuU2hoqG644QZt3ry5wpgOHTqkiy++uNQFjCQ1aNCg1LK//vpLnTp1UvXq1VWjRg11795du3fvLhHfhAkTJJUcMsEVvv76a1199dUKDQ1V48aNNWDAAKWlpZUoc/DgQT388MNq2LChwsLCdPHFF6t3795KT0+3lImMjNStt96q2rVr64ILLlCLFi0s7wMAAAAA+3CdU76ZM2fqkUce0X333adatWpp5syZVstt3LhR9957r+rUqaPq1avrmmuu0bhx40qU2bdvn/71r3+pfv36qlq1qlq0aKF33nmnRJzWEkHDhw8vFW9QUJAGDhyoGTNmWK6zFi5cKEn67LPPdPPNN+vCCy9U1apV1b59e/3yyy9W4/7xxx914403qlq1aqpTp446d+6sxYsXS5L69OmjevXqqaCgoNR63bp1U4sWLcrecQDgJvSsAQBIkk6dOqV77rlHvXv31pNPPmkZKmD69Om64IILNHjwYF1wwQVatmyZhg4dqoyMDH366acV1jtz5kxlZmbq3//+t4KCgjR69Gg99NBDOnz4cLl3qTVt2lRLlizRsmXLdMcdd5S7jR9++EF9+vRRRESEPvnkE+Xk5GjixIm69dZbtW3bNjVr1kz//ve/dfz4catDIzhj+PDhev/999W1a1e9+OKL2r9/vyZOnKjNmzdr7dq1qlKlivLz8xUREaG8vDy99NJLatiwoY4dO6Z58+YpLS1NtWrV0u7du3Xffffpmmuu0YgRIxQaGqqYmBitXbvWZbECAAAAgYbrHOs2btyomJgYTZs2TSEhIXrooYc0Y8aMUjeLRUZG6r777lOjRo30yiuvqGHDhtq7d6/mzZunV155RZK0Y8cOderUSVWqVFH//v3VrFkzHTp0SH/++ac+/PBDm2MqbtmyZfr55581cOBA1atXz5LoGTdunHr06KEnnnhC+fn5mjVrlh599FHNmzdP3bt3t6z//vvva/jw4br55ps1YsQIhYSEaOPGjVq2bJm6deump556St9//70WLVqk++67z7JeYmKili1b5vD8QQDgFDMAIKAMGDDAfP7p/7bbbjNLMk+aNKlU+ZycnFLL/v3vf5urVatmzs3NtSzr06ePuWnTppbHsbGxZknmCy+80JyammpZ/vvvv5slmf/8889y49y1a5e5atWqZknmdu3amV955RXz3LlzzdnZ2SXKZWZmmmvXrm1+/vnnSyxPTEw016pVq8Rya6+9PLfddpv56quvLvP55ORkc0hIiLlbt27moqIiy/Lx48ebJZmnTp1qNpvN5m3btpklmefMmVNmXZ9//rlZkvnkyZM2xwcAAADgLK5z7GviGzhwoLlJkyZmk8lkNpvN5sWLF5slmbdt22YpU1hYaG7evLm5adOm5tOnT5dY/9x6ZrPZ3LlzZ3ONGjXMR44cKbPM+fvxnGHDhpWKXZI5ODjYvHv37lLlz3/f8vPzza1btzbfcccdlmUHDx40BwcHmx988MES12nFYyoqKjJffPHF5l69epV4fuzYseagoCDz4cOHS20bANyNYdAAAJKk0NBQ9e3bt9TyqlWrWv6fmZmplJQUderUSTk5Odq3b1+F9fbq1Ut16tSxPO7UqZMk6fDhw+Wud/XVVys6OlpPPvmk4uLiNG7cOPXs2VPh4eH69ttvLeUiIyOVlpamxx57TCkpKZa/SpUqqUOHDlq+fHmFMTpqyZIlys/P16BBgxQc/M9X6vPPP6+aNWtq/vz5kqRatWpJkhYtWqScnByrddWuXVvS2eEYTCaT22IGAAAAAgnXOaUVFhZq9uzZ6tWrl2UIsjvuuEMNGjTQjBkzLOW2bdum2NhYDRo0yHK9cs659U6ePKlVq1bp2Wef1SWXXGK1jCNuu+02tWrVqtTy4u/b6dOnlZ6erk6dOmnr1q2W5XPnzpXJZNLQoUNLXKcVjyk4OFhPPPGE/vjjD2VmZlqenzFjhm6++WY1b97c4dgBwFEkawAAkqSLLrpIISEhpZbv3r1bDz74oGrVqqWaNWuqfv36lkk7i8+3Upbzf7Cfu6A5ffp0heteeeWV+uGHH5SSkqIdO3boo48+UuXKldW/f38tWbJE0tm5YKSzFxf169cv8bd48WK3TtJ55MgRSSo1nnFISIguvfRSy/PNmzfX4MGDNXnyZNWrV08RERGaMGFCif3Xq1cv3XLLLXruuecUHh6u3r176+effyZxAwAAADiB65zSFi9erJMnT+rGG29UTEyMYmJiFBsbq9tvv10//fST5Rrk0KFDkqTWrVuXWde55FR5ZRxRVrJk3rx5uummmxQWFqa6deuqfv36mjhxYon37NChQwoODraa7Cnu6aef1pkzZ/Tbb79Jkvbv36+oqCg99dRTrnshAGAH5qwBAEgqeYfSOWlpabrttttUs2ZNjRgxQpdddpnCwsK0detWvfnmmzYlEipVqmR1udlstjm2SpUqqU2bNmrTpo06duyo22+/XTNmzFDXrl0tMfzwww9q2LBhqXUrV/aOr7oxY8bomWee0e+//67Fixfr5Zdf1qhRo7RhwwZdfPHFqlq1qlatWqXly5dr/vz5WrhwoWbPnq077rhDixcvLnM/AgAAACgb1zmlnes9869//cvq8ytXrtTtt9/ucP3WlNXLpqioyOpya+/b6tWr1aNHD3Xu3Flff/21GjVqpCpVqmjatGmaOXOm3TG1atVK7du3148//qinn35aP/74o0JCQsrcLwDgbt7RggUA8EorVqzQqVOn9Ouvv6pz586W5bGxsYbFdP3110uSTpw4IUm67LLLJEkNGjRQ165dy13XmW741jRt2lTS2TuwLr30Usvy/Px8xcbGlorn3IXYu+++q3Xr1umWW27RpEmT9MEHH0g62xX/zjvv1J133qmxY8fqo48+0jvvvKPly5dX+NoAAAAA2CaQr3Oys7P1+++/q1evXnrkkUdKPf/yyy9rxowZuv322y0x7Nq1q8wYzl0H7dq1q9zt1qlTR2lpaaWWnxuNwBb/+9//FBYWpkWLFik0NNSyfNq0aSXKXXbZZTKZTNqzZ4/atWtXbp1PP/20Bg8erBMnTmjmzJnq3r17ieHtAMCTGAYNAFCmc3eLFb87LD8/X19//bXbt7169WoVFBSUWr5gwQJJ/ww9FhERoZo1a+qjjz6yWv7kyZOW/1evXl2SrF4kOKJr164KCQnRl19+WWIfTZkyRenp6erevbskKSMjQ4WFhSXWbdOmjYKDg5WXlydJSk1NLVX/uQuLc2UAAAAAOC+Qr3N+++03ZWdna8CAAXrkkUdK/d1333363//+p7y8PF133XVq3ry5vvjii1J1n9t39evXV+fOnTV16lTFx8dbLSOdTaCkp6drx44dlmUnTpywDEFmi0qVKikoKKhEb5y4uDjNnTu3RLmePXsqODhYI0aMKNVL6vyeT4899piCgoL0yiuv6PDhw5ah8ADACPSsAQCU6eabb1adOnXUp08fvfzyywoKCtIPP/xgV9d+R33yySeKiorSQw89pGuuuUaStHXrVn3//feqW7euBg0aJEmqWbOmJk6cqKeeekrXXXedevfurfr16ys+Pl7z58/XLbfcovHjx0uS2rdvL+ns3WIRERGqVKmSevfuXW4cJ0+etPR8Ka558+Z64oknNGTIEL3//vu6++671aNHD+3fv19ff/21brjhBssP/WXLlmngwIF69NFHdeWVV6qwsFA//PCDKlWqpIcffliSNGLECK1atUrdu3dX06ZNlZycrK+//loXX3yxbr31VpfsUwAAAACBfZ0zY8YMXXjhhbr55putPt+jRw99++23mj9/vh566CFNnDhR999/v9q1a6e+ffuqUaNG2rdvn3bv3q1FixZJkr788kvdeuutuu6669S/f381b95ccXFxmj9/vqKjoyVJvXv31ptvvqkHH3xQL7/8snJycjRx4kRdeeWV2rp1q037rnv37ho7dqzuvvtuPf7440pOTtaECRN0+eWXl0gCXX755XrnnXc0cuRIderUSQ899JBCQ0O1efNmNW7cWKNGjbKUrV+/vu6++27NmTNHtWvXttxwBwCGMAMAAsqAAQPM55/+b7vtNvPVV19ttfzatWvNN910k7lq1armxo0bm9944w3zokWLzJLMy5cvt5Tr06ePuWnTppbHsbGxZknmTz/9tFSdkszDhg0rN861a9eaBwwYYG7durW5Vq1a5ipVqpgvueQS8zPPPGM+dOhQqfLLly83R0REmGvVqmUOCwszX3bZZeZnnnnGvGXLFkuZwsJC80svvWSuX7++OSgoqNR+ON9tt91mlmT1784777SUGz9+vLlly5bmKlWqmMPDw80vvvii+fTp05bnDx8+bH722WfNl112mTksLMxct25d8+23325esmSJpczSpUvNDzzwgLlx48bmkJAQc+PGjc2PPfaY+cCBA+XGCAAAAIDrHFuuc5KSksyVK1c2P/XUU2XGl5OTY65WrZr5wQcftCxbs2aN+a677jLXqFHDXL16dfM111xj/uqrr0qst2vXLvODDz5orl27tjksLMzcokUL83vvvVeizOLFi82tW7c2h4SEmFu0aGH+8ccfzcOGDSsVryTzgAEDrMY3ZcoU8xVXXGEODQ01t2zZ0jxt2jSrdZjNZvPUqVPN1157rTk0NNRcp04d82233WaOjIwsVe7nn382SzL379+/zP0CAJ4QZDZ74LYBAAAAAAAAAPAyv//+u3r27KlVq1apU6dORocDIICRrAEAAAAAAAAQkO677z7t3btXMTExCgoKMjocAAGMOWsAAAAAAAAABJRZs2Zpx44dmj9/vsaNG0eiBoDh6FkDAAAAAAAAIKAEBQXpggsuUK9evTRp0iRVrsw97QCMxVkIAAAAAAAAQEDh/nUA3ibY6AAAAAAAAAAAAAACGckaAAAAAAAAAAAAAzEMmouYTCYdP35cNWrUYEIyAAAABASz2azMzEw1btxYwcHcB4aKcd0EAACAQGLPNRPJGhc5fvy4mjRpYnQYAAAAgMclJCTo4osvNjoM+ACumwAAABCIbLlmIlnjIjVq1JB0dqfXrFnT4GgAAAAA98vIyFCTJk0sv4WBinDdBAAAgEBizzUTyRoXOdeFv2bNmlx0AAAAIKAwnBVsxXUTAAAAApEt10wMLA0AAAAAAAAAAGAgQ5M1o0aN0g033KAaNWqoQYMG6tmzp/bv31+iTJcuXRQUFFTi74UXXihRJj4+Xt27d1e1atXUoEEDvf766yosLCxRZsWKFbruuusUGhqqyy+/XNOnTy8Vz4QJE9SsWTOFhYWpQ4cO2rRpk8tfMwAAAAAAAAAAQHGGJmtWrlypAQMGaMOGDYqMjFRBQYG6deum7OzsEuWef/55nThxwvI3evRoy3NFRUXq3r278vPztW7dOn333XeaPn26hg4daikTGxur7t276/bbb1d0dLQGDRqk5557TosWLbKUmT17tgYPHqxhw4Zp69atatu2rSIiIpScnOz+HQEAAAAAAAAAAAJWkNlsNhsdxDknT55UgwYNtHLlSnXu3FnS2Z417dq10xdffGF1nb/++kv33Xefjh8/rvDwcEnSpEmT9Oabb+rkyZMKCQnRm2++qfnz52vXrl2W9Xr37q20tDQtXLhQktShQwfdcMMNGj9+vCTJZDKpSZMmeumll/TWW2+V2m5eXp7y8vIsj89NFJSens7YywAAAAgIGRkZqlWrFr+BYTOOGQAAAAQSe37/etWcNenp6ZKkunXrllg+Y8YM1atXT61bt9aQIUOUk5NjeW79+vVq06aNJVEjSREREcrIyNDu3bstZbp27VqizoiICK1fv16SlJ+fr6ioqBJlgoOD1bVrV0uZ840aNUq1atWy/DVp0sSJVw4AAAAAAAAAAAJVZaMDOMdkMmnQoEG65ZZb1Lp1a8vyxx9/XE2bNlXjxo21Y8cOvfnmm9q/f79+/fVXSVJiYmKJRI0ky+PExMRyy2RkZOjMmTM6ffq0ioqKrJbZt2+f1XiHDBmiwYMHWx6f61kDAAAAAAAAAABgD69J1gwYMEC7du3SmjVrSizv37+/5f9t2rRRo0aNdOedd+rQoUO67LLLPB2mRWhoqEJDQw3bPgAAAAAAAAAA8A9eMQzawIEDNW/ePC1fvlwXX3xxuWU7dOggSYqJiZEkNWzYUElJSSXKnHvcsGHDcsvUrFlTVatWVb169VSpUiWrZc7VAQAAAAAAAAAA4A6GJmvMZrMGDhyo3377TcuWLVPz5s0rXCc6OlqS1KhRI0lSx44dtXPnTiUnJ1vKREZGqmbNmmrVqpWlzNKlS0vUExkZqY4dO0qSQkJC1L59+xJlTCaTli5daikDAAAAAAAAAADgDoYOgzZgwADNnDlTv//+u2rUqGGZY6ZWrVqqWrWqDh06pJkzZ+ree+/VhRdeqB07dujVV19V586ddc0110iSunXrplatWumpp57S6NGjlZiYqHfffVcDBgywDFP2wgsvaPz48XrjjTf07LPPatmyZfr55581f/58SyyDBw9Wnz59dP311+vGG2/UF198oezsbPXt29fzOwYAAAAAAAAAAAQMQ3vWTJw4Uenp6erSpYsaNWpk+Zs9e7aksz1elixZom7duqlly5Z67bXX9PDDD+vPP/+01FGpUiXNmzdPlSpVUseOHfXkk0/q6aef1ogRIyxlmjdvrvnz5ysyMlJt27bVmDFjNHnyZEVERFjK9OrVS5999pmGDh2qdu3aKTo6WgsXLlR4eLjndggAAAAAeMCqVat0//33q3HjxgoKCtLcuXMrXGfFihW67rrrFBoaqssvv1zTp093e5wAAABAoAgym81mo4PwBxkZGapVq5bS09NVs2ZNo8MBAAAA3I7fwL7rr7/+0tq1a9W+fXs99NBD+u2339SzZ88yy8fGxqp169Z64YUX9Nxzz2np0qUaNGiQ5s+fX+ImuIpwzAAAACCQ2PP719Bh0AAAAAAAnnfPPffonnvusbn8pEmT1Lx5c40ZM0aSdNVVV2nNmjX6/PPP7UrWAAAAALCOZA0AAABQjvk7TujXrUc19l/tVKtaFaPDAQyxfv16de3atcSyiIgIDRo0qNz18vLylJeXZ3mckZHhjvBs8uf243rpp20VluvSor5W7D9ZbpkqlYJUUFRykIp37r1KHy7Ya3dcna6op9UHU2wuX7d6iFKz8yss1/HSC7X+8Cm7Ypn4xHWasTFea2LKj+f+to315/bjpZYHB0mmv3fL/z3VXlUqBemFH7cqv9BUbn1drwrXkr1JFcY3ve8Nuvmyerry3b9KLF8yuLPe/N9ORR05rcc7XKKZG+NLrPPMtM2l6vqh3416asqmCrcpSSv+20VdPlthebz0tds0e3OCvll1uEQ9Nzarq01xqZZ/HVG3eogirm6onzbFl3qufo1Q3dmygbLzi5SckauNsfZto33TOqoeWlkdmtfVp4v2l1kupFKwBt5xucZGHii3ruduba7Ja2IVdeR0hdt+7tbmyi8yac3BFB1OyS7xXPN61TXs/lb6bPF+7TpW8hxx3SW1dcvl9fTVshhN6XO9luxN0qmsfC3eU/bxUqdaFZ3OKZBk/+frfBuG3KmbRi0tcWyf7942DbVgZ2K5cZTH1s/qDc3qaHNcxfv6kfYX65eooxWWO6d5veqKTcnWMzc3U4uGNbRif7Kub1pXHy7Yqw7N61o9zjpfWV91qlVRw5ph+r9Vhys85ic8fp0GzNxq9bnl/+2iZ6Zt0pFTOaWee+2uKzXm7+Mw4upwxaZk60BSliSpSd2qSkg9o5fuuFyb41KVfqZQ9S4IsbzfN192oe5qFa73/9xjdbvXXFxLO46ml1p+/vn9otpVdSztjOXxkzddoh83/PP5fPnOKzT4riu190SG7hm3usx9IElP3dRUm2JTtT8p07Is7uPu+nXrUS3Ymagx/2qr+79ao/jUHAUFSWaz1Ov6Jpq9JUGS9OGDrfXOb7vKrL9GaGVl5hWq6YXV9P2zN+rhieuVkpVnteyrXa/U50vK/oxXpHa1Kup8RX39sf24fvvPzbr2kjqSpO/WxWnYH7vLXXftW3fo+3Vx+r9Vh8t8Dee8d18rNa9XTc9O31Kq7Au3Xaa37mmp5Ixc3fjRUknSZfWrq9BkLnE83dUqXJHFzhmVg4NUWNYHugxP3nSJbr6snr5celD7Es++f+2b1lGNsMqW3ww/PX+THvt2Q4V11QyrrIzcf17jjOc66PfoY/p5y1G1CK+h/UmZGnJPS42JPKDgIKnIZC71m6M8j7a/WJvjUhV33meqRXgN/euGJnrm5ma66r2Fyi8q+d08+uFrtGRvkhbvSVKjWmGqVbWK5bUW99PzN2niykN6+qameu77LaoeUknTn71RXy2LUdUqwVq0u/T5uV2T2opOSCu1vH6NUJ3MLHmMXtWopvaeyFD3No1006V1NWVNrBrXrqoXu1xW4nv7rXtaat6O49p1LEPXN62jLcW+iy6tX10f9mxjeT8OfniPqlQydDYYmzEMmovQnR8AAMA/NXtrviTpmZubaXiPqw2OxrvwG9g/BAUFVTgM2pVXXqm+fftqyJAhlmULFixQ9+7dlZOTo6pVq1pdb/jw4Xr//fdLLTfimPlhwxG9N7fsRi74ho8faqO3ft1pdBgAYBH3cXddNzLSpkT6+aLe7ar2HyyRJF1ar3qpZKaj2l5cS9utJKPcJe7j7pL++d1cnlsuv1BrY+y7maC87T45eWOFNxngH5OevE4v/Gg9eeqvziVVjWLPNZNvpJQAAAAAg53Osf8CHAh0Q4YMUXp6uuUvISHB6JDg4zKL3Y0MAN7CkUSNdLbXxDkJp0v3LnJUYkauy+pyteQM6719HHU8/UzFhWCRlVdkdAgel5rt2mPOnRgGDQAAAABQroYNGyopqeSwFklJSapZs2aZvWokKTQ0VKGhoe4ODwAAAPB59KwBAHgtRuoEAMA7dOzYUUuXLi2xLDIyUh07djQoIgAAAMC/kKwBAHiljNwCdRq9XO//Wf7khAAAwH5ZWVmKjo5WdHS0JCk2NlbR0dGKjz87afKQIUP09NNPW8q/8MILOnz4sN544w3t27dPX3/9tX7++We9+uqrRoQPAAAA+B2SNQAArzRrU7yOnj6jaWvjjA4FAAC/s2XLFl177bW69tprJUmDBw/Wtddeq6FDh0qSTpw4YUncSFLz5s01f/58RUZGqm3bthozZowmT56siIgIQ+IHAAAA/A1z1gAAvBIjoAEA4D5dunQpd7jR6dOnW11n27ZtbowKAAAACFz0rAEAAABsQBIZAAAA8C5BRgcAuBDJGgAAAAAAAAAwEDcGOYbdBn9CsgYAAAAAAAAAAMBAJGsAAF6Ju2MAAAAAAAAQKEjWAAAAAAD8HmPa+wczt/QA8CPFz2hBfFEBbuFLQwySrAHgc/IKizR+2UHtPJpudCgAAAAAAABOCwqQ2wpc3W4eGHsNgYJkDQCfM2VNrD5bfED3j19jdCgAAAAAPChQGjMBBAbOaM4LoksS/AjJGgA+Z++JTKNDgAfwcwsAAAAAAACBgmQNAMAr+dCQogACBOclAAAAwLuYfWlCEqACJGsAeL2dR9OVkpVndBgAAAAAAABuYebWICDgVTY6AAAoz46jaeoxfq0kKe7j7gZHAwAAAAAAAACuR88aAF5tbcwpo0MAAAAAAAAAALciWQMAAAAAAAAA8DlBQUFGhwC4DMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAA+D2GtPcPZpmNDgEAXKb4GS1IfFE5wmzmewHl86UjhGQNAAAAAAAAAMDtSEkZi/3v3UjWAAAAAAAAn8Cd5wD8SfEzWqD0HHT1qwyi66xdAuMo810kawAAXomezAAAAAAAAHCGL6XzSNYAAAAAAAAAAAAYiGQNAAAAAAAAAACAgUjWAPA5vtR9EQDgP8yMzwgAAAAAcBOSNQAAr8QcgQAAAAAAAAgUJGsAAF6JG9gBAAAAAAAQKEjWwGedyS/S1ytiFJOcaXQoAAAAAAAAgMO4YREAyRr4rDGL92v0wv3qOnaV0aEAAAAAAAAAAOAwkjXwWdsS0owOAQAAAAAAAAAAp5GsAeBz6BkMAAAAewUpyOgQ4AJmrgYA+JHiZ7QgvqYAt/ClXw4kawAAAAAAAADAQNxU4Bj2mn3YX96NZA0Ar8adJQAAb+FLd2QBgL+iMROAPwnEM5rZ7Npf1bQb2YdrGu9GsgYAAD+XkJqjZ6dv1obDp4wOBQAAAAAAAFaQrAHg1Vx8wwUQkF6etU3L9iWr9zcbjA4FAAAAAGAFc3I5hnYj+BOSNQAA+LnjaWeMDgEAAAAAAADlIFkDAAAAAAAAAABgIJI1AACvRBdwAAAAAAAABAqSNQAAAAAAAAAAnxMUZHQEgOuQrAHgc+z5Hk7OyNUXSw4oMT3XbfEAAAAAAAAAgDNI1gDwa8//EKUvlhxUn6mbjA4FAAAAAAAAAKwiWQPAr21PSJMk7U/KNDYQ2C3Irj5UAAAA5WOYFP/AvIYA/EnxMxrXwI4x87WACvjSMUKyBj6LrzDAv3EhDgAAAACAfwni7glDsfe9G8kaAAAAAAAAAAAAA5GsAQAAAAAAPoFhggD4E85ozqOjDvwJyRoAAAAAAAAAMFCgDAVu9qUJRPwQe9+7kawBAAAAAAAAAAB+x5d6X5GsAQAAAGzBbWgAAAAAADchWQMAAAAAAAAAAGAgkjXwWdzcCgCucyorj7GDAQAAAAAADEKyBoBX86VxJQFfteZgitp/sEQv/bTN6FAAAAAAICBx7xwAkjUAAAS4SSsPSZLm7ThhcCQAAAAAAACBiWQNAAAAAAAAAACAgQxN1owaNUo33HCDatSooQYNGqhnz57av39/iTK5ubkaMGCALrzwQl1wwQV6+OGHlZSUVKJMfHy8unfvrmrVqqlBgwZ6/fXXVVhYWKLMihUrdN111yk0NFSXX365pk+fXiqeCRMmqFmzZgoLC1OHDh20adMml79mAIBt6AIOAABcidF1/YOZ2UsB+JHiZzSGgQfcw5falwxN1qxcuVIDBgzQhg0bFBkZqYKCAnXr1k3Z2dmWMq+++qr+/PNPzZkzRytXrtTx48f10EMPWZ4vKipS9+7dlZ+fr3Xr1um7777T9OnTNXToUEuZ2NhYde/eXbfffruio6M1aNAgPffcc1q0aJGlzOzZszV48GANGzZMW7duVdu2bRUREaHk5GTP7Aw/NHtzvFYfPGl0GADgE8xms17+aZve+W2n0aEAKAMNhAAAAHCXIG4rcAj7zT7sLe9W2ciNL1y4sMTj6dOnq0GDBoqKilLnzp2Vnp6uKVOmaObMmbrjjjskSdOmTdNVV12lDRs26KabbtLixYu1Z88eLVmyROHh4WrXrp1GjhypN998U8OHD1dISIgmTZqk5s2ba8yYMZKkq666SmvWrNHnn3+uiIgISdLYsWP1/PPPq2/fvpKkSZMmaf78+Zo6dareeustD+4V/7D7eLre/N/ZBse4j7sbHA2AQFRkMis4SArykduTjp4+oz+2H5ckDe9xtapUYqRSAAAAAACAQOFVLUHp6emSpLp160qSoqKiVFBQoK5du1rKtGzZUpdcconWr18vSVq/fr3atGmj8PBwS5mIiAhlZGRo9+7dljLF6zhX5lwd+fn5ioqKKlEmODhYXbt2tZQ5X15enjIyMkr84R8n0nLdvg3faH4FYIT8QpM6j16uRyZZP4d7o+LdcotM3L0PAABgDXdQA/AnnNEAFOc1yRqTyaRBgwbplltuUevWrSVJiYmJCgkJUe3atUuUDQ8PV2JioqVM8UTNuefPPVdemYyMDJ05c0YpKSkqKiqyWuZcHecbNWqUatWqZflr0qSJYy8cQLl8aVxJd4o6clprDqYYHYZHOdMhZu+JDB1LO6OoI6ddF5CbBRf7RiZZU7GCIpNSs/MN2faZ/CLl5BdWXBA2MZvNOpWVZ3QYAAAAADzA1Ve7DFVsH/aWd/OaZM2AAQO0a9cuzZo1y+hQbDJkyBClp6db/hISEowOCYAfe3jiOj05ZSMNmn6scrFsTRFZygrdO261rhsZqSOnsisu7EJFJrOuHrZQrYYuUkGRyaPb9lcfzt+r9h8s0dxtx4wOBQAAADAMSQcAXpGsGThwoObNm6fly5fr4osvtixv2LCh8vPzlZaWVqJ8UlKSGjZsaCmTlJRU6vlzz5VXpmbNmqpatarq1aunSpUqWS1zro7zhYaGqmbNmiX+AMDdThnUk8AIgZavCC7Wk8hEz5oKHUzOkiQt3p1UQUnXys4v1Lm351RW4Hwe3WnymlhJ0ocL9hocCQAAAAAAxjE0WWM2mzVw4ED99ttvWrZsmZo3b17i+fbt26tKlSpaunSpZdn+/fsVHx+vjh07SpI6duyonTt3Kjk52VImMjJSNWvWVKtWrSxlitdxrsy5OkJCQtS+ffsSZUwmk5YuXWopAwCAWzFYMQAAAAAAQMAyNFkzYMAA/fjjj5o5c6Zq1KihxMREJSYm6syZM5KkWrVqqV+/fho8eLCWL1+uqKgo9e3bVx07dtRNN90kSerWrZtatWqlp556Stu3b9eiRYv07rvvasCAAQoNDZUkvfDCCzp8+LDeeOMN7du3T19//bV+/vlnvfrqq5ZYBg8erG+//Vbfffed9u7dqxdffFHZ2dnq27ev53eMm2TmFhgdAuC0KWtitWJ/csUFAQBulZieq9MB1NsP8FcTJkxQs2bNFBYWpg4dOmjTpk3llv/iiy/UokULVa1aVU2aNNGrr76q3NxcD0ULAAAA+K/KRm584sSJkqQuXbqUWD5t2jQ988wzkqTPP/9cwcHBevjhh5WXl6eIiAh9/fXXlrKVKlXSvHnz9OKLL6pjx46qXr26+vTpoxEjRljKNG/eXPPnz9err76qcePG6eKLL9bkyZMVERFhKdOrVy+dPHlSQ4cOVWJiotq1a6eFCxcqPDzcfTvAgz6Yt0eT18Rq2jM36PaWDYwOB3DIpthUjZy3x+gwACDgpZ8p0E2jzvZIjvu4u8HRAHDU7NmzNXjwYE2aNEkdOnTQF198oYiICO3fv18NGpS+Zpg5c6beeustTZ06VTfffLMOHDigZ555RkFBQRo7dqwBrwAAAADwH4Yma8w2TEgQFhamCRMmaMKECWWWadq0qRYsWFBuPV26dNG2bdvKLTNw4EANHDiwwph80bnx4D9asJdkjaSUrDxdWD1EQUGMO+RLTqSfMToEALAI5AlA41KyjQ4BgAuMHTtWzz//vGU0gUmTJmn+/PmaOnWq3nrrrVLl161bp1tuuUWPP/64JKlZs2Z67LHHtHHjRo/GDQAAAPgjQ4dBA4ywcNcJXf/BEg35dafRoQAAfEzxFP/Oo+kavXCfcvILDYsHAByVn5+vqKgode3a1bIsODhYXbt21fr1662uc/PNNysqKsoyVNrhw4e1YMEC3XvvvWVuJy8vTxkZGSX+AAAAAJRmaM8awAhjFh+QJM3anKCPH77G4GgA33cmv0hVQyoZHQbgcf1/iJIkFRSZ9E73VgZHAwD2SUlJUVFRUalhn8PDw7Vv3z6r6zz++ONKSUnRrbfeKrPZrMLCQr3wwgt6++23y9zOqFGj9P7777s0dkfRqd4/BHLPVgD+p/gZLUhB5y2BLWwYuAkBz3cOEnrWAAhIr/28Xa/P2W50GD5v6O+7dNXQhdoWf9roUADD7EvMNDoEAPCIFStW6KOPPtLXX3+trVu36tdff9X8+fM1cuTIMtcZMmSI0tPTLX8JCQkejBgAAHgb7p0wFvvfu9GzBkDASc3O1/+2HpUkvdP9KtWuFmJwRL7r+/VHJElfLDmo75690en6Vh88KUnqdEV9p+uC7bhDFe5yKitPiRm5urpxLaNDAXCeevXqqVKlSkpKSiqxPCkpSQ0bNrS6znvvvaennnpKzz33nCSpTZs2ys7OVv/+/fXOO+8oOLj0vYChoaEKDQ11/QsAAAAA/Aw9awAEnCLTPw3TdJf1Hjn5hXpqyiY9NWWTsvOYAwTeKYgxdOzS/oMl6v7lGu0+nl7qucIikzqPXm5AVAAkKSQkRO3bt9fSpUsty0wmk5YuXaqOHTtaXScnJ6dUQqZSpbNDoZr5UQUPCeKeYAB+hDMagOJI1sBn0V4WGHifA8eZ/CLL/3OK/R+A7SavPqwV+5Pdvh17m2Q3Hk4ttWxTXKriU3NcE5CT1sak6I7PVmjD4VPllqMtGv5m8ODB+vbbb/Xdd99p7969evHFF5Wdna2+fftKkp5++mkNGTLEUv7+++/XxIkTNWvWLMXGxioyMlLvvfee7r//fkvSBgAAAIBjGAYNPosGE7jb3G3HVCOssu68KrziwoAP4w5V/7Dx8Cl9MH+vJCnu4+4GR1Mxb/oef2LyRklS7282+MS+A1ylV69eOnnypIYOHarExES1a9dOCxcuVHj42d8+8fHxJXrSvPvuuwoKCtK7776rY8eOqX79+rr//vv14YcfGvUSAADwG4EyPHVgvErvxf73biRr4BaB1hsiJjlLYyP3a+DtV6hV45pGhwMXOJZ2RoNmR0vyrkZPb2rcLC7QPvPwHp6+oPHmYX5OpOeWeFxkMmtj7Cm1vbi2qofykw+AdQMHDtTAgQOtPrdixYoSjytXrqxhw4Zp2LBhHogMAAAAcAXfabRiGDTABfpM3aQFOxP14NdrjQ7FEMv2Janb5yu161jpOQl8VWpWvtEh+BQvbr/2Wgt3Jarb5yu1LzHj7IIA2Yens/N131erNXVNrNGh+L3/W3VIj3+7UU9N2Wh0KAAAAAAAoAIkawAXOJZ2RpKUV2gyOBJjPDt9iw4kZem577YYHQrgM174MUoHkrL0nxlbSz3n6mHJvCmZ9vWKGO06lqER8/YYHYpDgnyoG9nPmxMkSVvj04wNBAAAAADcxIsudwGnkayBW3hTw+D5vDg0n5edV2h0CHbjeHANH2q/9jq++LlxRm5BYCa1A50t51pOIwAAAAhk3tyWBsAzSNYEGM778GWuuqOdxAK8navnYeGY9x1RR1K1PzHT6DAq5I65e/iNAgAAAAAIZCRrUK6CIpPScpi7AzCSN09oDsB1kjNy9fDE9Yr4YpVD67s6yeduvphD5HQMAMbzte87AChP8TMaN9kB7uI7vx1I1qBc945brXYjInX0dI7RocBBOfmFWnngpPI9OJ9OcmaukjNyXV4vSQvv/fHmpWH5Fi/aiRm5BRowc6sW7050ed2+3sDizrcp4fQZN9YOAHD1nHAAALgS31OOYa/Zh/3l3UjWBBh7P5AHk7MkSUv2JLk+GLhNXmGR5f///iFKfaZu0qeL9nlk2wVFJt344VLd+NHSEnHAv7mi+Z07irzHuCUHNX/HCfX/IcroUCrEBY3zCopMKjI59yleti9JnUYv05a4VKvP8y4BAAAAAFA+kjWAnzl8Mkst3l2oN37ZLklafTBFkjRzY7xHtp+T90+CJj2nwOn66Ezjfmk5+aV6XqXl5KvX/63Xz5sTDIrKGGaz2elGa3+QnJlnc9kik1nrD51SVl6hGyOCI2yZ56ugyKSOo5bpzjErnOq9+Oz0LUpIPaPHv93ocB0AAAAAAAQykjWAn/lm1WFJ0s9bjhocCXxBYnqu2o2I1F2fryyx/KtlMdoYm6o3/rfDpnr84a55s9mshyauU9exK1VY5LlhA33dtLWxeuzbDXri2w1Gh2IYX04qx6fmKCUrT3GnclTogkRlfhmfHWs1O7q1nPxC/bH9uDJynb8hAADge+hVC8CfcEZzng9fjgGlkKzxEwt3Jer577coLSff6FB8UmZugU1zusSfynH53C9n8ouYi8ULBcowXMv3J0uSjpwqOS9VZoA2gm6LT1NsSrYOp2TbvE5KVp6iE9LcF5SXm/N3Ynj70XSbygfi6W7D4VO6d9xqbY0/bXQofuHtX3fq5Z+26QUfGKYPAAAAAABbkazxEy/8GKXIPUkas/iA0aF4jKsa09NzCtRm+GLd8smycsutPnhSnT9drn/933rXbFjSgaRMXTV0oV7/xbbeCwC8z/UfLFHPCWsVdcT6XB3wL4589/T+ZoP2nMhQLxd+f1jja4kwR7/G50YflyStO3TKdcEAAAAABjMHSh+RAHmZ3ord791I1viZU9m2zzOAs7YmnL3T+WQFczTM+nvuDlfdQX8i/YzGLTkoSfoliiHLACOdyspzuqF7bUxgNRzvPp6uwT9H63jaGUPj8PQFjTPHSUERP4t9XaD0ugQAAAAAeF5lowOA/+s4aqk+fvga3XZlfaND8RqHT2bpjjErKy7oABqS/IvJZGZeBjdbczBFT07ZqO7XNDI6FMMUT3jYOpxm9y/XuCscwGv5Wu8lAAAAAIDvIFkDtzuRnqs+Uzcp7uPuRofiNZbtS3Zb3TQk+Zdnv9usFftPWh4H0vvrqbmcvl4RI0mav+OER7bn7dqNiHRr/QF0CHucNyfrmZsNAAAAAIDyMQwa3MKbG4z8ycJdJ9Rp9DJtD5DJzYMC8MAqnqhxB9pPrWO/oCwBeBoCAAAAAAAeQLImAHjj3az5hSblFhS5vN79iZlKzsx1eb32Kigy6detR3XMzXM5vPDjViWknlG/7za7dTtGMqph1NrH5njaGT0wfo1+28YcQ+dzdSKN9nDAu9n7yyIQk+2OKCwy6Zeoo+oxfo3iT+UYHQ4AAAAAwINI1gSAl37aZvm/t6Rtbv54ma4autBqwiY7r1BT1sQqIdW+Ror4UzmK+GKVbvxwqavCdNi0tbEa/PN23f7pCo9sL6/AZPk/7WHuM+LPPdp+NF2vzt5udCh+z+hzla9+jg4mZSopo2TC+peoo0rKyDMoItjD2ePOC+/NKJ+Pfs7c6fYxK/TfOdu142i63vp1h9HhAP6H845fMBv+SxEAXKf4GS2ILyqHeONN6vAuvnSIkKwJAPNcMA+DWWcn4U5Md02vlZSsPJnN0uGT2aWe+3DBXo2ct0fdv1xtV53bj6a5JDZXWH0wRZKUX2SqoKTvOpmZp8g9SSoyGXvG2xKX6tT6ZX2pW2s0zcordGpbsI+n7sT3pS/t8iSm5+quz1epw0f/JKy3xp/Wf+dUnFx010XB6ex8vfTTNq0+GJjzLhnN1y71HIl36d4kZXvZuXnH0TR9umifzuTb34M4IfWfHrnlfeckZ+ZqiRd8BwMAAMCFfO0HvKMC5XV6KXa/dyNZA5us2H9ST07ZqJtGub/Xypq/Ex0Zua5tfNl5NF1PTdmomOSsMstk5hZo8e5E5RWWbmBx5cnMH4aDuevzlXr++y2auSm+xHJP3+n2yKT1Vt8v2Ma4YeZoYDzHkihxcpfsTcwotczoYZQ+XLBXf24/rqembDI0Dvivft9t0Qs/RlVYzpPfEz3Gr9WE5Yf05bKDbtvGnWNW6rnvt2jW5viKCwMAAMA3cJkMBDySNbDJ2pgUo0Moxd623ge/Xmvp8VKW57/fov4/ROnD+XudiCwwpOUUSJKW7U0yOBIpr9C+Hky+nyrzbdviT6v9B0v0S1T5c/94KqHjB7lTr5H+93nhnONW5u3y9f1trRcSw7FUzOrn2Wz9YWJ6rkx29Bip6Lv9r50n1OLdhfpxwxGb6yyLPe/1gcRMp7dXlsy/b2hZvu9kBSUBAAAAAL6CZA0CRqENDT8bDp8dUmvOFiaQdwkfb5QNBGXlQ9w5Vu5/ZmxVana+TcNzGcWRPJGjuSVrjb/21vXDhiPqO22zYwG40MCftlZYhk5VttlxNM2hYbTOOT9x5isW7krUTaOW6pXZ0S6r88UZZ4/Ld+fuclmdrpRbUGQ1mcVnBQCsY04HAP6EMxqA4kjWwC38sYHB11+SIUOvuXinMXSW97Ln6DLxPrrce3Y0Qs/YeESfLdrvljgq6uHgjPI+/+tiUvTW/3YoM9c3ExTnFH+JPcav1b/+b73DdbUdsdjubRp9oXgyM88ypNmf248bHI1nHDqZpZbvLdQbv+wwOhQAAAAAgMFI1gQYRxtifH3YGngOd7r5huSMXH2ycJ8SThs7p4k3CLTc0Tu/7dL45THac7z0HDfeasHOE7r+gyVaf+iU1ecfn7xRszYn6PNI980RYoSdx9LtKu/JYznQPjfu8u2qw5KkORUMCwkAAAAA8H8kawCrw+j7ciuU9WSJu3qlGNJjJ4AV390/rI/T2MWO9ZD4z4ytmrjikCauOGT1eXs/A778ibHGkMPawW3GpmQ7tF5WXqFjG/SA09n5eu67LVq0O1HS2eP1VHa+np66sdz1jnog+Wjts2FPkjq/0KT7vlqtt/5XuifFMStz/DjFzmPKnZ9jq98VfH0AAAAAFr7dFmWHAHmZ3ord791I1sBnubMxNbeg9IT1vtOmFNin3fxCk1Ky8owOwyPe+323vlwWo4NJ9k9iveXIaTdE5FqeunO/vHNJckau/jtnu7YnpHkmGAcMnFnxPDGuYDabXZT0rbiOTxfv15K9Sfr3D1EllhfZMem8J9lzUbXqwEntOpahWZsTSj338k/bXBmWTV8H/p5vH+NgQhsAAACAb/DOq0R4E1+67iVZ42cYlgSBLuKLVbr+gyWKs7G3gT98ZLyhh4QrvvdsnTsj/UyB0s+4d26Sc7H895cd+iXqqB6YsNat23NGcqZnkpPPTNus+8ev8UjCJMVDr8kIvjpnU2GRSb2/Wa/hf+x2aH0j5hzbl5ihr5bFeHy7AAAAAAA4gmQN/FpuQZHmbElQcmauR7frq0ODLd6dqDlb/rnb+3jaGbsa2MySNseluiGys2zZr+eGhIrck+S2OIzksd4mXtCXrKCodA+3wiKT2r6/WG3fX6z8wtLPO6K8fXooOcsl2zDCCz9EadDsaJfVt/LvHiEHHOjJBd+37tApbTicqunr4owOxWZZucYnsgEAAABb+eh9XQBcqLLRAcA/OTPuvivzHJ8s3Kdpa+N0cZ2qrqvU6zm+A/v/PeRQx8su1KoDKXr7t5166qamGtmztU1by8or1HPfb3F4+0YwKiWRW1Ck3IIi1a4W4pL6Nh4+pTUxKXr5zitUpZL35eHP5Bcpv9CkWtWq2FQ+v8ikL63cEZ+dV2T5f1pOvhrUDJMkrY1J0abYVL1y5xUKDjbmXfWmHG12XqEW/j3fi6t50+s8X6Bf27jzvSk0lUyOevNx4E7uvIC2lqAGAAAAAAQO72vRg1O8pfFkmIPDpLjaud4VR0+7eNLmClTUG8XVb5Or247Scgr08V97JUk/bDji4tohSdeNjFS7EZFKy8l3SX29vtmgr5bFaObGeJfUZ6+Kzj1thi9S2xGLlZFr2/BlB5Ps69HyxOSNGrf0oH7ffsyu9bzd5rhUHTppf+8eb0laWDsubGnsdjb+IpNZy/Yl6aQfD6dmTal96+SXzensfJnKGPau+LaavTXfuQ1BkjRtbazRIQB+z0suleCkgJmAG0BAKH5G85Y2PcDf+FKvNZI1AcaHjk3P4cuwlKAg7xnKzZdOqPbIyT/bQ2TnsXSX1htr41w9rlbR+1T4d4PvgUT3DqGVkOqaxKw3HP5xKdl6dNJ63TlmZbnlvPkzUlFsR0/nuGUuk1mb4/Xs9C3q9nn5+85VvPk9cNSuY+m6dmSk+kzb5LZt7D3hX0Pq5RUWaeGuEw6vvzbmlAujAQAAgK/xhuHIfRF7zT7sL+9GsgawkbckLzwhSEEyaCQpeAl771hcui9Ze09k2L2d1QdP6qGv1+qgG+dByS0o0rqYlDLnuHHVR9uZBvv8QpPm7yjZyBvjwflyjLpD9dZPluvrFYdcXu+Sv3tVns6xrScXSvvx716Vqw+muG0bI+ftcVvdRhi1YJ9e+HGry+rjznEAAAAACCwkawJYbkGRZm2KV2J6rmExuLshwpV3O9tz97evJ3bs6Vnj4y8VLtRzwlq713lqyiZtjU/Tv/+eL8kd3vhlhx6fvFEj5lkfntHaR9uRc8dxJ+bqmrjikN7/078arm316aL9Lqsr0E9H/jbnyZFTxvQUdNSvW4+WeEyqBQAAAABgD5I1AWxs5AG99etOdf9ytdGhuASNIs45PxnlkkZPH2g55bixzpHu13nn9Vz5YcMRPTppndLPVNy7IdXGuXscSfD+sf24JOnHDe6dz2f2loQSj3cdS9epLNvmTFm0O9EdIbnMvB3HXVaXM0l0Pq9l2xp/Wm/9urPEstPZrpkTyyhnCoqMDsGjVh446cBafCoABB6GCQLgTzijOY9fxPAnlY0OAMZZvi9ZknTKyxpzTP44+P95XN0bxRXVFd/t5fWsKSwyqXIl8ryo2Htzd0k622vEFnZ/Lrz4V210Qpqlp1Hcx93dui1P9G4bOHOb+zdSjKNfA0Z9e3hDD0NrPbPsHQau+Ms4/z0IgK9mm3jDew0AAAAA8E+0uMIm7mqksXZXlKsmCDdSRUOm2bI/Y5IztWCn4xMV2+v8kKw1SA2eHa1r3l+sFBt7CxR3Jr9Ia2NS7B6mxx0NY/YOU1fW+/nmLzs0cOZWt0yQ7k/O5BfaVO78hKEvW3PQ9jvkuTvU9/nyKcDx2H34RTvB0f21Nf60Fu6yrwedLx9XAAAAsB9zFgIgWQO/4W/NnV3HrtJ/ZmzVajsafctTUYKieMKhrMbjX7cdU05+kWZvTrD6fHlenBGlJyZvdOn8FMUdOpmlE+meS/TlFhRp9pYEzdtxQkdPu2a7v0cf0+/Rx1xSl6+z1kiZV1gkk4d/u/pCIs5bQzSbzVp36JQHtlP+8weSMrUt/rTb4/B3vp5ANULxXfbQ1+v0wo9RiknOdONWAAAAAO/npZewAYP9790YBg1ww1nK3p4b5dl1LEOdrqjvsvqs2Rp/WlviUi2Pg4LKb/45kGRjY1Oxfbti/9mk0w/rj+jte69yIMqync7O151jVrq0Tnu4Yui+7LxCvTIrWpJ051XhuiDUf0/PjuyujNwCXTciUs3qVXd9QFYY3TDtiR9PtiRoJelYmmPJyE2xqSUe/x59TA+0u8ihupzR7fNVkqTnOzXXLZfXU5cWDZyqz1uTY/ANCafP6PIGNWwqa/R5CAAAAADgWfSsCTD+dN3v6aGDXJmA8bYGmIe+XqePFuyzPA6SFHxekGtjUiz//z3adZONu0JsSrZHtuPO9y232ETaeX42qfZ3649Y/u/oPly5/6QKTWbFJGe5KKrynWuQd+Xn3lfd8vEyh9Y7kZ5b4vG5ZKRtXJ8R+XZ1rJ6Zttnl9XoLVx+pDMHgGST/AAAAAADnkKwB/Iwr2paDgkrX8+x0/23khGeR//AOJKL+8dmi/Rq98J+E9dK9SXp2+mYlZ+aWsxbcjfmcAAAAAACBhGQNbOKrbXrumm+i8+jl+mHDkYoL2ulE+hmlnylweb32s6eJzDsPDlces2aztONoms7ke6bHS36RqexY/PRu9/PfrldnR9uwjvuPPU/MWWPLe/rtqsMlHqdk5WnkvD06aOuQhChTRm6Bxi+P0dcrDul0dr52Hk1Xv++2aNm+ZL3/5x6b6jCbpV3H0pWTX+jmaN3LP88u3q287yp63QCAdf76exiA73LmurH4mtys5CC+FlABX7q2IlkTwHw1AXOOJ3+km86b1Tw+NUfvzd3l0m2czMxTx1HL1Pb9xS6t9xx7fzz40l33tsb64NdrlV9YMhFiy275Jeqoeoxfqy1HPDNJ+W/bjtlV3pfeK1udys4v8diHvlcl2f9DoKK38MMFe0s8fn3Odk1ZE6uIL1bZGZnxnDl3u+NILyr6J55ZmxN0//g1lscnM/NsqmP94VO676s1eujrdS6Pz90cPX144seus9/znj41GnEuXrI3SV8tPejx7QK+yh9/MwEA/EiAfE0FyMv0Wux/70ayxs+4q/EkkLP7A2Zu1e1jVrh9HpFdx9MdXtcdb7svXcvamojaFp+mJXuT7K5/1uZ4u9dxRm45PXgC+bMYaMo7qnceO3u+MBmQxfLnY/DnLQlOrb8v0fGeTrleMFdVTrFzz/mnVV+6E+kcd8TsjbthTOQBo0MAAAAAALgAyZoA42gjQyB3NZ+/44SOnMrRqoMnXVantzd1+lKipixlNdIVGdG6XQ5rDd/2RuiJobpcyVq4Fb0Ca4dkIJ+XjGTrfnfmPFLWIW1tsa+dr8q6q9tTwyyWp+37i/XhfNuGfoP7ednXFQAAANyN339AwCNZA78Qk5ylAz4wd8PamBQ9NWWj4lPPGB1KuYIkBdvYAuprDaXnKyv+4svd+XvpXMN38Qbcr5bFaNcxx3tawXV8dbgUdyfw3Hl85hUWaem+ZLfVbzRvT65+uzrW6nIf/Sj4tL0nMowOAQAAAADgQZWNDgCu5a7GFC9vW1LXsSutLve2sJ+YvFGStPpgisGRlC8oKKjUseTQseXDjXt5581t42n3fbVGcR93t6mstYRCXEq2LrwgRDXCqji0fXc2zJZVd3k9Nqz2qHDzARabkq1jad6dWDXCmfwiPWjD3Cxl9o6p4MS8xonzo7d/V7mS2WxWfpFJoZUruad+t9RqH78ccs8bdiwA+Di//H4AELA4owEojp41sEmhlbE4tsaf1vA/diszt8CAiOBOQeIHw4RlMUaH4LADSZnq8tkKdfhoqcN1BFKjd1n+/cMWt9S7LiZF09aW7L1g//4u/xPqzh5BmbmFbqtbcs2x56s9ouzxxOSNuuq9hTqdnS/J8z1fAmAX2+38XlOcRgEAAAAA9qBnDRz20N93VheZzBrZs7VDdZx/J/3Iea4dK9+mtiQfanDKyC1QjdDKbm+INMv2YdDsr9s3mq/WHTpldAgOW3Xg7PxKOU7MgeHp98moj+GuY+laf9j6e53gpuEKH/+7h11FbN8nvvGZ8oRASiCcO0dF7k3Sv65vYnA0Fftg/l51vOxCXd24ltGhAAAAAADglehZA6cdOpnlsrqmrLE+Vr43MLqnQdSR07pm+GJFfLHKMxu0sdGzvGInM/NcEkqFMTjRQlv2ROaefcO9bR6LI6dyLP8vLHLtkHDe9FLv+2qNW+ot/hLHLTmoZ6ZtUlpOfpnljU4yuON499RrsnY8edvnyRkbD59S+hn39WAta1dV9PY5sotfmRVt/0oAAAAAUA7/ufoDSNbAz/nDCftcg+fXy88Oy3UgKcuheTTOT2hk5Bbovq9Wa8Jy68N9nd9Q50jD3H/n7LB/JdjE3sbomORMDZq1TTHJtiVXTcXqL37snMkv0utztmvp3iS7th/IPl9yQCv2n9TYyANGh+IVfP287On4e32zQQ+Md09SsTzueJ2uTvwCAAAA/sRXRiJxVmC8Su/F/vduJGtgqINJWcordHyoJpdww1nKkRvKi69TfB4ga23ytja4l2f62jjtOpahTxfttxqLK4Za23siw+k6ijOq84E92y0sMumB8Wv06uxoG+s+W7u7hrabuiZW+xIz1PubjZobfVyPf7vBoXryC03q/uVqXTV0oeZEHVW/7xyfz8XoXiTO+m3bUd300VLtOpZeZhlrL/F0jnfN7+VPvU/OcfYleeuhGVesp5sRBs7cqsMns52uJ+5Ujsu/FzytvGPMlvN42pmye9jZYtySg3rxxyin6gAAAACAQOJL7VAka2CRmVug5Ixcj25z0Oxo3felY3cMB3m4Wc2TH+zpa+PsKh9Uxv/zC/+5izkrr+Sk4BUlyc5/ub50YitPocmkbfGn7VrHnvbfLUdOa/vRdP227Zh9gbnJiHl7dPcXq5WSdXZIumQbh6Y7//O1Juakdh83rpE1y8qk9kYdk6/O3q7EjFwNnLnVJfU5fy7zkw9ngHD3nGPuMG/HCX0wf69L6rpn3GrlFhh8k8Z5cvJLn1/c5dXZ251a//MlB/TXrkQXRQMAAABv4of30wGwU2WjA4D3aDN8sSRp63t3KeNMgVvHyC/uYPLZ3jWhlSt5ZHueYO379US67UOX5btoqBhnutDa2p5ob7ujp5Ns5xv2+25lFGv4X3XgpB5o11iVK5XMXTsap8nOX1f2vkcrDySr6YXVFFrZuVx7UJB9PwRNBo9e9PZvO40NwIpCk7f8kvaWOOAMX+9xYo/M3EKFVfGO7/z/RR3Va3OcS6CUxZXfdpm5nvtdBvgz30uXw5pAGSYIQGAofkbzwfu6AJ/gS4lQetb4oR/Wx+md33ZaHeLGlvP+3hMZ6vLZCj0wYa3rgyvD6Wz3NEC48sPobF0dRy1zan1v/dL25AnPnk2Vtb8yzuuh8dqc7Zq08lC5dW2LT7Njy6UVFpm0NiZF2Xll372dmm1bj5ePFuzTe3N3uX2/23IR/PWK0vMdHTqZJZODSQyjE3nFTVwRozNedvd/cd56PrBFRcduea/NHce9N/xmy8gt0OOTNxodRgne+GN2xf5k3TlmRZnPRx1J1XPfbVG8HcPGuStRYytb93P7D5bo1k+WuzcYAAAAGMqbrol9CXvNPuwv72ZosmbVqlW6//771bhxYwUFBWnu3Lklnn/mmWcUFBRU4u/uu+8uUSY1NVVPPPGEatasqdq1a6tfv37Kyio5n8eOHTvUqVMnhYWFqUmTJho9enSpWObMmaOWLVsqLCxMbdq00YIFC1z+ej3lvd93a8bGeK2JSTE6lBLOTSzsq/Mk+GbUvstsNmvp3iQl2TA0n7MTt/+61b1Dln25LEZPTN6oft9tLrNM17GrbK5vTtRRp2Oy92NorQF99MLS8x3dOWal3vt9V3k1lbltb7pLcm70cZfXac+5z2x2/95wdDguX04UeQNrx8FJG4cnLI+n3xYjPq3PTNusQ+XMnfPwxPVasjdJ/5np/JwuZrNZy/cl63ia7b1i3an4sKYAAAAAAP9kaLImOztbbdu21YQJE8osc/fdd+vEiROWv59++qnE80888YR2796tyMhIzZs3T6tWrVL//v0tz2dkZKhbt25q2rSpoqKi9Omnn2r48OH65ptvLGXWrVunxx57TP369dO2bdvUs2dP9ezZU7t2ldfg6P2szfFQnKcz9i3fW6iP/9pn1zo7j6br7i9WaeWBk26JKSE1R+/Ote19tra3ohPSbC7rTt7TxG2f+TtOaObGeKvP/bH9uPp9t0XTis3fk1HGEDDby3gfnOHKBumfNp19jRsOp7quUi82o4z31N+Ul3vx1c+kLZzNt5f12UrOyNVni/Yb2jjui+/b6IX79N85230ydnfZdezskHLOnMeX7E1W3+mbdfPHzvWKBQAAAADAVobOWXPPPffonnvuKbdMaGioGjZsaPW5vXv3auHChdq8ebOuv/56SdJXX32le++9V5999pkaN26sGTNmKD8/X1OnTlVISIiuvvpqRUdHa+zYsZakzrhx43T33Xfr9ddflySNHDlSkZGRGj9+vCZNmuTCV2y8g8lZOpiUqSvCa3h824UmsyatPKQ3725h8zp9p29SSla++kzdpLiPu7s8pj5TN+mYEw2DPSesdUtc9srKK5TZbLbrTvkJy8sf+svWBllnGsMG/D1Be6cr6qlJ3Wolnlt9sHTPMFsTa+ckpNo+FM75PNUBzKhuzvbOWePqbbukHtdU4xWM7q3iDd3t+/8QVWYC3J1s7dVSZDJr3o7jatmwppsjsk9KVr5+iTqqGqGO/aQz+tjzRhm5BXr9F+vDo7l6f1VU3/G0M5q1OcG1GwUAAAD8CDeuwZ94/Zw1K1asUIMGDdSiRQu9+OKLOnXqlOW59evXq3bt2pZEjSR17dpVwcHB2rhxo6VM586dFRISYikTERGh/fv36/Tp05YyXbt2LbHdiIgIrV+/vsy48vLylJGRUeLPV9z1ue3DLXlKWQP+nD+/iKvqPedwStnDqZzP2xu0PrEyJFVZzg1JZw93NuYWnzQ5ITXHZRNtF++VY4+1MSlum68kJ9+5Y/octw+Rdd777a3Hv9ls1sh5ezyyrWQbhuQrj6PDjlmty2U1ObBtJzdeVpLQlkSNq4/DY2lnFPGFbd+JMzce0Suzom0u72n5DpzXy+MNwxIadd4ZOHOb0nKs9+T0dJL7yckb9eXSg57dKAB4OW+4yQQAXIUzGoDivDpZc/fdd+v777/X0qVL9cknn2jlypW65557VFR0thE1MTFRDRo0KLFO5cqVVbduXSUmJlrKhIeHlyhz7nFFZc49b82oUaNUq1Yty1+TJk2ce7Eu4qPTwZQp2Iu+tezZt658G6w1mFmb82DSyvJ7ypSss3zubCArqwHw3GvqNHq57hm32iVzONgeU0lPODjRt8lU8Tu/LuZUhWUC0ekyGkbLY5a07tApTVkT6/qArLjxo6X6fn2cR7ZVET871RtmzcGSQ2yWd+pb68bPrrd9d5tMZr84yBzdr6vsGHrV0Xn4lu9P1j3jVmtPBTcn2HNTCQAAAADAt3l1sqZ3797q0aOH2rRpo549e2revHnavHmzVqxYYXRoGjJkiNLT0y1/CQkMUeEOzt41lZThuQZ/d7E2ifsz0zY73EDkjR6YsFZ9pm0usSzulHMNVJ7ePROWx6jtiMU6lJxl13recPe6p5X13uw5bn+PqrLufneXEX863ounvM+sL32cK4qVidB9X5fPVujXbcecqiM7r7BEr8nibL0hwNs/Fwt3JardiEjLvHrnv67ywu87bbP2nsjQjqPp7gsQAAAAPiUQ2wcAlOTVyZrzXXrppapXr55iYmIkSQ0bNlRycnKJMoWFhUpNTbXMc9OwYUMlJSWVKHPucUVlyporRzo7l07NmjVL/PkaV30J2NsLY++JTJvLOtOzZujv9s1v4kqe6BBUZEMvDkdZayAr63hxxTAERSazVh04aVPPFG+x/lDJu+w/XbRfmbmFGjl/r0ERnWVyQ+um2Wz2yHATCaeNm1jeSO74QW5kMrf18EVKzc43bPsVOXo6R6eybE/k/7r1qH6Pdi5xUVzx4fDWxaQo3cMJx/ONWVz6hoB4G+b7Ku8QM5vNunrYIrV9f7EzoXm9F36MUvqZAvWZusnoUACnTJgwQc2aNVNYWJg6dOigTZvKP6bT0tI0YMAANWrUSKGhobryyiu1YMECD0ULAAAA+C+fStYcPXpUp06dUqNGjSRJHTt2VFpamqKioixlli1bJpPJpA4dOljKrFq1SgUF/zSGREZGqkWLFqpTp46lzNKlS0tsKzIyUh07dnT3SzLMhsOuG87F3jbBe79cbXPZ8uZ4qKiB8/v1R2zeji3y7LhbPMWOhkDbnT+HiBeNEecivvSS+k7fbHW5p15CWY3x368/YtNn0t44ucPHu3jzRyW/0KTOo5frlVnRVp93R0LRHrd+slztP1hiU9mMMwUa/PN2vTIr2mXzWD3//RbL/x+fvFH3j19j6Llvwc6yh3yFfby9JxBgzezZszV48GANGzZMW7duVdu2bRUREVHqhrhz8vPzdddddykuLk6//PKL9u/fr2+//VYXXXSRhyMHAAC+yp9GivFF7H3vZmiyJisrS9HR0YqOjpYkxcbGKjo6WvHx8crKytLrr7+uDRs2KC4uTkuXLtUDDzygyy+/XBEREZKkq666Snfffbeef/55bdq0SWvXrtXAgQPVu3dvNW7cWJL0+OOPKyQkRP369dPu3bs1e/ZsjRs3ToMHD7bE8corr2jhwoUaM2aM9u3bp+HDh2vLli0aOHCgx/eJs2xt8On9zQZlnHHNROfu5M0NkmVJzsjVbgeGc3IVVzT6BQUZf/L25HvPDwXPclXDtDefH+w9pIw8Z9jLlvcvK8/698vPmxP0mxPDa9m6X21NZldUX/EEzUo75jGxR3xqjkvOQb6U7PYEhuMDbDN27Fg9//zz6tu3r1q1aqVJkyapWrVqmjp1qtXyU6dOVWpqqubOnatbbrlFzZo102233aa2bdt6OHIAAADA/xiarNmyZYuuvfZaXXvttZKkwYMH69prr9XQoUNVqVIl7dixQz169NCVV16pfv36qX379lq9erVCQ0MtdcyYMUMtW7bUnXfeqXvvvVe33nqrvvnmG8vztWrV0uLFixUbG6v27dvrtdde09ChQ9W/f39LmZtvvlkzZ87UN998o7Zt2+qXX37R3Llz1bp1a8/tDAOknfHeYWrO8cXGp42xqUaH4BaeGAYrUGQXa8h2x3519ecmKCiI99+L+VKu8Y3/7TA6BK/k6p6g/sKZc1lmrrHDywG+ID8/X1FRUeratatlWXBwsLp27ar169dbXeePP/5Qx44dNWDAAIWHh6t169b66KOPVFRUdu/DvLw8ZWRklPgDAAAAUFplIzfepUuXcu8mXbRoUYV11K1bVzNnziy3zDXXXKPVq8sfeuvRRx/Vo48+WuH2/ElugfffdVrW3dF/bD+uzXGnPRyNsUpNXFzGZ8dVDbe2tpH5YkLtfM4OKWfvPr/po6UVFwpEvpR1kPt7ZDlzVNpyTNOjzHu4Illjb0I1J79QL83c5vj2/ODc74isPJJA8B8pKSkqKipSeHh4ieXh4eHat2+f1XUOHz6sZcuW6YknntCCBQsUExOj//znPyooKNCwYcOsrjNq1Ci9//77Lo/fEYF67vI3DM8LwNs4c2lVfNWzv+ldc44LpMs9rm1REV/67eBTc9bAOxxIynR5nWWdV4PLuKB6+afyG5j87URdWGQKqC9ayfhh2Nwps4whouxR8ged/Yyc8ygQjmV3715X12/PDxdfeP/87TvAHaavi9PSfdbnpEDZElLPGB0CYCiTyaQGDRrom2++Ufv27dWrVy+98847mjRpUpnrDBkyROnp6Za/hIQED0YMAIAPCZCbCvxxDmZfwt73bob2rIFv6vb5Ks0dcItHthVIJ/DyXutVQxeqemjJj2tZ5W3ZZb9EHbUrNl90dt4dzzTYFt/nRjQRn79Nt7RTe+CjmJHrunm08sqYryImOVOXN6jhkm24+/xU3tvoivf4hw1HdGPzun52nrVvx5xf+nBKdonHvrRn7H0b08+4r4dIRcfnjA3xurhOVbdt3wjfr49z6z4F3KFevXqqVKmSkpKSSixPSkpSw4YNra7TqFEjValSRZUqVbIsu+qqq5SYmKj8/HyFhISUWic0NLTEMNYAAAAArKNnjR9ztP3NlkbAZR66G9eXGsrcqaDIrLQc+xuBRvy5x+ryIb/udDYkC3uPM1uH6vHke282m5WQmqM7x6zQrE3xHtxy+QmlO8as8FwgXuDTRftdUo/JZNa//s/6WPvjlsa4ZBuu5Ox8QI6e6+ftOKEVB046tW14D093JnJme58vOaDX5mx3XTBWeDoJOfT33R7dHuAKISEhat++vZYu/Wd4VpPJpKVLl6pjx45W17nlllsUExMjk+mfmyIOHDigRo0aWU3UAAAAOzBAABDwSNb4MV8aBcavbuz2IjM2ejbx4MuG/bFbh05m6y0XJrKcdfhkdsWFfJCrPu9BQUFW68rKd10PnfK4aqitxIxcl9TjiFgvOcZ2HUsv87moI6XnJ/PUMGeObCUhNcflccB+3jAUHj9t4AsGDx6sb7/9Vt9995327t2rF198UdnZ2erbt68k6emnn9aQIUMs5V988UWlpqbqlVde0YEDBzR//nx99NFHGjBggFEvAQAAAPAbDIMGr+bO3kG+rqyGqPLu0k/JylO9C2wbhuL82h19L1Kz81W3+j93WnrrpF65BUUuqcfabiq+rNR+dbA5b2uxBmxPNAi6ahsun2vFOw8nq3E5G+rJzDzVr3H281ti6D0P7wN3JNe3xpdOyJzz8MR1pZb9Z8ZW1wfhIp1GL1fcx909vl273xcv/ey4EjeCABXr1auXTp48qaFDhyoxMVHt2rXTwoULFR4eLkmKj49XcPA/9/c1adJEixYt0quvvqprrrlGF110kV555RW9+eabRr0EAAAAwG+QrEEpRjRueGuDqy0i95Qc5/vIKWPvVC8vGVJYZNuOPj+BYDabHX6PrhsZqT8H3urYyj7I2lwp5e26J6ds1Ac9W9u9nV7fbLCpfm/kzs+7L59LirP2Mh78eq3WvHmHx2PxRn/tSrT8Pzkzr9gzQTqRfkbL99s2vFtFxwtt/b7j/IS7f83FBLjXwIEDNXDgQKvPrVixotSyjh07asOGDaULAx7i7BCyAOBNOKMBKI5h0AAnPf/9lhKPP1t8wKBI3Kf5kAVO9YiZsfGIC6Oxna9cyL07d5dL63O0jbLI5CeZjnLEn8rW5NWHleOhodJc6ejpM0aHIMn4z1VhUcmE6JQ1sSUef/LXPk+G4zO8YVgwd5q08lCJx79tO2ZQJIB7NWvWTCNGjFB8PEPdAgAAAP6GZA2cxs2rgSG3oHSPEXgnR9tk7x232rWBGKCi89H2o+n6YP5efbpov0P1F1aQ0Lrt0+U6kW49qeLKU6XRCRNXS7Jj3p6npmwq51mz8ov8+1y142iavl112OgwymVEWmjXsYwSj0fO26MDSVku306hyfbjyyypwM+PR3jeoEGD9Ouvv+rSSy/VXXfdpVmzZikvL6/iFQEAAPyUf9+WhkBDssbPLCw2NIwk/bH9uHs25LE7dB1rkAyEE3VZr9HTjbjrDp1yWV2TVv7TAOmvQ9i441W5qs79SZmKP1V6cnRX35HvDW/txsOpTtdhba8cOZXjcCLI5u2azS6f+8nWIRLdZcLyQxUX+tv6w64753jDsWivHuPX6sMFe52vyMnXXt55YdUB24ahc7cT6bYnAW2VlJGn+TtO2FR22b5kXTsiUuk5BS6PA4Fr0KBBio6O1qZNm3TVVVfppZdeUqNGjTRw4EBt3eq983kBAAAAqBjJGj9T/KbvxIxcvfzTNrvr8PORUvzaqAV7VeThNzDNhY1Qnyz0z+GLTmZ63x2vZbXTdv50efkFYHEiPVd7jmeUWl7WcHKu+GSazWY9OWWjkjJcd0wVmczaGOt88soX+dP3nd0fWTe+9u/Wx7mvcnu46Q0eMNP2BvGsvEIt2GVbcgewx3XXXacvv/xSx48f17BhwzR58mTdcMMNateunaZOner3Qx8CAOCPXH1Tnrfid4qx2PvejWSNHzudne+R7XjqHBsI82k46/9WHdbccsbpt+eL36VDNjlQWXxq6R4e3mr5vmRDt++JT4av9HQaG+nZOaPu/dKzQ8flF5m0NsZ1PUsk+4YgkwLnAsLXVPSuPPj1Op3JL/JILK5S/KyzYn9F51nPHpdcYMJoBQUF+vnnn9WjRw+99tpruv766zV58mQ9/PDDevvtt/XEE08YHSLgNvwWAeBPOKMBKK6y0QHAR3mo4bb4Zh77doP6dGymtk1qeWTbvirHRY1xRv9gcDY5ZzbbfiHn7Gt1yZBEAcTdbZxxKdnu3YAN/LkRgTZq3xSdkKZfth7VUzc1NToUhzwzbbPL63Qm4TJlTawLIwFst3XrVk2bNk0//fSTgoOD9fTTT+vzzz9Xy5YtLWUefPBB3XDDDQZG6b185N4TAECAOjusPRdc9uLr3T7sL+9GsgY+Y1NsqjbZOFQPd7w6x9UXska8HfYmUHz5kDn/7XJJosDJKoz8DJ4/0binecOxZOv+DwqS8gvtmwDd2xu6bN3/787dqasa1Sy/LhfE4ym2vC0Fdr7XjnLVZ8Dd+395hb11yvbBfJL0MMYNN9ygu+66SxMnTlTPnj1VpUqVUmWaN2+u3r17GxAdAAAAAGeQrEEp3tQQ50WheFSyDfNReEODMM4KhLtf7P0s/nfODrfEcT5Hz1fufLdWHjipS+tXd7oeTyS8zGapy2cr3L4db/Tjhng9duMl5ZY5csp3hmP0laEKPWlu9PFyn/+9gucBb3T48GE1bVp+D7nq1atr2rRpHooIAAAAgKswZw0kSZF7kgzdvn83c0vxdjb4zd6S4KZIbGM2SzHJWW7ehr+/655z/p4MsiG14u523f9tPer2bXtr03T6mQKjQ7DZ/sRMo0Mw1Jn8QqND8Fm+cAb3pbnPAFslJydr48aNpZZv3LhRW7ZsMSAiAAAAY/nCtQlgK5I1/syOFtHnv7fz4s5DDe3+cqNwToFvNQjOiXJtsmjD4X8mRPfLHI3Bx2mGO5IDPvLZs3Y8ecN5w5aEWYV1WHkh1up15iNldGLYaAmnzxgdgl9K86GEJeBrBgwYoISE0ufuY8eOacCAAQZEBAAAAMBVGAYNfskV+YA9xzPUqFaYC2ryHrY2IP+0ybUNuMfTcl1an7exp1neV3NVrkqApGblK8mGYf7czQvyOQ6xdT4ihsSyTUGRe+ZwMZnMCg723/eg2VvzVada6XkyzknNds1n3F/2YGp2vtEhwI/s2bNH1113Xanl1157rfbs2WNARAAAAABchZ41KMWbej644u50R9375Wrd8OESj23P3lfqyCTyK5yYTNkpxV5cXqFJk1cfVkqWdzVeOdO27W3t4o4cG57ynL29+AA7eMv31y/lDAPoLrachly5e07neFfvGW95763JKygyOgT4kdDQUCUllR6++MSJE6pcmfvwEBiMvEYEAABwJ5I1/syglgt/mouk0OQ/r0WS3vp1pyHbPf9y6oP5e9Xvu82GxGK0zFzvaOCs8CLXhw99bzgFeXPCzJ/tPJZu1/vvrmNl97F0t9S7OS7VqfX3J2a4KJLyGfEZXLrPtpsRoo78sw+94VwB2Ktbt24aMmSI0tP/Oc+kpaXp7bff1l133WVgZAAAwFlcRwIgWQOnnd+rYOGuRLvr2HfCegOSt/VYCBSe2O87jrqnMdMIZSU+/hd1VBGfryqxbPDP2z0RUkDYn5SpbCaI597SYvKLTFq42/bvoH1uSl58t/6I3vjl7Gc9/pTrJrmfuTG+zOdsuawrLPqnVKBeBo6Yt9fj24zca1CvVvilzz77TAkJCWratKluv/123X777WrevLkSExM1ZswYo8MDAAAA4AT6ysMx5bTm70/KtLu6ft9t0aPtL3YmohK87W5Zb4unIr4Wr7Pc9Xpfm+O9iRl/uGOn9zcbHF7XkFfvgo2OWXyg1LJTHp4Pw5uHHkmzc2iugiL3HQk/bzmqgbdfoSenbHTbNuAcW29McLbH8N4ybkgBHHHRRRdpx44dmjFjhrZv366qVauqb9++euyxx1SlStlzSQEAAADwfiRrUIq9vSoycwvV+5v16tH2Ij3e4RKHtzsnyvNj/MMzfKGHlDNtcd72+n7YcMT5Soq9JrO8u4H+fG//Zsxwf65U1vH4zarDng0ETikwmRSf6rqeNeXx9Jw15fG2c2Jx2xPS7F7nickk3OBdqlevrv79+xsdBgAAgEN8/9ZR38b+924ka/yYox++/EKTDZX/U/u54aw2HE51KlljzYn0XJfW508CrfeLN/O2dsmE1DMVlnFnjwKUwY4DpeOopRrZs7X7YkHA87bzljW7j2do57F03d26oaFxrDt0yqX15RUWubQ+BKY9e/YoPj5e+fkle1f26NHDoIh8gy/dfIKy+UMPcQD+xZmzUvG2nbPfU645xwXSmZL2MVTEl44Rh5I1CQkJCgoK0sUXnx22atOmTZo5c6ZatWrFXV5+YMqaWKNDAICAVmgya/yyGKPDgJdxZROjO3+ruuqH8KDZ0ZKklQdOuqbC8xj1g92XLhTgfQ4fPqwHH3xQO3fuVFBQkGWYvqC/u7QVFZEMBADAZwXIPQUB8jK9FvvfuwU7stLjjz+u5cuXS5ISExN11113adOmTXrnnXc0YsQIlwYIxzn64YtNyXZpHPDuIWGsc21LEncxuldmbqHbt+F7x3D53P1yUrLynK7jWFrFPaQAe/jqx/j36ONGhwB4jVdeeUXNmzdXcnKyqlWrpt27d2vVqlW6/vrrtWLFCqPDAwAAAOAEh5I1u3bt0o033ihJ+vnnn9W6dWutW7dOM2bM0PTp010ZH+AQX+wa/+z0zUaHELCcPV6CDM5kDJi51eV1+mqjrrfYn5hZeqHvnZbgS/jQAgFh/fr1GjFihOrVq6fg4GAFBwfr1ltv1ahRo/Tyyy8bHR4AAAAAJziUrCkoKFBoaKgkacmSJZaxkVu2bKkTJ064LjrAD2TnFdo05EmhyZtacl3b6nemgCE5fI03HY3u4O+vD37K2VOzhxI6/tYTD/AmRUVFqlGjhiSpXr16On78bM+zpk2bav/+/UaGBgAAnMWFKhDwHErWXH311Zo0aZJWr16tyMhI3X333ZKk48eP68ILL3RpgHCCg60lZgZTd6n/W3nI6BAcEFjHgLPDtPl7u6TZ7J+vMSE1x+gQ3CY7z/1D46FiLv86DaxTs9uRVIIvat26tbZv3y5J6tChg0aPHq21a9dqxIgRuvTSSw2ODgAAAIAzHErWfPLJJ/q///s/denSRY899pjatm0rSfrjjz8sw6MBOOtkVr7RIQBOWXXgpF+2Ed/+2QqjQ3CbgW4YGg/+xZ03ZvjKPR++EidQ3LvvviuTySRJGjFihGJjY9WpUyctWLBAX375pcHRAQAAAHBGZUdW6tKli1JSUpSRkaE6depYlvfv31/VqlVzWXBwkoOtEEbPv+EKNMDAo3z/I1OuyD1J6tGusdFhuJx3DT3oWpvjThsdAtyhnHONN52G+A4u3+eRB4wOAT4sIiLC8v/LL79c+/btU2pqqurUqeMXv+EBWzjbKx4AAMBbOdSz5syZM8rLy7Mkao4cOaIvvvhC+/fvV4MGDVwaIHwPjTSeMWVNrNEh+A2zk/1GuFzE+fw5WeLs5wUGKvbW0ahrnP9bddjoEOCjCgoKVLlyZe3atavE8rp16/KZBgAAAYtrVPgTh5I1DzzwgL7//ntJUlpamjp06KAxY8aoZ8+emjhxoksDhBO4aPNrny5iEllvkZNfZHQIsFNeAe8Z3G/OlgSjQyjBU5cw/PwA3KNKlSq65JJLVFTEdxgAAADgjxxK1mzdulWdOnWSJP3yyy8KDw/XkSNH9P333zNWsjdxsIuLO8exD1TsUv/mz8NpSVJqjv/Nu3Q4JdvoEHwW5zPbuboHRXnDvthyV31BkUk7jqbJ5OZz1tHTZ9xaPxDI3nnnHb399ttKTU01OhQAAAAALubQnDU5OTmqUaOGJGnx4sV66KGHFBwcrJtuuklHjhxxaYDwPGebcLij1rvl0qMAdorck6S+NzczOgx4if/O2W50CHDQvB0nNG/HCf2325XcmAH4qPHjxysmJkaNGzdW06ZNVb169RLPb9261aDIAM/5cMFeo0MAgBIue3uBw+veNGqp5f/5RSZXhCNJOpmZ57K6bNHsrfk2l407lWPIdnHWawF4TT8n6qjmRB1V3MfdjQ6lQg4lay6//HLNnTtXDz74oBYtWqRXX31VkpScnKyaNWu6NEDAEX9EHzc6hBK8KYF13chIo0PwOrRZltRzwlpFJ6QZHQa8VLKHf/TD9b5ZdVi9bmhidBiG+2O7d/1WcMZz323R5D7XGx0GPKBnz55Gh+DT+H0DAAAQuE5m5ql+jVCjwyiXQ8maoUOH6vHHH9err76qO+64Qx07dpR0tpfNtdde69IAAUcM/3O30SF4LeZXwYbDp8p9noYM92DSQ7gTPWUCW6HJdXdhwrsNGzbM6BB82hl+BwMAAASsIh+YxsChZM0jjzyiW2+9VSdOnFDbtm0ty++88049+OCDLgsOznH08LOlE0h5ddNeBF/jTT2fPKH3NxuMDgEAAAAAAABAMQ4laySpYcOGatiwoY4ePSpJuvjii3XjjTe6LDD4pozcAsV6wcTdJIwAeJvyJocHnBVkR9bZbGd5AN4jODi43M9vURE9RwAAAABf5VCyxmQy6YMPPtCYMWOUlZUlSapRo4Zee+01vfPOOwoODnZpkHCMO5thyqr7xg+XKLeAoTjOR/IIPo92XcCrpZ8psKs8w6YBvum3334r8bigoEDbtm3Td999p/fff9+gqAAAAAC4gkPJmnfeeUdTpkzRxx9/rFtuuUWStGbNGg0fPly5ubn68MMPXRokPMuZ5hsSNfBFZjPziVRkzOIDRocABDw6wwB44IEHSi175JFHdPXVV2v27Nnq16+fAVEBAAAAcAWHkjXfffedJk+erB49eliWXXPNNbrooov0n//8h2SNt3CwVccfbrbNK2QICMCVoo6cNjoEn0dCEN6CnA/gf2666Sb179/f6DAAAAAAr+UL7TIOjVeWmpqqli1bllresmVLpaamOh0UXCPDziFR/InJ+z97Xs0fEnb2yMkv4pgBEDA43QH+5cyZM/ryyy910UUXGR2K16OHIgAAALyZQz1r2rZtq/Hjx+vLL78ssXz8+PG65pprXBIYnDd9XZzRIQA+ITU7X5tiSTQD8G6ubGMMtKS8v6P9OXDUqVNHQcUyDmazWZmZmapWrZp+/PFHAyMDAAAA4CyHkjWjR49W9+7dtWTJEnXs2FGStH79eiUkJGjBggUuDRDeKTkzz+gQfMqWIyQCAACOW3MwxegQAHiBzz//vESyJjg4WPXr11eHDh1Up04dAyMDAAAA4CyHkjW33XabDhw4oAkTJmjfvn2SpIceekj9+/fXBx98oE6dOrk0SHiWLfO9zNqc4IFI/Meni/YbHYJdGCICALzLk1M26pH2F7usPs7zgG965plnjA4BAAAAgJs4lKyRpMaNG+vDDz8ssWz79u2aMmWKvvnmG6cDg3FO5wTuXDc4i+FxAPc4fDLL6BAAAD5s2rRpuuCCC/Too4+WWD5nzhzl5OSoT58+BkUGAAAAwFnBRgcAwPuQqwHc469diUaHAB+2Noah0Fxh5YGTeu3n7UaHAThk1KhRqlevXqnlDRo00EcffWRARAAAAABcxeGeNQBsU1BkMjoEAIAfOJGe67K6ArkHZZ+pm4wOAXBYfHy8mjdvXmp506ZNFR8fb0BEAAAAAFyFnjWAm/0SdVSZuYVGh2EXpjIAAADwPg0aNNCOHTtKLd++fbsuvPBCAyICAAAA4Cp29ax56KGHyn0+LS3NmVgAAADgbgHcqwbwdY899phefvll1ahRQ507d5YkrVy5Uq+88op69+5tcHQAAAAAnGFXsqZWrVoVPv/00087FRAAAP4okIedgnfhUPQ/QUH0iQ0UI0eOVFxcnO68805Vrnz2Us5kMunpp59mzhoAAADAx9mVrJk2bZq74gAAAIAHZOUVirZ9wDeFhIRo9uzZ+uCDDxQdHa2qVauqTZs2atq0qdGhAQAAAF7NF26itStZAwAAHGM2S3uOZxgdBiDJN36kAijbFVdcoSuuuMLoMAAAAAC4ULDRAQAAEAgW7k7U/J0njA4DAODDHn74YX3yySello8ePVqPPvqoAREBAAAAcBWSNQBK4YZrAAAA77Nq1Srde++9pZbfc889WrVqlQERAQAAAHAVkjUAAAAA4AOysrIUEhJSanmVKlWUkcFQmwAAAIAvI1kDAAAAAD6gTZs2mj17dqnls2bNUqtWrQyICAAAAICrVDY6AADeJ8joAAAAAFDKe++9p4ceekiHDh3SHXfcIUlaunSpZs6cqV9++cXg6AAAAAA4g2QNgFJMZmatAQDAV8QkZxkdAjzk/vvv19y5c/XRRx/pl19+UdWqVdW2bVstW7ZMdevWNTo8AAAAAE4gWQOglNM5BUaHAAAAbBSfmmN0CPCg7t27q3v37pKkjIwM/fTTT/rvf/+rqKgoFRUVGRwdAAAAAEcxZw0AAECA2ZaQZnQIAJywatUq9enTR40bN9aYMWN0xx13aMOGDUaHBQAAAMAJhiZrVq1apfvvv1+NGzdWUFCQ5s6dW+J5s9msoUOHqlGjRqpataq6du2qgwcPliiTmpqqJ554QjVr1lTt2rXVr18/ZWWVHApix44d6tSpk8LCwtSkSRONHj26VCxz5sxRy5YtFRYWpjZt2mjBggUuf70AAADeIOrIaaNDAGCnxMREffzxx7riiiv06KOPqmbNmsrLy9PcuXP18ccf64YbbjA6RAAAAABOMDRZk52drbZt22rChAlWnx89erS+/PJLTZo0SRs3blT16tUVERGh3NxcS5knnnhCu3fvVmRkpObNm6dVq1apf//+luczMjLUrVs3NW3aVFFRUfr00081fPhwffPNN5Yy69at02OPPaZ+/fpp27Zt6tmzp3r27Kldu3a578UDAAAAgA3uv/9+tWjRQjt27NAXX3yh48eP66uvvjI6LAAAAAAuZOicNffcc4/uueceq8+ZzWZ98cUXevfdd/XAAw9Ikr7//nuFh4dr7ty56t27t/bu3auFCxdq8+bNuv766yVJX331le6991599tlnaty4sWbMmKH8/HxNnTpVISEhuvrqqxUdHa2xY8dakjrjxo3T3Xffrddff12SNHLkSEVGRmr8+PGaNGmSB/YEAAAAAFj3119/6eWXX9aLL76oK664wuhwAAAAAJ9jNjoAG3jtnDWxsbFKTExU165dLctq1aqlDh06aP369ZKk9evXq3bt2pZEjSR17dpVwcHB2rhxo6VM586dFRISYikTERGh/fv36/Tp05Yyxbdzrsy57ViTl5enjIyMEn8AAAAA4Gpr1qxRZmam2rdvrw4dOmj8+PFKSUkxOiwAAAAALuS1yZrExERJUnh4eInl4eHhlucSExPVoEGDEs9XrlxZdevWLVHGWh3Ft1FWmXPPWzNq1CjVqlXL8tekSRN7XyIAAAAAVOimm27St99+qxMnTujf//63Zs2apcaNG8tkMikyMlKZmZkO1z1hwgQ1a9ZMYWFh6tChgzZt2mTTerNmzVJQUJB69uzp8LYBAAAA/MNrkzXebsiQIUpPT7f8JSQkGB0SAAAAAD9WvXp1Pfvss1qzZo127typ1157TR9//LEaNGigHj162F3f7NmzNXjwYA0bNkxbt25V27ZtFRERoeTk5HLXi4uL03//+1916tTJ0ZcCAAAA4Dxem6xp2LChJCkpKanE8qSkJMtzDRs2LHUhUVhYqNTU1BJlrNVRfBtllTn3vDWhoaGqWbNmiT8AAAAA8IQWLVpo9OjROnr0qH766SeH6hg7dqyef/559e3bV61atdKkSZNUrVo1TZ06tcx1ioqK9MQTT+j999/XpZde6mj4AAAAAM7jtcma5s2bq2HDhlq6dKllWUZGhjZu3KiOHTtKkjp27Ki0tDRFRUVZyixbtkwmk0kdOnSwlFm1apUKCgosZSIjI9WiRQvVqVPHUqb4ds6VObcdAAAAAPBGlSpVUs+ePfXHH3/YtV5+fr6ioqJKzN0ZHBysrl27ljt354gRI9SgQQP169fPpu0w1ycAAABgG0OTNVlZWYqOjlZ0dLQkKTY2VtHR0YqPj1dQUJAGDRqkDz74QH/88Yd27typp59+Wo0bN7aMi3zVVVfp7rvv1vPPP69NmzZp7dq1GjhwoHr37q3GjRtLkh5//HGFhISoX79+2r17t2bPnq1x48Zp8ODBljheeeUVLVy4UGPGjNG+ffs0fPhwbdmyRQMHDvT0LgEAAAAAt0tJSVFRUZFdc3euWbNGU6ZM0bfffmvzdpjrEwAAALCNocmaLVu26Nprr9W1114rSRo8eLCuvfZaDR06VJL0xhtv6KWXXlL//v11ww03KCsrSwsXLlRYWJiljhkzZqhly5a68847de+99+rWW2/VN998Y3m+Vq1aWrx4sWJjY9W+fXu99tprGjp0qPr3728pc/PNN2vmzJn65ptv1LZtW/3yyy+aO3euWrdu7aE9AQAAAADeKzMzU0899ZS+/fZb1atXz+b1mOsTAAAAsE1lIzfepUsXmc3mMp8PCgrSiBEjNGLEiDLL1K1bVzNnzix3O9dcc41Wr15dbplHH31Ujz76aPkBAwAAAIAfqFevnipVqmTz3J2HDh1SXFyc7r//fssyk8kkSapcubL279+vyy67rNR6oaGhCg0NdXH0AAAAgP/x2jlrAAAAAADuERISovbt25eYu9NkMmnp0qVW5+5s2bKldu7caRnGOjo6Wj169NDtt9+u6OhohjcDAAAAnGRozxoAAAAAgDEGDx6sPn366Prrr9eNN96oL774QtnZ2erbt68k6emnn9ZFF12kUaNGKSwsrNQw0bVr15Ykho8GAAAAXIBkDQAAAAAEoF69eunkyZMaOnSoEhMT1a5dOy1cuFDh4eGSpPj4eAUHMxgDAAAA4AkkawAAAAAgQA0cOFADBw60+tyKFSvKXXf69OmuDwgAAABwA7PZbHQIFeI2KQAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAAADkawBAAAAAAAAAAAwEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAAADkawBAAAAAAAAAAAwEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAfstsNjqCipGsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAAADkawBAAAAAAAAAAAwEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAAADkawBAAAAAAAAAAAwEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAAADkawBAAAAAAAAAAAwEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAAADkawBAAAAAAAAAAB+y2w2OoKKkawBAAAAAAAAAAAwEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAAADkawBAAAAAAAAAAAwEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAOC3zDIbHUKFSNYAAAAAAAAAAAAYiGQNAAAAAAAAAACAgUjWAAAAAAAAAAAAGIhkDQAAAAAAAAAAgIFI1gAAAAAAAAAAABiIZA0AAAAAAAAAAICBSNYAAAAAAAAAAAAYiGQNAAAAAAAAAACAgUjWAAAAAAAAAAAAGIhkDQAAAAAAAAAAgIG8OlkzfPhwBQUFlfhr2bKl5fnc3FwNGDBAF154oS644AI9/PDDSkpKKlFHfHy8unfvrmrVqqlBgwZ6/fXXVVhYWKLMihUrdN111yk0NFSXX365pk+f7omXBwAAAAAAAAAA3MxsNjqCinl1skaSrr76ap04ccLyt2bNGstzr776qv7880/NmTNHK1eu1PHjx/XQQw9Zni8qKlL37t2Vn5+vdevW6bvvvtP06dM1dOhQS5nY2Fh1795dt99+u6KjozVo0CA999xzWrRokUdfJwAAAAAAAAAACExen6ypXLmyGjZsaPmrV6+eJCk9PV1TpkzR2LFjdccdd6h9+/aaNm2a1q1bpw0bNkiSFi9erD179ujHH39Uu3btdM8992jkyJGaMGGC8vPzJUmTJk1S8+bNNWbMGF111VUaOHCgHnnkEX3++eeGvWYAAAAA8IQJEyaoWbNmCgsLU4cOHbRp06Yyy3777bfq1KmT6tSpozp16qhr167llgcAAABgO69P1hw8eFCNGzfWpZdeqieeeELx8fGSpKioKBUUFKhr166Wsi1bttQll1yi9evXS5LWr1+vNm3aKDw83FImIiJCGRkZ2r17t6VM8TrOlTlXR1ny8vKUkZFR4g8AAAAAfMXs2bM1ePBgDRs2TFu3blXbtm0VERGh5ORkq+VXrFihxx57TMuXL9f69evVpEkTdevWTceOHfNw5AAAAID/8epkTYcOHTR9+nQtXLhQEydOVGxsrDp16qTMzEwlJiYqJCREtWvXLrFOeHi4EhMTJUmJiYklEjXnnj/3XHllMjIydObMmTJjGzVqlGrVqmX5a9KkibMvFwAAAAA8ZuzYsXr++efVt29ftWrVSpMmTVK1atU0depUq+VnzJih//znP2rXrp1atmypyZMny2QyaenSpR6OHAAAAPA/lY0OoDz33HOP5f/XXHONOnTooKZNm+rnn39W1apVDYxMGjJkiAYPHmx5nJGRQcIGAAAAgE/Iz89XVFSUhgwZYlkWHBysrl27VjjKwDk5OTkqKChQ3bp1yyyTl5envLw8y2NGJAAAAACs8+qeNeerXbu2rrzySsXExKhhw4bKz89XWlpaiTJJSUlq2LChJKlhw4ZKSkoq9fy558orU7NmzXITQqGhoapZs2aJPwAAAADwBSkpKSoqKrI6ysC5UQgq8uabb6px48alhpUujhEJAAAAANv4VLImKytLhw4dUqNGjdS+fXtVqVKlRJf7/fv3Kz4+Xh07dpQkdezYUTt37iwx5nJkZKRq1qypVq1aWcqc320/MjLSUgcAAAAAoKSPP/5Ys2bN0m+//aawsLAyyw0ZMkTp6emWv4SEBA9GCQAAAPgOrx4G7b///a/uv/9+NW3aVMePH9ewYcNUqVIlPfbYY6pVq5b69eunwYMHq27duqpZs6ZeeukldezYUTfddJMkqVu3bmrVqpWeeuopjR49WomJiXr33Xc1YMAAhYaGSpJeeOEFjR8/Xm+88YaeffZZLVu2TD///LPmz59v5EsHAAAAALepV6+eKlWqZHWUgXOjEJTls88+08cff6wlS5bommuuKbdsaGio5doLAAAAQNm8umfN0aNH9dhjj6lFixb617/+pQsvvFAbNmxQ/fr1JUmff/657rvvPj388MPq3LmzGjZsqF9//dWyfqVKlTRv3jxVqlRJHTt21JNPPqmnn35aI0aMsJRp3ry55s+fr8jISLVt21ZjxozR5MmTFRER4fHXCwAAAACeEBISovbt25cYZcBkMmnp0qXljjIwevRojRw5UgsXLtT111/viVABAACAgODVPWtmzZpV7vNhYWGaMGGCJkyYUGaZpk2basGCBeXW06VLF23bts2hGAEAAADAFw0ePFh9+vTR9ddfrxtvvFFffPGFsrOz1bdvX0nS008/rYsuukijRo2SJH3yyScaOnSoZs6cqWbNmlnmtrngggt0wQUXGPY6AAAAAH/g1ckaAAAAAIB79OrVSydPntTQoUOVmJiodu3aaeHChQoPD5ckxcfHKzj4n8EYJk6cqPz8fD3yyCMl6hk2bJiGDx/uydABAAAAv0OyBgAAAAAC1MCBAzVw4ECrz61YsaLE47i4OPcHBAAAALiB2egAbODVc9YAAAAAAAAAAAD4O5I1AAAAAAAAAAAABiJZAwAAAAAAAAAAYCCSNQAAAAAAAAAAAAYiWQMAAAAAAAAAAGAgkjUAAAAAAAAAAAAGIlkDAAAAAAAAAABgIJI1AAAAAAAAAAAABiJZAwAAAAAAAAAAYCCSNQAAAAAAAAAAAAYiWQMAAAAAAAAAAGAgkjUAAAAAAAAAAMBvmc1mo0OoEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAAAAAAAAADAQyRoAAAAAAAAAAAADkawBAAAAAAAAAAAwEMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAMBDJGgAAAMCH3XzZhUaHAAAAAABwEskaAAAAwIeFVuYnPQAAAAD4Oq7sAAAAAB8WHBRkdAgAAAAAACeRrAEAAAAAAAAAAH7LbHQANiBZAwAAAPgwOtYAAAAAgO8jWQMAAAAAAAAAAGAgkjUAAACAT6NrDQAAAAD4OpI1AAAAgA+rxC96AAAAAPB5XNoBAAAAPmzwXS2MDgEAAAAA4CSSNQAAAIAPa1gzzOgQAAAAAABOIlkDAAAA+DKmrAEAAAAAn0eyBgAAAAAAAAAAwEAkawAAAAAfFkTPGgAAAADweSRrAAAAAAAAAAAADESyBgAAAPBhdKwBAAAAgPKZzUZHUDGSNQAAAAAAAAAAAAYiWQMAAFCBe9s0NDoEoExBTFoDAAAAAD6PZA0AAEAF7m3TyOgQAAAAAACAHyNZAwAAAPgw+tUAAAAAgO8jWQMAAFCBIJrDAQAAAACAG5GsAQAAAAAAAAAAMBDJGgAAAAAAAAAAAAORrAEAAKiAWWajQwAAAAAAAH6MZA0AAAAAAAAAAICBSNYAAABUIEhBRocAAAAAAAD8GMkaAAAAAAAAAAAAA5GsAQAAAAAAAAAAfsz756IlWQMAAFABsw/8qAMAAAAAAL6LZA0AAADgw4KYUgkAAAAAfB7JGgAAgAoEidZwAAAAAADgPiRrAAAAAAAAAAAADESyBgAAAPBhwYyDBgAAAAA+j2QNAABABcwyGx0CUKawKpWMDgEAAAAAvJrZBy7rSdYAAAAAPqpBjVCjQwAAAAAAuADJGgAAgAoEyfPDTL1215Ue3yYAAAAAADAGyRoAAAAv9EKXy4wOAT6A6WoAAAAAwD+QrAEAAAAAAAAAADAQyRoAAOAWr0e0MDoElzHLB2YiBAAAAAAAPotkDeCAS+pWc3mdTS90fZ0A4Kxxvds5vG6lYMZnAtzNiPmUAAAAAMDX+MItmCRrzjNhwgQ1a9ZMYWFh6tChgzZt2mR0SAgQd1/d0OgQAKCUB9pd5PC6RSZf+ClkGxrEAfgre69/5syZo5YtWyosLExt2rTRggULPBQpAAAA4N9I1hQze/ZsDR48WMOGDdPWrVvVtm1bRUREKDk52ejQKlSlEo1Ivq5O9RCjQ5AkNaoVZnQIAPyEyQ+SNf/ufKkWDupkyLYrMXM8ADez9/pn3bp1euyxx9SvXz9t27ZNPXv2VM+ePbVr1y4PRw4AAAD4H5I1xYwdO1bPP/+8+vbtq1atWmnSpEmqVq2apk6danRogMfccnk9o0MA4CeKzL6frLmtRX21bFjT5vItG9ZwyXbrVKuiYIaRs0ug3mxATg/OsPf6Z9y4cbr77rv1+uuv66qrrtLIkSN13XXXafz48R6OHAAAAPA/JGv+lp+fr6ioKHXt2tWyLDg4WF27dtX69etLlc/Ly1NGRkaJPyP5QXuYT3FHwwhtLQD8jT/0rDHKFQ1ck/QBgLLYe/0jSevXry9RXpIiIiLKLC9533UTAAAA4K1I1vwtJSVFRUVFCg8PL7E8PDxciYmJpcqPGjVKtWrVsvw1adLEU6FaVddLhtDyZnWqVXFZXW/fe5XL6jrn9pYNrC531V3atnroun/mp+jRtrFHt+0tLqpd1WV11QyrbFO5+65p5LJtorTix7Unuevc3KSu647R8vyny2UOrxsUJHX7ey6uRrXCdFer8ArWsF33Np77vJzrVXNd09o2lX+u06Uu2e5Ld17uknps0bOdf5zrX+xymbqVcZzVu8C7fidd0eCCcp9vfVHZvbnOX/dFJz6nCGz2Xv9IUmJiol3lJe+6bnr0+osN2zYAAABQEdtaEVHKkCFDNHjwYMvjjIwMQy88Jj55nY6cylHNsCq6tH51JWbkKiE1R03qVpPM0tG0M7qhWV3VrxGqFfuTdUWDGpq/84S6t2mkmOQsZeYWKL/IpNYX1VKloCDVqRaiI6nZWrYvWe92b6W4U9kqLDJr6b4ktWpUU6ey8pVwOkf3tmmkwyezVe+CEJnM0on0MzqZmafcgiI93qGp4k5lq1bVKtp1LF3VQyorO79QoZUr6fIG1TV7c4IKisxq26SWRi/8//buPT6q+s4b+GduZ+6XZJLM5H6BcEsitwgGUaxE0VKr7T4VXRbR9WmL4lOoVbddW+3r6VKou/XRur3u81SsVam2iltqcWlAWFgkgICEhHBJQq6T22Tu9zm/54/g1FTXahsyZPJ5v155vZJzfpnzO/OdnDmffOfMtOKhG2di+ew8bDvchVAsiZpCK4qz9Th4fhiD/iiWz86DTqOCVq2ESavB7tMD0GmUCMaSyDFKCEQTWFxux380u5Bn0eFktwfRhIyZTjOWTMtBoU2PtqEAXjzUiaoCC5QKBc4NBGDSqmHRa2DRq3HDHCd6PWEEogl4Q3FAAQwHYqgtzUI8KaPfF0Vxth6ldiP+6+vXIxBN4FjnCIqyDBACCETjEAIozjZAo1JCoQDsRgktfX4EYwkM+KOYlmtENC6jIteI84MBZBkk5Ji0KM424Nymm/Gbd7pxuGMEOo0SX62fAaNWjQvDIWjVSug0KvT7IvBF4pjpMEMvqXDkwggsOjXebnNjcXk2irMNsOo12H92CFcUW9HU44UsA/5oHI3tbnxleSWOd3rg8kWw6spiKBUKvNU6gMb2EXx5WQUcFh12/K+lMEgqlOcYcf2sPNQUWRFPylAqFNCqlfBHEni7bRi5Zi3CsSRCsSRmOs0IXqzBofZhJGWB62fnYc/pQfjCcTisOuSatJCFwEgohlhCxpunXKgpsqG2NAs5Ji38kTiKsgw4cG4Iz799AQ/eMAP9vgjyzDp0DAdRZjdCoQCOd3kgC4G6Cju84ThiCRmz8y2IJ2UkZIGjF0ZQYNOhudcHXyQBu1FCOD76mCrJNiCWlPHKkW5Y9RpY9Rq4gzH86kgXHl05GxadGlcU2dAzEoZRq0ZTjxcGSQWDpMZIKAaDpEK2UUKry4+yHCPiSRkmrRpJWUClVOBUrw8mnRr5Vh2C0QSqCqzwheNICoH/s+sMZjjMmOEwI56UcfX0HLQNBiGpFajIMWHD8kpkGyW8cKgTK6qc6POGkUgKZBkltPT5cMMcB1r6fHAHY6gutKLQpscv376Aaypz0dTjhc2ggScUR8dwEPlWHablmdDlDqGxfQTrllVAFoCAQPtgEJ+alYekLHCofRhVBVb8xykXInEZshD4dE0+9p4ZREWuEVUFVhzv8qAk24BBfxRNPV787eIS7DsziDyLDofahlFTaMVIKI5YMonXjvVieq4JC0ptEAK4YY4D24/1oH0oiHuvKcebp/ph0KigVimwoCQLvkgc4VgShVl6tLr82HtmEPlWHeYVZyHLoIEvkoCkUkKrUUKjUkKvUeHZA+2w6DX4wsIiHOvywBuOI8ckYabTgjP9flj1GmQbJPR4wpiWa0LXSAi1pVn4yvWVcFp16PWEEY4nkWfWoanXi7P9fkzLNaFjOIT62XlIyALFWQa0DwWhUAB6jQrecBzNvT7oJBVaXT5kGSQUZelxZVk2FAoFTvV64Y8koFQA0YSMXk8Ea+pKoVQAbYNBuIMxZBslDPgjkGVgXokN3nAc+84MojLPjNqyLLQNBtHU48WnZuWh1xNGtlGCVq0EFLh42wo89YczuHdpOWY5LegYDmL/2SGE40lUF1pRnKXHiW4PbpjjRPtgEI0dbkTiSdxxZTF+d7IPn7miACe6PbDqNYglZJh1ajgtOvz2RC8EgCXTcmA3SegeCUMWAmatGtMv/lP4xGM3osXlw0gwBoUCKMsxQlIp4Q7G4A7GsGR6DrpHQnB5I+geGX0e2LC8EkqlAvse/hRyzVpoVAoc6/KgwKbHSDAGq16DeFLG75tcuKuuNPXYBQCLToPzgwF0ukPQaVS4ZW4BovEkYkkZDrMONoMGn2sphM2gwVAgBr2kQrndiBcbO/Hlayvgi8ThDcfhDsagVirxi4MduO+6aTg7EMC0XCMOnh+GP5pA/WwHtOrR/VAqFLCbJFwYDuGmKieOd3uQZ9amGm75Vj12ffVavNvtxex8C1r6fIgmZBi1Klw3Mw/NvT7MybfAatBgTr4FF4aDaOnzoTjbgEKbHrlmLQxaNRrbh1FqN2LQH8VV5Xb4o3H0eiIYCcWQlAW0aiWMWjWuqrADAJr/9wrsbR2EUqnAp2bmoeniY+3ohRHcckU+lEoFgtEE+rwRlNoNUCsVOO3yo9Mdwq7mfvztohIsrcyByxuB3ajFUDCK4UAMI8EYZjrNSAqB+cU2fO3GmdBqlNjV3I8VVU74wnGolUqcHfDDpFVjVr4Ff2juh1ajRCIpsLA0C+1DQbQPBVHpMMEgqWGUVIglZXS5w3AHY8i36XDdjFyc6vXBqFUjFEtAp1Ehx6jFBXcQ+VY9ukdCsOo16PVEYNCq4AnFkGWQEI4lEYgm0O+PYrbTjNZ+PyrzzJhTYEHPSBiSWokTXR6cHwzgfywsQjwpMC3XiNWLS7Hv7CBGgqPH618f7cZXb5iBWU4Lzg74oVEpIYSAWafBaZcfCgBG7ejf+JJpOfBHElAoAK1aiVaXH2qVEmV2A4KxJCLxJFpdfgQiCXxmbj5+c7Qbt84vxKkeH1pdPhi0asQSMvKtOlQVWNE2FIAvHEep3YjhQAwOixYmnRrdI2EsLMnCBXcIRkkFADDrNPiv80MozjZAFgIzHWa81ToIq0EDm16DE90elNqNCEQSqJtmx0gwhj2tA6gqsKKq4OO/TR9ROlxOuWlhaTaevftKvHGyD8e7PAjHk/ifS8txqN0No1aN7pEQBnxRAKPP1ZF4ErGEjD+0DGBesQ1d7hCqC61QKICekTAseg063SGsrSvFy0e6McNhQr8vin5fBCuqnHAHY/BHE9h/dhBldiN0GhWa+0avLCqzG+DyRWDTS7ixyoGTPV50j4SxZJodu08PwCipUV1oRSiWwJl+P4YCMdTPduB41wgcFh2a+3wwa9UwSGrYDBqE40ksLMnCgfNDWFCShfklNrx+vBfZRglCjB7r/JEEWvp8mJZrQnOfDwZJjUh89HgL/PFFRgU2PSS1EpJKCb2kgkalRMdwEEsvnrvaDBq4vBFkGyVkGyX4owmccflxwR3C3CIrhgIxOC069HpHj3cJWaDV5YfdJGGm0wylQoH2oSB6RsJw+SK4dkYumi8+v9WWZY0+J0gqNPV4YdZp8Nl5BTjd50OfN4JKhxmner2oq7AjGE2gsd2NYCyJ2tIsRBJJ1JZmwxOKoc8bwb6zgyi06eGLJDB4MYfNdJphkNQY9EeRa9YiGE1g/7kh5Jm1kNQqtPT5UJlnSj3fVOQa4bDo8MqRblj0aiwoyYLDosPxLg8q80w42jmCkmwDlAoFwrHRc5VoIol8qx6N7W5UFVhQXWjF0QsjiCaS6PNEEIknMeCPYl6xDRfcIZTZDbDoNPCG47iiyIaXj3TBeTFLmLRqdAwHsag8G4FoEtUFo+eAB84N44Y5DiSSMpxWHQ61uWHSqSEE4PJFIAQw02nCjXOc+N3JPvjCcRTY9OhyhxCIJrCgJAvnBwNwWnWIJWT81/lh1FXYYdSqMDvfgn1nhxBLyGgfCuCWKwpwdiAAjUqBkmwjvOE4Wvp8UCkVuG1eAcIXH0MqpQIXhkMwadUwatUIRBLYecqFHJMWlXkmCAiU2Y1ocfkx4Iugbpode04PYE6BBecGAjBIapTnGLH79B8/M8uq16B+tgN93jC0aiWWTMvBpjdaAAA6jRL3Xzcd5wcDOHBuCJG4DCEEls92XJx7EJ7w6GPx3R4vPl2dj4Ntw7AbJSRkAVkIzHCY0eUOQVIrEY4loZdUWFiahYPnh2EzaGCU1MgxaaGXVHipsROLyrPx+QWFGPLHcG4ggFB89PxArVRg0B+FSqlAnzcC5cXz5YPnh7GoPBs2g4TG9mHMzv/jc7YCwEgojnMDAQSiCSydnjOafS1alNmNONIxgnA8CZNWjXhShkWvQb8vgmsqc3C4YwSVeSa4fBHkmrTodIdQlGWA3SjhtMsHy8X/wcxyWmAzaOCLxNE+GEQsKTAUiOKqimy0uvwosRsxLdeIpCxwpGMEFblGROJJLJuRi9eP90KpUCDbKOHsQABDgShm51uwuDwbVr0G73SOYDgQgy8SR/dIGHOLrCixG1FVYMHWAx24osiKHLMWTT1eFGcZUrlKL6nwi4MXcPV0OxRQ4LTLh+l5JoTjMgptOnS5w5hfYkO2UcIrR7qhUiqQlAVuqnbi/+1vR2WeCXOLbdh3ZhCfnVuA/7u/HRuWV8IbjuPsgB8AcODcMJbNyIXDooUsALVSgZY+H050e6FRKXDdzDycHwjg7qvL8OKhTshCQBajx+Wei3+jkXgS2UYJaqUCRRfnn2WQIAuB4UAMzX0+dLpDqJ/tgCcUQ1GWHnpJheZeH6wGCQoA3SMhZBsl9HoiCMUS0GtUWFCahR3v9o0+BhTA0uk5yLfqMOCPwqLTYNAfhTcch1WvwbQ8I072+GDTa9A9EkJCFrgwHEJ1oQVm7ejzj1mnhtOqQ+dwCLIQCESTUCmBfl8Un7kiHwfODaEoy4CTPV6YdWoUWEeP7woF8G63FwBQkWPEtDwThgJRhKJJ6C6en5bZDXB5IxjwRzESimFGnhm+SBx6SYWhQBTJpEBCFvCERv/f8amZuYgmZETjMhKyDK1ahT5vGEqFApUOE9QqJRpa+jGv2IZANIFsoxbecBxalRJlOQY0trthkNRQKRUIxRJQKBRIJGUUZulhM0iQZQEhgKWVOWh1+fFujxcWnRqN7W7MyrfAG4phaWUOekbCUKuUyDJoIARwpn/0ceEJx+Gw6KBUAJ5QHFdV2NE9EkanO4jPzS/C8a4R+COjx7JO9+j/4EqyjQjFEhgKRJFj0sIXiWOGw4x3u73IMUnwRxLIMY1mxteO9QAAFpTYIIvR45fTokOnO4ROdwhGrQrzim047fLDbpQQjCbhtOowEoohHEvCqtegscONaFzGZ+cVoN8XwWmXHyqFAgtLs5Bv1WFP6wCMWjV0ahUsejXahoLwhOLIM2sRjCVwVbkdLS4fimyG0Z8r7OgcDsEbjiPXrIU7GMP5wQBqCq04OxBAc58PsYSMkmwDgtEEcs1anHb5MT3PhNn5FuxqduGKIhs6h0NYMn30tuwmCW+e6sc1lTk41OZGqd0Ap1UHs04NdzCGQX8UklqF2U4zzg4EcOMcBxKywOEON4YCUTgsOrQNBqFRKZBn0SEaT6LUbsTJHi/iSRndI2HcMrcAnlAMhTY9jnd54LTq4PKO3h+frnFiltOCV9/pRq83glhCRqndgOpCK073+ZBv1SMUS2AkFEeuSYsT3R4kZIGkLPDUqnnj+uLsS0UhBN9ACxh9GwCDwYBf//rXuO2221LL165dC4/Hg9dff/0jf9/n88FqtcLr9cJiYWgmIiIioszHc+DJ6y/JPyUlJXjwwQexcePG1LLHH38c27dvx4kTJz7WdvmYISIiIqKp5JOc//Jt0C6SJAkLFy5EQ0NDapksy2hoaEBdXV0aZ0ZERERERDS+/pL8U1dXN2Y8AOzatYt5iYiIiIhoHPBt0N7nwQcfxNq1a1FbW4tFixbhqaeeQjAYxD333JPuqREREREREY2rP5d/7rrrLhQWFmLz5s0AgA0bNmDZsmX4/ve/j5UrV2Lbtm04cuQIfvazn6VzN4iIiIiIMgKbNe+zatUqDA4O4rHHHoPL5cK8efOwc+fOD3yIJhERERER0WT35/JPZ2cnlMo/vhnDkiVL8OKLL+Kb3/wm/vEf/xGVlZXYvn07qqur07ULREREREQZg59ZM0743stERERENNXwHJg+KT5miIiIiGgq4WfWEBERERERERERERERTRJs1hAREREREREREREREaURmzVERERERERERERERERpxGYNERERERERERERERFRGrFZQ0RERERERERERERElEZs1hAREREREREREREREaURmzVERERERERERERERERpxGYNERERERERERERERFRGrFZQ0RERERERERERERElEZs1hAREREREREREREREaWROt0TyBRCCACAz+dL80yIiIiIiCbGe+e+750LE/05zE1ERERENJV8kszEZs048fv9AIDi4uI0z4SIiIiIaGL5/X5YrdZ0T4MmAeYmIiIiIpqKPk5mUgi+DG5cyLKM3t5emM1mKBSKCd++z+dDcXExurq6YLFYJnz7NL5Yz8zBWmYW1jNzsJaZg7VMLyEE/H4/CgoKoFTyHZbpz2NuovHCWmYW1jNzsJaZg7XMLKxn+nySzMQra8aJUqlEUVFRuqcBi8XCP7gMwnpmDtYys7CemYO1zBysZfrwihr6JJibaLyxlpmF9cwcrGXmYC0zC+uZHh83M/Hlb0RERERERERERERERGnEZg0REREREREREREREVEasVmTIbRaLR5//HFotdp0T4XGAeuZOVjLzMJ6Zg7WMnOwlkT0SfCYkTlYy8zCemYO1jJzsJaZhfWcHBRCCJHuSRAREREREREREREREU1VvLKGiIiIiIiIiIiIiIgojdisISIiIiIiIiIiIiIiSiM2a4iIiIiIiIiIiIiIiNKIzRoiIiIiIiIiIiIiIqI0YrMmQ/zwhz9EWVkZdDodFi9ejMbGxnRPaUrbvHkzrrzySpjNZuTl5eG2225Da2vrmDGRSATr16+H3W6HyWTC3/zN36C/v3/MmM7OTqxcuRIGgwF5eXl4+OGHkUgkxox56623sGDBAmi1WkyfPh1bt2691Ls3pW3ZsgUKhQIbN25MLWMtJ5eenh783d/9Hex2O/R6PWpqanDkyJHUeiEEHnvsMeTn50Ov16O+vh5nz54dcxtutxurV6+GxWKBzWbDvffei0AgMGbMu+++i2uuuQY6nQ7FxcV44oknJmT/popkMolvfetbKC8vh16vx7Rp0/Cd73wHQojUGNby8rVv3z7ccsstKCgogEKhwPbt28esn8javfLKK5g1axZ0Oh1qamrwxhtvjPv+EtHlgZnp8sPclLmYmyY3ZqbMwdw0uTE3TUGCJr1t27YJSZLEz3/+c3Hq1CnxxS9+UdhsNtHf35/uqU1ZK1asEM8++6xoamoSx48fF5/+9KdFSUmJCAQCqTHr1q0TxcXFoqGhQRw5ckRcddVVYsmSJan1iURCVFdXi/r6enHs2DHxxhtviJycHPGNb3wjNaatrU0YDAbx4IMPiubmZvHMM88IlUoldu7cOaH7O1U0NjaKsrIyccUVV4gNGzaklrOWk4fb7RalpaXi7rvvFocOHRJtbW3izTffFOfOnUuN2bJli7BarWL79u3ixIkT4rOf/awoLy8X4XA4Neamm24Sc+fOFW+//bb4z//8TzF9+nRx5513ptZ7vV7hcDjE6tWrRVNTk3jppZeEXq8XP/3pTyd0fzPZpk2bhN1uFzt27BDt7e3ilVdeESaTSTz99NOpMazl5euNN94Qjz76qHj11VcFAPHaa6+NWT9RtTtw4IBQqVTiiSeeEM3NzeKb3/ym0Gg04uTJk5f8PiCiicXMdHlibspMzE2TGzNTZmFumtyYm6YeNmsywKJFi8T69etTPyeTSVFQUCA2b96cxlnR+w0MDAgAYu/evUIIITwej9BoNOKVV15JjWlpaREAxMGDB4UQowdkpVIpXC5XasyPf/xjYbFYRDQaFUII8cgjj4iqqqox21q1apVYsWLFpd6lKcfv94vKykqxa9cusWzZslToYC0nl3/4h38QS5cu/W/Xy7IsnE6n+Od//ufUMo/HI7RarXjppZeEEEI0NzcLAOLw4cOpMb///e+FQqEQPT09QgghfvSjH4msrKxUfd/b9syZM8d7l6aslStXir//+78fs+zzn/+8WL16tRCCtZxM/jR0TGTtbr/9drFy5cox81m8eLH48pe/PK77SETpx8w0OTA3TX7MTZMfM1NmYW7KHMxNUwPfBm2Si8ViOHr0KOrr61PLlEol6uvrcfDgwTTOjN7P6/UCALKzswEAR48eRTweH1O3WbNmoaSkJFW3gwcPoqamBg6HIzVmxYoV8Pl8OHXqVGrM+2/jvTGs/fhbv349Vq5c+YH7m7WcXP793/8dtbW1+MIXvoC8vDzMnz8f//Zv/5Za397eDpfLNaYWVqsVixcvHlNPm82G2tra1Jj6+noolUocOnQoNebaa6+FJEmpMStWrEBraytGRkYu9W5OCUuWLEFDQwPOnDkDADhx4gT279+Pm2++GQBrOZlNZO147CWaGpiZJg/mpsmPuWnyY2bKLMxNmYu5KTOxWTPJDQ0NIZlMjjmZAQCHwwGXy5WmWdH7ybKMjRs34uqrr0Z1dTUAwOVyQZIk2Gy2MWPfXzeXy/WhdX1v3UeN8fl8CIfDl2J3pqRt27bhnXfewebNmz+wjrWcXNra2vDjH/8YlZWVePPNN3HffffhK1/5Cp577jkAf6zHRx1TXS4X8vLyxqxXq9XIzs7+RDWnv87Xv/513HHHHZg1axY0Gg3mz5+PjRs3YvXq1QBYy8lsImv3341hbYkyCzPT5MDcNPkxN2UGZqbMwtyUuZibMpM63RMgynTr169HU1MT9u/fn+6p0F+gq6sLGzZswK5du6DT6dI9HforybKM2tpafPe73wUAzJ8/H01NTfjJT36CtWvXpnl29Em8/PLLeOGFF/Diiy+iqqoKx48fx8aNG1FQUMBaEhERTULMTZMbc1PmYGbKLMxNRJMLr6yZ5HJycqBSqdDf3z9meX9/P5xOZ5pmRe954IEHsGPHDuzZswdFRUWp5U6nE7FYDB6PZ8z499fN6XR+aF3fW/dRYywWC/R6/XjvzpR09OhRDAwMYMGCBVCr1VCr1di7dy9+8IMfQK1Ww+FwsJaTSH5+PubMmTNm2ezZs9HZ2Qngj/X4qGOq0+nEwMDAmPWJRAJut/sT1Zz+Og8//HDqVWI1NTVYs2YNvvrVr6ZeyclaTl4TWbv/bgxrS5RZmJkuf8xNkx9zU+ZgZsoszE2Zi7kpM7FZM8lJkoSFCxeioaEhtUyWZTQ0NKCuri6NM5vahBB44IEH8Nprr2H37t0oLy8fs37hwoXQaDRj6tba2orOzs5U3erq6nDy5MkxB9Vdu3bBYrGkTpzq6urG3MZ7Y1j78bN8+XKcPHkSx48fT33V1tZi9erVqe9Zy8nj6quvRmtr65hlZ86cQWlpKQCgvLwcTqdzTC18Ph8OHTo0pp4ejwdHjx5Njdm9ezdkWcbixYtTY/bt24d4PJ4as2vXLsycORNZWVmXbP+mklAoBKVy7GmMSqWCLMsAWMvJbCJrx2Mv0dTAzHT5Ym7KHMxNmYOZKbMwN2Uu5qYMJWjS27Ztm9BqtWLr1q2iublZfOlLXxI2m024XK50T23Kuu+++4TVahVvvfWW6OvrS32FQqHUmHXr1omSkhKxe/duceTIEVFXVyfq6upS6xOJhKiurhY33nijOH78uNi5c6fIzc0V3/jGN1Jj2trahMFgEA8//LBoaWkRP/zhD4VKpRI7d+6c0P2dapYtWyY2bNiQ+pm1nDwaGxuFWq0WmzZtEmfPnhUvvPCCMBgM4pe//GVqzJYtW4TNZhOvv/66ePfdd8Wtt94qysvLRTgcTo256aabxPz588WhQ4fE/v37RWVlpbjzzjtT6z0ej3A4HGLNmjWiqalJbNu2TRgMBvHTn/50Qvc3k61du1YUFhaKHTt2iPb2dvHqq6+KnJwc8cgjj6TGsJaXL7/fL44dOyaOHTsmAIgnn3xSHDt2TFy4cEEIMXG1O3DggFCr1eJf/uVfREtLi3j88ceFRqMRJ0+enLg7g4gmBDPT5Ym5KbMxN01OzEyZhblpcmNumnrYrMkQzzzzjCgpKRGSJIlFixaJt99+O91TmtIAfOjXs88+mxoTDofF/fffL7KysoTBYBCf+9znRF9f35jb6ejoEDfffLPQ6/UiJydHfO1rXxPxeHzMmD179oh58+YJSZJERUXFmG3QpfGnoYO1nFx++9vfiurqaqHVasWsWbPEz372szHrZVkW3/rWt4TD4RBarVYsX75ctLa2jhkzPDws7rzzTmEymYTFYhH33HOP8Pv9Y8acOHFCLF26VGi1WlFYWCi2bNlyyfdtKvH5fGLDhg2ipKRE6HQ6UVFRIR599FERjUZTY1jLy9eePXs+9Hly7dq1QoiJrd3LL78sZsyYISRJElVVVeJ3v/vdJdtvIkovZqbLD3NTZmNumryYmTIHc9Pkxtw09SiEEGLiruMhIiIiIiIiIiIiIiKi9+Nn1hAREREREREREREREaURmzVERERERERERERERERpxGYNERERERERERERERFRGrFZQ0RERERERERERERElEZs1hAREREREREREREREaURmzVERERERERERERERERpxGYNERERERERERERERFRGrFZQ0RERERERERERERElEZs1hAR0ZRQVlaGp556Kt3TICIiIiIiumwxNxERpQ+bNURENO7uvvtu3HbbbQCA6667Dhs3bpywbW/duhU2m+0Dyw8fPowvfelLEzYPIiIiIiKij8LcRERE76dO9wSIiIg+jlgsBkmS/uLfz83NHcfZEBERERERXX6Ym4iIJi9eWUNERJfM3Xffjb179+Lpp5+GQqGAQqFAR0cHAKCpqQk333wzTCYTHA4H1qxZg6GhodTvXnfddXjggQewceNG5OTkYMWKFQCAJ598EjU1NTAajSguLsb999+PQCAAAHjrrbdwzz33wOv1prb37W9/G8AHL+fv7OzErbfeCpPJBIvFgttvvx39/f2p9d/+9rcxb948PP/88ygrK4PVasUdd9wBv99/ae80IiIiIiKaUpibiIgIYLOGiIguoaeffhp1dXX44he/iL6+PvT19aG4uBgejwfXX3895s+fjyNHjmDnzp3o7+/H7bffPub3n3vuOUiShAMHDuAnP/kJAECpVOIHP/gBTp06heeeew67d+/GI488AgBYsmQJnnrqKVgsltT2HnrooQ/MS5Zl3HrrrXC73di7dy927dqFtrY2rFq1asy48+fPY/v27dixYwd27NiBvXv3YsuWLZfo3iIiIiIioqmIuYmIiAC+DRoREV1CVqsVkiTBYDDA6XSmlv/rv/4r5s+fj+9+97upZT//+c9RXFyMM2fOYMaMGQCAyspKPPHEE2Nu8/3v41xWVoZ/+qd/wrp16/CjH/0IkiTBarVCoVCM2d6famhowMmTJ9He3o7i4mIAwC9+8QtUVVXh8OHDuPLKKwGMhpOtW7fCbDYDANasWYOGhgZs2rTpr7tjiIiIiIiILmJuIiIigFfWEBFRGpw4cQJ79uyByWRKfc2aNQvA6Kuy3rNw4cIP/O4f/vAHLF++HIWFhTCbzVizZg2Gh4cRCoU+9vZbWlpQXFycChwAMGfOHNhsNrS0tKSWlZWVpQIHAOTn52NgYOAT7SsREREREdFfgrmJiGhq4ZU1REQ04QKBAG655RZ873vf+8C6/Pz81PdGo3HMuo6ODnzmM5/Bfffdh02bNiE7Oxv79+/Hvffei1gsBoPBMK7z1Gg0Y35WKBSQZXlct0FERERERPRhmJuIiKYWNmuIiOiSkiQJyWRyzLIFCxbgN7/5DcrKyqBWf/ynoqNHj0KWZXz/+9+HUjl6cejLL7/8Z7f3p2bPno2uri50dXWlXiXW3NwMj8eDOXPmfOz5EBERERERjQfmJiIi4tugERHRJVVWVoZDhw6ho6MDQ0NDkGUZ69evh9vtxp133onDhw/j/PnzePPNN3HPPfd8ZGCYPn064vE4nnnmGbS1teH5559PfYDm+7cXCATQ0NCAoaGhD73Mv76+HjU1NVi9ejXeeecdNDY24q677sKyZctQW1s77vcBERERERHRR2FuIiIiNmuIiOiSeuihh6BSqTBnzhzk5uais7MTBQUFOHDgAJLJJG688UbU1NRg48aNsNlsqVd+fZi5c+fiySefxPe+9z1UV1fjhRdewObNm8eMWbJkCdatW4dVq1YhNzf3Ax+0CYxelv/6668jKysL1157Lerr61FRUYFf/epX477/REREREREfw5zExERKYQQIt2TICIiIiIiIiIiIiIimqp4ZQ0REREREREREREREVEasVlDRERERERERERERESURmzWEBERERERERERERERpRGbNURERERERERERERERGnEZg0REREREREREREREVEasVlDRERERERERERERESURmzWEBERERERERERERERpRGbNURERERERERERERERGnEZg0REREREREREREREVEasVlDRERERERERERERESURmzWEBERERERERERERERpdH/Bx+Co20pNLbkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot Loss and Accuracy side-by-side\n",
    "plt.figure(figsize=(20, 5), facecolor=\"w\")\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_hist, label=\"Train Set Loss\")\n",
    "plt.title(\"Train Set Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(acc_hist, label=\"Train Set Accuracy\")\n",
    "plt.title(\"Train Set Accuracy\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93e1c092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss Statistics: Min=0.0 | Max=24318.5 | Mean=5502.713815789473\n",
      "Train Accuracy Statistics: Min=nan | Max=nan | Mean=nan\n",
      "Train Window [0, 100]: Avg. Loss=4819.5000\n",
      "Train Window [100, 200]: Avg. Loss=5559.3650\n",
      "Train Window [200, 300]: Avg. Loss=5240.4700\n",
      "Train Window [300, 400]: Avg. Loss=5329.9050\n",
      "Train Window [400, 500]: Avg. Loss=4591.9700\n",
      "Train Window [500, 600]: Avg. Loss=4894.0000\n",
      "Train Window [600, 700]: Avg. Loss=4757.0500\n",
      "Train Window [700, 800]: Avg. Loss=5603.5550\n",
      "Train Window [800, 900]: Avg. Loss=5363.6250\n",
      "Train Window [900, 1000]: Avg. Loss=4836.5850\n",
      "Train Window [1000, 1100]: Avg. Loss=4722.5950\n",
      "Train Window [1100, 1200]: Avg. Loss=5050.3700\n",
      "Train Window [1200, 1300]: Avg. Loss=5748.3200\n",
      "Train Window [1300, 1400]: Avg. Loss=5030.0350\n",
      "Train Window [1400, 1500]: Avg. Loss=5547.8900\n",
      "Train Window [1500, 1600]: Avg. Loss=6409.3250\n",
      "Train Window [1600, 1700]: Avg. Loss=6314.2250\n",
      "Train Window [1700, 1800]: Avg. Loss=5184.5550\n",
      "Train Window [1800, 1900]: Avg. Loss=5575.5250\n",
      "Train Window [1900, 2000]: Avg. Loss=5952.1900\n",
      "Train Window [2000, 2100]: Avg. Loss=5162.2500\n",
      "Train Window [2100, 2200]: Avg. Loss=5969.0350\n",
      "Train Window [2200, 2300]: Avg. Loss=5672.7350\n",
      "Train Window [2300, 2400]: Avg. Loss=4985.6400\n",
      "Train Window [2400, 2500]: Avg. Loss=5766.5150\n",
      "Train Window [2500, 2600]: Avg. Loss=5045.1850\n",
      "Train Window [2600, 2700]: Avg. Loss=5927.9250\n",
      "Train Window [2700, 2800]: Avg. Loss=5151.1350\n",
      "Train Window [2800, 2900]: Avg. Loss=6232.3250\n",
      "Train Window [2900, 3000]: Avg. Loss=5275.1200\n",
      "Train Window [3000, 3100]: Avg. Loss=5966.1550\n",
      "Train Window [3100, 3200]: Avg. Loss=5148.4850\n",
      "Train Window [3200, 3300]: Avg. Loss=5561.8400\n",
      "Train Window [3300, 3400]: Avg. Loss=5500.9250\n",
      "Train Window [3400, 3500]: Avg. Loss=5595.7800\n",
      "Train Window [3500, 3600]: Avg. Loss=5114.3350\n",
      "Train Window [3600, 3700]: Avg. Loss=5011.2600\n",
      "Train Window [3700, 3800]: Avg. Loss=4840.4150\n",
      "Train Window [3800, 3900]: Avg. Loss=5244.5000\n",
      "Train Window [3900, 4000]: Avg. Loss=4771.3050\n",
      "Train Window [4000, 4100]: Avg. Loss=5052.5300\n",
      "Train Window [4100, 4200]: Avg. Loss=6698.5250\n",
      "Train Window [4200, 4300]: Avg. Loss=5480.2300\n",
      "Train Window [4300, 4400]: Avg. Loss=5572.4000\n",
      "Train Window [4400, 4500]: Avg. Loss=5191.0650\n",
      "Train Window [4500, 4600]: Avg. Loss=5238.3150\n",
      "Train Window [4600, 4700]: Avg. Loss=5536.2100\n",
      "Train Window [4700, 4800]: Avg. Loss=4841.6350\n",
      "Train Window [4800, 4900]: Avg. Loss=5508.1800\n",
      "Train Window [4900, 5000]: Avg. Loss=5685.2300\n",
      "Train Window [5000, 5100]: Avg. Loss=5468.3650\n",
      "Train Window [5100, 5200]: Avg. Loss=4806.2400\n",
      "Train Window [5200, 5300]: Avg. Loss=5716.5600\n",
      "Train Window [5300, 5400]: Avg. Loss=5382.7800\n",
      "Train Window [5400, 5500]: Avg. Loss=5663.2350\n",
      "Train Window [5500, 5600]: Avg. Loss=4974.3350\n",
      "Train Window [5600, 5700]: Avg. Loss=5683.9850\n",
      "Train Window [5700, 5800]: Avg. Loss=5311.5550\n",
      "Train Window [5800, 5900]: Avg. Loss=6007.8350\n",
      "Train Window [5900, 6000]: Avg. Loss=5594.5900\n",
      "Train Window [6000, 6100]: Avg. Loss=4997.5600\n",
      "Train Window [6100, 6200]: Avg. Loss=5251.2250\n",
      "Train Window [6200, 6300]: Avg. Loss=4858.0150\n",
      "Train Window [6300, 6400]: Avg. Loss=5567.1650\n",
      "Train Window [6400, 6500]: Avg. Loss=5912.6950\n",
      "Train Window [6500, 6600]: Avg. Loss=6011.5700\n",
      "Train Window [6600, 6700]: Avg. Loss=5307.1550\n",
      "Train Window [6700, 6800]: Avg. Loss=5244.7300\n",
      "Train Window [6800, 6900]: Avg. Loss=5650.0300\n",
      "Train Window [6900, 7000]: Avg. Loss=4977.3350\n",
      "Train Window [7000, 7100]: Avg. Loss=6274.9650\n",
      "Train Window [7100, 7200]: Avg. Loss=5272.3250\n",
      "Train Window [7200, 7300]: Avg. Loss=5725.6550\n",
      "Train Window [7300, 7400]: Avg. Loss=6353.3200\n",
      "Train Window [7400, 7500]: Avg. Loss=5771.4750\n",
      "Train Window [7500, 7600]: Avg. Loss=5799.9350\n",
      "Train Window [7600, 7700]: Avg. Loss=5725.3500\n",
      "Train Window [7700, 7800]: Avg. Loss=5223.2800\n",
      "Train Window [7800, 7900]: Avg. Loss=5494.5750\n",
      "Train Window [7900, 8000]: Avg. Loss=5019.7000\n",
      "Train Window [8000, 8100]: Avg. Loss=5563.6350\n",
      "Train Window [8100, 8200]: Avg. Loss=6094.4200\n",
      "Train Window [8200, 8300]: Avg. Loss=5969.1700\n",
      "Train Window [8300, 8400]: Avg. Loss=5658.8800\n",
      "Train Window [8400, 8500]: Avg. Loss=5669.8400\n",
      "Train Window [8500, 8600]: Avg. Loss=5753.3800\n",
      "Train Window [8600, 8700]: Avg. Loss=5732.8150\n",
      "Train Window [8700, 8800]: Avg. Loss=5457.5650\n",
      "Train Window [8800, 8900]: Avg. Loss=5264.6950\n",
      "Train Window [8900, 9000]: Avg. Loss=5486.7550\n",
      "Train Window [9000, 9100]: Avg. Loss=5130.3800\n",
      "Train Window [9100, 9200]: Avg. Loss=5491.8750\n",
      "Train Window [9200, 9300]: Avg. Loss=5979.3650\n",
      "Train Window [9300, 9400]: Avg. Loss=5596.5900\n",
      "Train Window [9400, 9500]: Avg. Loss=6137.1400\n",
      "Train Window [9500, 9600]: Avg. Loss=5459.8450\n",
      "Train Window [9600, 9700]: Avg. Loss=6239.0300\n",
      "Train Window [9700, 9800]: Avg. Loss=6631.0550\n",
      "Train Window [9800, 9900]: Avg. Loss=5412.1250\n",
      "Train Window [9900, 10000]: Avg. Loss=5648.5750\n",
      "Train Window [10000, 10100]: Avg. Loss=5577.0300\n",
      "Train Window [10100, 10200]: Avg. Loss=5571.9650\n",
      "Train Window [10200, 10300]: Avg. Loss=5309.4200\n",
      "Train Window [10300, 10400]: Avg. Loss=5605.2900\n",
      "Train Window [10400, 10500]: Avg. Loss=5708.5450\n",
      "Train Window [10500, 10600]: Avg. Loss=5419.5800\n",
      "Train Window [10600, 10700]: Avg. Loss=5437.0300\n",
      "Train Window [10700, 10800]: Avg. Loss=5952.2200\n",
      "Train Window [10800, 10900]: Avg. Loss=5712.4350\n",
      "Train Window [10900, 11000]: Avg. Loss=5886.3450\n",
      "Train Window [11000, 11100]: Avg. Loss=5935.7812\n"
     ]
    }
   ],
   "source": [
    "# Print loss statistics\n",
    "print(f\"Train Loss Statistics: Min={np.min(loss_hist)} | Max={np.max(loss_hist)} | Mean={np.mean(loss_hist)}\")\n",
    "\n",
    "# Print accuracy statistics\n",
    "print(f\"Train Accuracy Statistics: Min={np.min(acc_hist)} | Max={np.max(acc_hist)} | Mean={np.mean(acc_hist)}\")\n",
    "\n",
    "# Print F1 Score statistics\n",
    "if len(f1_hist) > 0:\n",
    "    print(f\"Train F1 Score Statistics: Min={np.min(f1_hist)} | Max={np.max(f1_hist)} | Mean={np.mean(f1_hist)}\")\n",
    "\n",
    "# Print how the loss evolves over time\n",
    "num_iters = len(loss_hist)\n",
    "window_step = 100\n",
    "for train_window in range(0, num_iters, window_step):\n",
    "    print(f\"Train Window [{train_window}, {train_window+window_step}]: Avg. Loss={np.mean(loss_hist[train_window:train_window+window_step]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3557d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Loss in Bokeh\n",
    "from snnTorch.utils.bokeh_plots import create_line_plot\n",
    "import bokeh.plotting as bplt\n",
    "from bokeh.io import output_notebook, output_file\n",
    "\n",
    "# output_notebook()   # Show the plot in the notebook\n",
    "\n",
    "y_arrays_loss = [(loss_hist, \"Loss History\")]\n",
    "\n",
    "loss_plot = create_line_plot(\n",
    "    title=\"Training Loss\", x_axis_label=\"Iteration\", y_axis_label=\"Loss\",\n",
    "    x=list(range(len(loss_hist))), y_arrays=y_arrays_loss,\n",
    "    sizing_mode=\"fixed\",        # stretch_both\n",
    "    tooltips=\"Data point @x: @y\",\n",
    "    legend_location=\"top_right\",\n",
    "    legend_bg_fill_color=\"navy\",\n",
    "    legend_bg_fill_alpha=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f960b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "showPlot = True\n",
    "if showPlot:\n",
    "    bplt.show(loss_plot)\n",
    "\n",
    "# Clear the Bokeh Plots\n",
    "bplt.curdoc().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8973c1",
   "metadata": {},
   "source": [
    "## Output Neurons Spiking behavior to a Test Input\n",
    "Let's visualize the output neurons' spiking behavior when we feed a test input to the network of each Class Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65d443c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function for testing. No Penalty and higher tolerance.\n",
    "#TODO # Is it okay to use a different loss function for testing?\n",
    "\n",
    "\n",
    "loss_fn_test = SF.mse_temporal_loss(\n",
    "    target_is_time=True,\n",
    "    tolerance=PRED_GT_TOLERANCE * 1.5,       # Tolerance for the mse loss (in timesteps). If the output neuron spikes within this tolerance, the loss is 0\n",
    "    reduction='mean',        # Average the loss across the batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c577f",
   "metadata": {},
   "source": [
    "### Output Behavior for GT -1 -> No HFO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4529a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found batch with Ground Truth:  tensor([-1.])\n",
      "test_no_hfo_input shape = torch.Size([1, 180, 2])\n",
      "Number of UP spikes in the batch: 12.0\n",
      "Number of DN spikes in the batch: 12.0\n",
      "test_no_hfo_gt shape = torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "net.eval()  # Set the network to evaluation mode\n",
    "\n",
    "test_no_hfo_input, test_no_hfo_gt = None, None\n",
    "for test_batch, test_gt_batch in iter(test_loader):\n",
    "    # Check if current batch has an input without an HFO\n",
    "    test_no_hfo_input_idx = torch.argmin(test_gt_batch).item()\n",
    "    if test_gt_batch[test_no_hfo_input_idx] < 0:\n",
    "        # Found a batch without an HFO\n",
    "        # Get the input data and ground truth for the test batch\n",
    "        test_no_hfo_input = test_batch[test_no_hfo_input_idx]\n",
    "        test_no_hfo_gt = test_gt_batch[test_no_hfo_input_idx]\n",
    "        break\n",
    "\n",
    "if test_no_hfo_input is None:\n",
    "    print(\"No Batch without a HFO found in the Test Set!\")\n",
    "    exit()\n",
    "\n",
    "# Add a batch dimension to the input data. Shape: (1, num_steps)\n",
    "test_no_hfo_input = test_no_hfo_input.unsqueeze(0)\n",
    "test_no_hfo_gt = test_no_hfo_gt.unsqueeze(0)\n",
    "\n",
    "print(\"Found batch with Ground Truth: \", test_no_hfo_gt)\n",
    "print(f\"test_no_hfo_input shape = {test_no_hfo_input.shape}\")\n",
    "print(f\"Number of UP spikes in the batch: {torch.sum(test_no_hfo_input[:, :,0])}\")\n",
    "print(f\"Number of DN spikes in the batch: {torch.sum(test_no_hfo_input[:, :, 1])}\")\n",
    "print(f\"test_no_hfo_gt shape = {test_no_hfo_gt.shape}\")\n",
    "\n",
    "test_no_hfo_input = test_no_hfo_input.to(device)    # Send the test data to the device\n",
    "test_no_hfo_gt = test_no_hfo_gt.to(device)        # Send the test ground truth to the device\n",
    "\n",
    "# Feed the test batch through the network\n",
    "test_spks, test_mem, test_cur = net(test_no_hfo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a092a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No HFO Event\n",
      "input_spike_times: [array([ 29,  36,  62,  77,  93, 102, 110, 121, 129, 139, 147, 153], dtype=int64), array([ 26,  32,  55,  73,  80,  96, 105, 114, 125, 131, 141, 150], dtype=int64)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snnTorch.utils.hfo import input_sample_to_spike_raster\n",
    "\n",
    "\n",
    "# Creates a Figure and Axis objects\n",
    "fig, ax = input_sample_to_spike_raster(\n",
    "    test_no_hfo_input[0, :, :].cpu().detach().numpy(),\n",
    "    test_no_hfo_gt[0].cpu().detach().numpy(),\n",
    "    PRED_GT_TOLERANCE,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2862a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate the Loss and Accuracy\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test_no_hfo_gt \u001b[38;5;241m=\u001b[39m test_no_hfo_gt\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)   \u001b[38;5;66;03m# Add num_features dimension to the ground truth tensor\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_spks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_no_hfo_gt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# Copy the ground truth to avoid modifying it in place\u001b[39;00m\n\u001b[0;32m      7\u001b[0m acc_val \u001b[38;5;241m=\u001b[39m first_spike_acc(out_spks, test_no_hfo_gt, tolerance\u001b[38;5;241m=\u001b[39mPRED_GT_TOLERANCE, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Remove the batch dimension\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\snntorch\\functional\\loss.py:801\u001b[0m, in \u001b[0;36mmse_temporal_loss.__call__\u001b[1;34m(self, spk_rec, targets)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, spk_rec, targets):\n\u001b[1;32m--> 801\u001b[0m     spk_time, target_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspk_time_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspk_rec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# return encoded targets\u001b[39;00m\n\u001b[0;32m    804\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(\n\u001b[0;32m    805\u001b[0m         spk_time \u001b[38;5;241m/\u001b[39m spk_rec\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), target_time \u001b[38;5;241m/\u001b[39m spk_rec\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    806\u001b[0m     )  \u001b[38;5;66;03m# spk_time_final: num_spikes x B x Nc. # Same with targets.\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\snntorch\\functional\\loss.py:484\u001b[0m, in \u001b[0;36mSpikeTime.forward\u001b[1;34m(self, spk_out, targets)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# next need to check how tolerance copes with multi-spikes\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance:\n\u001b[1;32m--> 484\u001b[0m     spk_time_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolerance_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspk_time_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolerance\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spk_time_final, targets\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\torch\\autograd\\function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\snntorch\\functional\\loss.py:629\u001b[0m, in \u001b[0;36mSpikeTime.Tolerance.forward\u001b[1;34m(ctx, spk_time, target, tolerance)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, spk_time, target, tolerance):\n\u001b[0;32m    626\u001b[0m     spk_time_clone \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    627\u001b[0m         spk_time\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    628\u001b[0m     )  \u001b[38;5;66;03m# spk_time_clone: BxN (FxBxN for multi-spike); target: TxBxN\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m     spk_time_clone[torch\u001b[38;5;241m.\u001b[39mabs(spk_time \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m<\u001b[39m tolerance] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    630\u001b[0m         torch\u001b[38;5;241m.\u001b[39mones_like(spk_time) \u001b[38;5;241m*\u001b[39m target\n\u001b[0;32m    631\u001b[0m     )[torch\u001b[38;5;241m.\u001b[39mabs(spk_time \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m<\u001b[39m tolerance]\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spk_time_clone\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "# Extract the output spikes of the network\n",
    "out_spks = test_spks[-1]\n",
    "\n",
    "# Calculate the Loss and Accuracy\n",
    "test_no_hfo_gt = test_no_hfo_gt.clone().unsqueeze(1)   # Add num_features dimension to the ground truth tensor\n",
    "loss_val = loss_fn_test(out_spks, test_no_hfo_gt.clone())   # Copy the ground truth to avoid modifying it in place\n",
    "acc_val = first_spike_acc(out_spks, test_no_hfo_gt, tolerance=PRED_GT_TOLERANCE, verbose=False)\n",
    "\n",
    "# Remove the batch dimension\n",
    "out_spks = out_spks.squeeze(1)  # Resulting Shape = (num_steps, num_neurons)\n",
    "\n",
    "print(f\"out_spks Shape: {out_spks.shape}\")\n",
    "print(f\"Number of output spikes per class: {torch.sum(out_spks[:, 0])}\")\n",
    "print(f\"Loss: {loss_val.item()} | Accuracy: {acc_val.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afd2b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target label is: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (1, 1) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe target label is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(test_no_hfo_gt\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#  Plot spike count histogram\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m anim \u001b[38;5;241m=\u001b[39m \u001b[43msplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspike_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_spks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                        \u001b[49m\u001b[43manimate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m HTML(anim\u001b[38;5;241m.\u001b[39mto_html5_video())\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\snntorch\\spikeplot.py:248\u001b[0m, in \u001b[0;36mspike_count\u001b[1;34m(data, fig, ax, labels, num_steps, animate, interpolate, gridshader, interval, time_step)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(xrange \u001b[38;5;241m*\u001b[39m interpolate):\n\u001b[0;32m    247\u001b[0m     idx \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mfloor(i \u001b[38;5;241m/\u001b[39m interpolate)\n\u001b[1;32m--> 248\u001b[0m     \u001b[43m_plt_style\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gridshader:  \u001b[38;5;66;03m# gs appears unused but is needed by plt\u001b[39;00m\n\u001b[0;32m    251\u001b[0m         gs \u001b[38;5;241m=\u001b[39m _GridShader(  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n\u001b[0;32m    252\u001b[0m             ax, facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlightgrey\u001b[39m\u001b[38;5;124m\"\u001b[39m, first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m\n\u001b[0;32m    253\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\snntorch\\spikeplot.py:338\u001b[0m, in \u001b[0;36m_plt_style\u001b[1;34m(data, labels, ax, idx, time_step)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by spike_count to modify style of plot.\"\"\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# spike data\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: time})\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# numeric placeholder for the y axis\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\pandas\\core\\series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\pandas\\core\\construction.py:633\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    642\u001b[0m     _sanitize_non_ordered(data)\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\pandas\\core\\construction.py:659\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    656\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    657\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 659\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    663\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[1;32mc:\\Users\\NCN\\Miniconda3\\envs\\lava_snn_ripples\\lib\\site-packages\\pandas\\core\\construction.py:718\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m     )\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (1, 1) instead"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "idx = 0     # Choose a sample from the batch to visualize (only 1 sample in the batch)\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='w', figsize=(12, 7))\n",
    "\n",
    "# Define the labels for the classes\n",
    "# Single Neuron -> HFO Detected\n",
    "labels=['HFO']\n",
    "\n",
    "print(f\"The target label is: {int(test_no_hfo_gt.sum() > 0)}\")\n",
    "\n",
    "# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\n",
    "\n",
    "#  Plot spike count histogram\n",
    "anim = splt.spike_count(out_spks.detach().cpu(), fig, ax, labels=labels, \n",
    "                        animate=True, interpolate=1)\n",
    "\n",
    "HTML(anim.to_html5_video())\n",
    "# anim.save(\"spike_bar.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5082e4c",
   "metadata": {},
   "source": [
    "### Output Behavior for GT > 0 -> HFO at a given timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81cb92a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found batch with Ground Truth:  tensor([155.])\n",
      "test_hfo_input shape = torch.Size([1, 180, 2])\n",
      "Number of input spikes in the batch: 5.0\n"
     ]
    }
   ],
   "source": [
    "net.eval()  # Set the network to evaluation mode\n",
    "\n",
    "test_hfo_input, test_hfo_gt = None, None\n",
    "for test_batch, test_gt_batch in iter(test_loader):\n",
    "    # Check if current batch has an input without an HFO\n",
    "    test_hfo_input_idx = torch.argmax(test_gt_batch).item()\n",
    "    if test_gt_batch[test_hfo_input_idx] > 0 and test_gt_batch[test_hfo_input_idx] < WINDOW_SIZE:\n",
    "        # Found a batch without an HFO\n",
    "        # Get the input data and ground truth for the test batch\n",
    "        test_hfo_input = test_batch[test_hfo_input_idx]\n",
    "        test_hfo_gt = test_gt_batch[test_hfo_input_idx]\n",
    "        break\n",
    "\n",
    "if test_hfo_input is None:\n",
    "    print(\"No Batch with an HFO found in the Test Set!\")\n",
    "    exit()\n",
    "\n",
    "# Add a batch dimension to the input data. Shape: (1, num_steps)\n",
    "test_hfo_input = test_hfo_input.unsqueeze(0)\n",
    "test_hfo_gt = test_hfo_gt.unsqueeze(0)\n",
    "\n",
    "print(\"Found batch with Ground Truth: \", test_hfo_gt)\n",
    "print(f\"test_hfo_input shape = {test_hfo_input.shape}\")\n",
    "print(f\"Number of input spikes in the batch: {torch.sum(test_hfo_input)}\")\n",
    "\n",
    "test_hfo_input = test_hfo_input.to(device)    # Send the test data to the device\n",
    "test_hfo_gt = test_hfo_gt.to(device)        # Send the test ground truth to the device\n",
    "\n",
    "# Feed the test batch through the network\n",
    "test_spks, test_mem, test_cur = net(test_hfo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d06b35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Interval: 135.0 to 175.0\n",
      "input_spike_times: [array([10, 16, 82], dtype=int64), array([13, 66], dtype=int64)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creates a Figure and Axis objects\n",
    "fig, ax = input_sample_to_spike_raster(\n",
    "    test_hfo_input[0, :, :].cpu().detach().numpy(),\n",
    "    test_hfo_gt[0].cpu().detach().numpy(),\n",
    "    PRED_GT_TOLERANCE,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20479f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_spks Shape: torch.Size([185, 1])\n",
      "Number of output spikes per class: 0.0\n",
      "First Out Spike Time: 0\n",
      "Loss: 0.0 | Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Extract the output spikes of the network\n",
    "out_spks = test_spks[-1]\n",
    "\n",
    "# Calculate the Loss and Accuracy\n",
    "test_hfo_gt = test_hfo_gt.clone().unsqueeze(1)   # Add num_features dimension to the ground truth tensor\n",
    "loss_val = loss_fn_test(out_spks, test_hfo_gt.clone())   # Copy the ground truth to avoid modifying it in place\n",
    "acc_val = first_spike_acc(out_spks, test_hfo_gt, tolerance=PRED_GT_TOLERANCE, verbose=False)\n",
    "\n",
    "# Remove the batch dimension\n",
    "out_spks = out_spks.squeeze(1)  # Resulting Shape = (num_steps, num_neurons)\n",
    "\n",
    "print(f\"out_spks Shape: {out_spks.shape}\")\n",
    "print(f\"Number of output spikes per class: {torch.sum(out_spks[:, 0])}\")\n",
    "print(f\"First Out Spike Time: {torch.argmax(out_spks[:, 0])}\")\n",
    "print(f\"Loss: {loss_val.item()} | Accuracy: {acc_val.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "idx = 0     # Choose a sample from the batch to visualize (only 1 sample in the batch)\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='w', figsize=(12, 7))\n",
    "\n",
    "print(f\"The target label is: {test_hfo_gt.sum() > 0}\")\n",
    "\n",
    "# Define the labels for the classes\n",
    "# Single Neuron -> HFO Detected\n",
    "labels=['HFO']\n",
    "\n",
    "# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\n",
    "\n",
    "#  Plot spike count histogram\n",
    "anim = splt.spike_count(out_spks.detach().cpu(), fig, ax, labels=labels, \n",
    "                        animate=True, interpolate=1)\n",
    "\n",
    "HTML(anim.to_html5_video())\n",
    "# anim.save(\"spike_bar.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b56fa4",
   "metadata": {},
   "source": [
    "## Show the Trained Network Parameters\n",
    "Show the trained parameters and calculate the parameter difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52451cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the network architecture\n",
    "total_params = 0    # Accumulator for the total params in the network\n",
    "# Iterate through the layers of the network\n",
    "for idx, (name, param) in enumerate(net.named_parameters()):\n",
    "    untrained_param = untrained_params[idx]\n",
    "\n",
    "    # print(\"param: \", param)\n",
    "    if param.shape == torch.Size([]):\n",
    "        print(f\"Scalar Param ({name}) | Shape={param.shape} | Param Diff: {torch.sum(torch.abs(param - untrained_param)).item()} | Value={param} \\n\")\n",
    "    elif len(param.shape) == 1:\n",
    "        print(f\"Vector Param ({name}) | Shape={param.shape} | Param Diff: {torch.sum(torch.abs(param - untrained_param)).item()} | Value={param} \\n\")\n",
    "    else:\n",
    "        print(f\"Tensor Param ({name}) | Shape={param.shape}. Total={param.numel()} | Param Diff: {torch.sum(torch.abs(param - untrained_param)).item()} | Preview: {param[:8, :8]}\\n\")\n",
    "\n",
    "    # Add the number of parameters in the layer to the total\n",
    "    total_params += param.numel()\n",
    "\n",
    "# Print the total number of parameters in the network\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb5c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained network to a file\n",
    "SAVE_TRAINED_NETWORK = False\n",
    "prefix=\"test_mesquita\"\n",
    "if SAVE_TRAINED_NETWORK:\n",
    "    os.makedirs(\"./out\",exist_ok=True)  # Create the output directory if it doesn't exist \n",
    "    torch.save(net.state_dict(), f\"./out/{prefix}_trained_net_loss.pth\") # trained_net_loss_penalty.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90a23e",
   "metadata": {},
   "source": [
    "## Test the Network on the Test Set\n",
    "#### Load a Trained Network Model for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a network from a file\n",
    "LOAD_TRAINED_NETWORK = False\n",
    "if LOAD_TRAINED_NETWORK:\n",
    "    filename = f\"./out/{prefix}_trained_net_loss.pth\"     # \"./trained_net_loss_penalty.pth\"\n",
    "    net.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3398f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network on the entire test set\n",
    "\n",
    "test_loss_hist = []         # History of the test loss\n",
    "test_acc_hist = []          # History of the test accuracy\n",
    "verbose_training = False    # For debugging purposes\n",
    "max_test_iter = None        # Maximum number of iterations to test the network\n",
    "\n",
    "# Test Training Loop\n",
    "with torch.no_grad():\n",
    "    iter_counter = 0                    # Counter for the iterations\n",
    "    for data, targets in iter(test_loader):\n",
    "        data = data.to(device)          # Send the data to the device (GPU or CPU)\n",
    "        targets = targets.to(device)    # Send the targets to the device (GPU or CPU)\n",
    "\n",
    "        # Perform a training step\n",
    "        loss_val, acc_val = forward_step(data, targets, is_train=False, verbose=False)\n",
    "        \n",
    "        # Store the Loss History\n",
    "        test_loss_hist.append(loss_val)\n",
    "        # Append the accuracy to the accuracy history\n",
    "        test_acc_hist.append(acc_val)\n",
    "        \n",
    "        # Print if target has at least 1 spike\n",
    "        if verbose_training and torch.sum(targets) > 0:\n",
    "            print(f\"Epoch: {epoch} | Iteration: {iter_counter} has a Channel Burst!\")\n",
    "\n",
    "\n",
    "        # Print Train/Test Loss/Accuracy\n",
    "        if iter_counter % 50 == 0:\n",
    "            tr_utils.test_printer(\n",
    "                iter_counter,\n",
    "                loss_val, acc_val\n",
    "            )\n",
    "\n",
    "        iter_counter += 1       # Increment the iteration counter\n",
    "\n",
    "        if max_test_iter and iter_counter > max_test_iter:\n",
    "            break   # Stop the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot Loss and Accuracy side-by-side\n",
    "plt.figure(figsize=(20, 5), facecolor=\"w\")\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(test_loss_hist, label=\"Test Set Loss\")\n",
    "plt.title(\"Test Set Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_acc_hist, label=\"Test Set Accuracy\")\n",
    "plt.title(\"Test Set Accuracy\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print loss statistics\n",
    "print(f\"Test Loss Statistics: Min={np.min(test_loss_hist)} | Max={np.max(test_loss_hist)} | Mean={np.mean(test_loss_hist)}\")\n",
    "\n",
    "# Print accuracy statistics\n",
    "print(f\"Test Accuracy Statistics: Min={np.min(test_acc_hist)} | Max={np.max(test_acc_hist)} | Mean={np.mean(test_acc_hist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd79bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lava_snn_ripples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
